{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#torch-admp","title":"torch-admp","text":"<p>Automatic Differentiable Multipolar Polarizable (ADMP) in PyTorch backend</p>"},{"location":"#overview","title":"Overview","text":"<p><code>torch-admp</code> is a PyTorch implementation of the ADMP (Automatic Differentiable Multipolar Polarizable) module in DMFF (Differentiable Molecular Force Field) package. This package provides efficient implementations of various molecular dynamics force calculations including:</p> <ul> <li>Particle Mesh Ewald (PME) for electrostatic interactions</li> <li>Charge Equilibration (QEq) methods</li> <li>Polarizable electrode models</li> <li>Neighbor list management</li> <li>Optimization algorithms</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install torch-admp\n</code></pre> <p>For development:</p> <pre><code>git clone https://github.com/ChiahsinChu/torch-admp.git\ncd torch-admp\npip install -e .[docs,test]\n</code></pre>"},{"location":"#features","title":"Features","text":"<ul> <li>GPU Accelerated: Built on PyTorch for efficient GPU computation</li> <li>JIT Compilation: Support for TorchScript compilation</li> <li>Modular Design: Clean separation of different force components</li> <li>Extensible: Easy to add new force modules</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>API Reference - Complete API documentation</li> <li>Examples - Usage examples and tutorials</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you use torch-admp in your research, please cite:</p> <pre><code>@software{torch_admp,\n  author = {ChiahsinChu},\n  title = {torch-admp: ADMP in PyTorch backend},\n  url = {https://github.com/ChiahsinChu/torch-admp},\n  year = {2024}\n}\n</code></pre>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the LGPL-3.0-or-later License - see the LICENSE file for details.</p>"},{"location":"CHANGELOG/","title":"CHANGELOG","text":""},{"location":"CHANGELOG/#changelog","title":"CHANGELOG","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"CHANGELOG/#115-2026-01-26","title":"[1.1.5] - 2026-01-26","text":""},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>Restored polarizable electrode module with CONP/CONQ support</li> <li>Improved energy unit handling in electrode calculations</li> </ul>"},{"location":"CHANGELOG/#changed","title":"Changed","text":"<ul> <li>Updated electrode implementation with improved PME integration</li> <li>Enhanced CI configuration for electrode testing</li> <li>Updated project metadata and citation information</li> <li>Ensured consistent tensor precision across the codebase</li> <li>Updated dependency requirements for conda environments</li> </ul>"},{"location":"CHANGELOG/#fixed","title":"Fixed","text":"<ul> <li>Fixed citation metadata formatting</li> <li>Code fixes for electrode module stability</li> <li>Python code formatting improvements</li> </ul>"},{"location":"CHANGELOG/#unreleased","title":"[Unreleased]","text":""},{"location":"CHANGELOG/#added_1","title":"Added","text":"<ul> <li>Multi-Python version testing matrix (3.9, 3.10, 3.11, 3.12)</li> <li>Optional vesin dependency support with proper import handling</li> </ul>"},{"location":"CHANGELOG/#changed_1","title":"Changed","text":"<ul> <li>Updated minimum Python version requirement from 3.8 to 3.9</li> <li>Made vesin an optional dependency instead of required</li> <li>Enhanced CI workflow to test against multiple Python versions</li> <li>Configured coverage reports to only upload for Python 3.11</li> </ul>"},{"location":"CHANGELOG/#fixed_1","title":"Fixed","text":"<ul> <li>Added proper error handling for vesin_nblist when vesin is not installed</li> <li>Improved test coverage for neighbor list functionality with enhanced consistency checks</li> </ul>"},{"location":"CHANGELOG/#114-2026-01-20","title":"[1.1.4] - 2026-01-20","text":""},{"location":"CHANGELOG/#added_2","title":"Added","text":"<ul> <li>Docstring coverage badge to documentation</li> <li>DeepMD package integration for enhanced compatibility</li> </ul>"},{"location":"CHANGELOG/#changed_2","title":"Changed","text":"<ul> <li>Enhanced testing infrastructure</li> <li>Improved error handling in tests</li> <li>Updated precision handling for better compatibility with DeepMD</li> </ul>"},{"location":"CHANGELOG/#removed","title":"Removed","text":"<ul> <li>DeepMD code from tests (moved to integration)</li> </ul>"},{"location":"CHANGELOG/#fixed_2","title":"Fixed","text":"<ul> <li>Device and dtype consistency in matinv_optimize function</li> </ul>"},{"location":"CHANGELOG/#113-2026-01-17","title":"[1.1.3] - 2026-01-17","text":""},{"location":"CHANGELOG/#added_3","title":"Added","text":"<ul> <li>Global precision handling for consistent tensor operations</li> <li>Comprehensive NumPy-style docstrings throughout the codebase</li> <li>Development tools:</li> <li>Python test script (<code>scripts/python_test.sh</code>)</li> <li>PyPI release automation script (<code>scripts/pypi_release.sh</code>)</li> <li>Enhanced documentation in <code>scripts/README.md</code></li> </ul>"},{"location":"CHANGELOG/#changed_3","title":"Changed","text":"<ul> <li>Fixed dtype consistency and device placement across all tensors</li> <li>Replaced deprecated <code>torch.inverse</code> with <code>torch.linalg.inverse</code></li> <li>Improved CI configuration to trigger documentation deployment only on master branch</li> <li>Updated README.md with latest project information</li> <li>Enhanced PME and QEq modules with better precision handling</li> <li>Improved neighbor list implementation with better error handling</li> </ul>"},{"location":"CHANGELOG/#112-2026-01-16","title":"[1.1.2] - 2026-01-16","text":""},{"location":"CHANGELOG/#added_4","title":"Added","text":"<ul> <li>Batch inference support for PME and QEq modules</li> <li>Enhanced BaseForceModule with standardized input tensor handling</li> <li>Shape verification for forward methods in BaseForceModule and derived classes</li> <li>Comprehensive documentation updates for tensor shapes and batch processing</li> </ul>"},{"location":"CHANGELOG/#changed_4","title":"Changed","text":"<ul> <li>Converted PME (Particle Mesh Ewald) to support batch inference</li> <li>Converted QEq (Charge Equilibration) to support batch inference</li> <li>Updated docstrings to specify tensor shapes for batch processing</li> <li>Improved test tolerance settings for numerical tests</li> <li>Temporarily removed polarizable electrode module (will be re-added in future release)</li> </ul>"},{"location":"CHANGELOG/#fixed_3","title":"Fixed","text":"<ul> <li>Improved numerical stability in batch processing</li> <li>Enhanced error handling for tensor shape validation</li> </ul>"},{"location":"CHANGELOG/#111-2026-01-08","title":"[1.1.1] - 2026-01-08","text":""},{"location":"CHANGELOG/#added_5","title":"Added","text":"<ul> <li>Pypi release</li> </ul>"},{"location":"CHANGELOG/#fixed_4","title":"Fixed","text":"<ul> <li>Bug fixes and stability improvements</li> </ul>"},{"location":"CHANGELOG/#110-2025-11-18","title":"[1.1.0] - 2025-11-18","text":""},{"location":"CHANGELOG/#added_6","title":"Added","text":"<ul> <li>Enhanced PME functionality</li> <li>Improved QEq methods</li> <li>Additional electrode simulation features</li> </ul>"},{"location":"CHANGELOG/#fixed_5","title":"Fixed","text":"<ul> <li>Performance optimizations</li> <li>Memory usage improvements</li> </ul>"},{"location":"CHANGELOG/#100-2025-03-28","title":"[1.0.0] - 2025-03-28","text":""},{"location":"CHANGELOG/#added_7","title":"Added","text":"<ul> <li>Initial release of torch-admp</li> <li>Core functionality for:</li> <li>PME (Particle Mesh Ewald) calculations</li> <li>QEq (Charge Equilibration) methods</li> <li>Electrode simulations</li> <li>Neighbor list management</li> <li>Spatial calculations</li> <li>Optimization utilities</li> <li>Example scripts for PME and QEq</li> <li>Comprehensive test suite</li> <li>Documentation with API references and examples</li> </ul>"},{"location":"CHANGELOG/#related-documents","title":"Related Documents","text":"Document Type Link Description Project Context AGENTS.md Project overview and current focus API Documentation api/ Detailed API references Examples examples/ Usage examples and tutorials"},{"location":"agents/AGENTS/","title":"torch-admp Project Documentation","text":""},{"location":"agents/AGENTS/#torch-admp-project-documentation","title":"torch-admp Project Documentation","text":""},{"location":"agents/AGENTS/#project-overview","title":"Project Overview","text":"<p><code>torch-admp</code> is a PyTorch implementation of the ADMP (Automatic Differentiable Multipolar Polarizable) module in DMFF (Differentiable Molecular Force Field) package. This package provides efficient implementations of various molecular dynamics force calculations including PME (Particle Mesh Ewald), QEq (Charge Equilibration), polarizable electrode models, and optimization algorithms.</p>"},{"location":"agents/AGENTS/#key-components","title":"Key Components","text":""},{"location":"agents/AGENTS/#core-modules","title":"Core Modules","text":"<ul> <li>PME Module: Electrostatic interaction calculations using Particle Mesh Ewald method</li> <li>QEq Module: Charge equilibration methods for dynamic charge distribution</li> <li>Electrode Module: Polarizable electrode models for electrochemical simulations</li> <li>Neighbor List: Efficient neighbor list construction for periodic systems</li> <li>Optimizer: Various optimization algorithms for charge and force calculations</li> </ul>"},{"location":"agents/AGENTS/#architecture","title":"Architecture","text":"<ul> <li>Built on PyTorch for GPU acceleration and automatic differentiation</li> <li>Modular design with clear separation of force components</li> <li>JIT compilation support for performance optimization</li> <li>Extensible framework for adding new force modules</li> </ul>"},{"location":"agents/AGENTS/#development-guidelines","title":"Development Guidelines","text":""},{"location":"agents/AGENTS/#code-standards","title":"Code Standards","text":"<ul> <li>Follow PEP 8 Python style guidelines</li> <li>Use NumPy-style docstrings for all public functions and classes</li> <li>Include type hints for all function parameters and return values</li> <li>Maintain backward compatibility when possible</li> </ul>"},{"location":"agents/AGENTS/#testing","title":"Testing","text":"<ul> <li>Unit tests for all core functionality</li> <li>Integration tests for complete workflows</li> <li>Performance benchmarks for critical paths</li> <li>Numerical accuracy validation against reference implementations</li> </ul>"},{"location":"agents/AGENTS/#documentation-requirements","title":"Documentation Requirements","text":"<ul> <li>All public APIs must have comprehensive docstrings</li> <li>Examples should be provided for major use cases</li> <li>Theory sections should explain the mathematical foundations</li> <li>Performance considerations should be documented</li> </ul>"},{"location":"agents/AGENTS/#common-workflows","title":"Common Workflows","text":""},{"location":"agents/AGENTS/#installation-and-setup","title":"Installation and Setup","text":"<pre><code># Basic installation\npip install torch-admp\n\n# Development installation\ngit clone https://github.com/ChiahsinChu/torch-admp.git\npip install -e torch-admp[docs,test]\n# DMFF is required for tests\npip install \"DMFF @ git+https://github.com/ChiahsinChu/DMFF.git@devel\"\n</code></pre>"},{"location":"agents/AGENTS/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Use GPU acceleration when available</li> <li>Enable JIT compilation for repeated calculations</li> </ul>"},{"location":"agents/AGENTS/#validation-scenarios","title":"Validation Scenarios","text":""},{"location":"agents/AGENTS/#basic-functionality-validation","title":"Basic Functionality Validation","text":"<ul> <li>Module Import: Test all modules can be imported successfully</li> <li>Device Compatibility: Verify CPU and GPU functionality</li> <li>JIT Compilation: Test TorchScript compilation of key modules</li> </ul>"},{"location":"agents/AGENTS/#scientific-validation","title":"Scientific Validation","text":"<ul> <li>Consistency test: Compare output energy/forces against reference data (e.g., analytical solutions, results from other packages)</li> </ul>"},{"location":"agents/AGENTS/#critical-warnings","title":"Critical Warnings","text":"<ul> <li>Numerical Precision: Use double precision for charge calculations</li> </ul>"},{"location":"agents/AGENTS/#file-organization","title":"File Organization","text":"<pre><code>torch_admp/\n\u251c\u2500\u2500 __init__.py          # Package initialization\n\u251c\u2500\u2500 base_force.py        # Base class for force modules\n\u251c\u2500\u2500 pme.py              # PME implementation\n\u251c\u2500\u2500 qeq.py              # QEq methods\n\u251c\u2500\u2500 electrode.py        # Polarizable electrode models\n\u251c\u2500\u2500 nblist.py           # Neighbor list generation\n\u251c\u2500\u2500 optimizer.py        # Optimization algorithms\n\u251c\u2500\u2500 recip.py            # Reciprocal space calculations\n\u251c\u2500\u2500 spatial.py          # Spatial transformations\n\u2514\u2500\u2500 utils.py            # Utility functions\n</code></pre>"},{"location":"agents/AGENTS/#changelog","title":"Changelog","text":"<p>Add Changelog section with the following format in the end of each file in the subfolders of this path.</p> Date Changes Author yyyy-mm-dd Descriptions... xxx"},{"location":"agents/todo/","title":"torch-admp Development Plans","text":""},{"location":"agents/todo/#torch-admp-development-plans","title":"torch-admp Development Plans","text":""},{"location":"agents/todo/#features","title":"Features","text":""},{"location":"agents/todo/#restore-polarizable-electrode-package","title":"Restore polarizable electrode package","text":"<ul> <li>[x] reintroduce polarizable electrode module with batch support</li> <li>[x] add numerical uncertainty tests for polarizable electrode</li> </ul>"},{"location":"agents/todo/#constant-q-with-finite-field","title":"constant Q with finite field","text":"<ul> <li>[ ] implement ffield with conq</li> <li>[ ] add electrode tests for ConqInterface3DBIAS</li> </ul>"},{"location":"agents/todo/#support-batch-inference","title":"Support batch inference","text":"<ul> <li>[x] update docstrings for <code>BaseForceModule</code> and its derived classes, and specify the shape of input tensors</li> <li>[x] add shape verification for forward methods in for <code>BaseForceModule</code> and its derived classes</li> <li>[x] change required shapes of input tensors by adding the dimension of nframes</li> <li>[x] support multi-batch in PME</li> <li>[x] support multi-batch in QEq</li> </ul>"},{"location":"agents/todo/#documentation","title":"Documentation","text":""},{"location":"agents/todo/#set-up-basic-vibe-coding-structure","title":"Set up Basic Vibe Coding Structure","text":"<ul> <li>[x] Create docs/agents/ directory</li> <li>[x] Create AGENTS.md with project context</li> <li>[x] Create CHANGELOG in docs/ for the tagged versions</li> </ul>"},{"location":"agents/todo/#chores","title":"Chores","text":"<ul> <li>[x] update release in github and zenodo</li> </ul>"},{"location":"api/base_force/","title":"base_force","text":""},{"location":"api/base_force/#base_force","title":"base_force","text":""},{"location":"api/base_force/#torch_admp.base_force","title":"<code>torch_admp.base_force</code>","text":"<p>Base force module for torch-admp.</p> <p>This module provides the abstract base class for force modules in torch-admp, which defines the common interface for force calculations. It includes standardized input validation and unit conversion functionality.</p>"},{"location":"api/base_force/#torch_admp.base_force.BaseForceModule","title":"<code>BaseForceModule(units_dict: Optional[Dict] = None)</code>","text":"<p>               Bases: <code>Module</code>, <code>ABC</code></p> <p>Abstract base class for force modules in torch-admp.</p> <p>This class provides a common interface for force modules that take atomic positions and simulation box as input and return energy values. It is designed to be compatible with OpenMM-torch and sets up a constants library as a class attribute for necessary physical constants.</p> Notes <p>All subclasses must implement the _forward_impl method to define specific force calculations.</p> <p>Initialize the BaseForceModule.</p> PARAMETER DESCRIPTION <code>units_dict</code> <p>Dictionary containing unit conversion factors. If None, default units will be used.</p> <p> TYPE: <code>Optional[Dict]</code> DEFAULT: <code>None</code> </p> ATTRIBUTE DESCRIPTION <code>const_lib</code> <p>Library containing physical constants and unit conversions.</p> <p> TYPE: <code>TorchConstants</code> </p> Source code in <code>torch_admp/base_force.py</code> <pre><code>def __init__(self, units_dict: Optional[Dict] = None) -&gt; None:\n    \"\"\"\n    Initialize the BaseForceModule.\n\n    Parameters\n    ----------\n    units_dict : Optional[Dict], default=None\n        Dictionary containing unit conversion factors. If None, default units\n        will be used.\n\n    Attributes\n    ----------\n    const_lib : TorchConstants\n        Library containing physical constants and unit conversions.\n    \"\"\"\n    torch.nn.Module.__init__(self)\n    self.const_lib = TorchConstants(units_dict)\n</code></pre>"},{"location":"api/base_force/#torch_admp.base_force.BaseForceModule.forward","title":"<code>forward(positions: torch.Tensor, box: Optional[torch.Tensor], pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor, params: Dict[str, torch.Tensor]) -&gt; torch.Tensor</code>","text":"<p>Compute the potential energy for the given atomic configuration.</p> <p>This method validates input dimensions and then calls the abstract _forward_impl method which must be implemented by subclasses.</p> PARAMETER DESCRIPTION <code>positions</code> <p>Atomic positions with shape (natoms, 3). Each row contains the x, y, z coordinates of an atom.</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors with shape (3, 3). Each row represents a box vector. Required for periodic boundary conditions.</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>pairs</code> <p>Tensor of atom pairs with shape (n_pairs, 2). Each row contains the indices of two atoms that form a pair.</p> <p> TYPE: <code>Tensor</code> </p> <code>ds</code> <p>Distance tensor with shape (n_pairs,). Contains the distances between atom pairs specified in the pairs tensor.</p> <p> TYPE: <code>Tensor</code> </p> <code>buffer_scales</code> <p>Buffer scales for each pair with shape (n_pairs,). Contains values of 1 if i &lt; j else 0 for each pair, used for buffer management.</p> <p> TYPE: <code>Tensor</code> </p> <code>params</code> <p>Dictionary of parameters for the PES model. Common parameters include atomic charges, Lennard-Jones parameters, etc.</p> <p> TYPE: <code>Dict[str, Tensor]</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Scalar energy tensor representing the total potential energy of the system.</p> Source code in <code>torch_admp/base_force.py</code> <pre><code>def forward(\n    self,\n    positions: torch.Tensor,\n    box: Optional[torch.Tensor],\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n    params: Dict[str, torch.Tensor],\n) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the potential energy for the given atomic configuration.\n\n    This method validates input dimensions and then calls the abstract\n    _forward_impl method which must be implemented by subclasses.\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        Atomic positions with shape (natoms, 3). Each row contains the\n        x, y, z coordinates of an atom.\n    box : Optional[torch.Tensor]\n        Simulation box vectors with shape (3, 3). Each row represents a\n        box vector. Required for periodic boundary conditions.\n    pairs : torch.Tensor\n        Tensor of atom pairs with shape (n_pairs, 2). Each row contains\n        the indices of two atoms that form a pair.\n    ds : torch.Tensor\n        Distance tensor with shape (n_pairs,). Contains the distances\n        between atom pairs specified in the pairs tensor.\n    buffer_scales : torch.Tensor\n        Buffer scales for each pair with shape (n_pairs,). Contains values\n        of 1 if i &lt; j else 0 for each pair, used for buffer management.\n    params : Dict[str, torch.Tensor]\n        Dictionary of parameters for the PES model. Common parameters include\n        atomic charges, Lennard-Jones parameters, etc.\n\n    Returns\n    -------\n    torch.Tensor\n        Scalar energy tensor representing the total potential energy of the\n        system.\n    \"\"\"\n    # verify and standardize shape of input tensors\n    (\n        _positions,\n        _box,\n        _pairs,\n        _ds,\n        _buffer_scales,\n    ) = self.standardize_input_tensor(\n        positions,\n        box,\n        pairs,\n        ds,\n        buffer_scales,\n    )\n    nf = _positions.size(0)\n    _params = {k: v.reshape(nf, -1) for k, v in params.items()}\n\n    # Call the implementation in subclasses\n    # Use getattr to explicitly access the tensor and avoid type checker issues\n    length_coeff = getattr(self.const_lib, \"length_coeff\")\n    energy_coeff = getattr(self.const_lib, \"energy_coeff\")\n    energy = self._forward_impl(\n        _positions * length_coeff,\n        _box * length_coeff if _box is not None else None,\n        _pairs,\n        _ds * length_coeff,\n        _buffer_scales,\n        _params,\n    )\n    return energy / energy_coeff\n</code></pre>"},{"location":"api/base_force/#torch_admp.base_force.BaseForceModule.standardize_input_tensor","title":"<code>standardize_input_tensor(positions: torch.Tensor, box: Optional[torch.Tensor], pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor) -&gt; Tuple[torch.Tensor, Optional[torch.Tensor], torch.Tensor, torch.Tensor, torch.Tensor]</code>","text":"<p>Verify the shape of input tensors.</p> PARAMETER DESCRIPTION <code>positions</code> <p>Atomic positions with shape (natoms, 3) or (nframes, natoms, 3)</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors with shape (3, 3) or (nframes, 3, 3)</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>pairs</code> <p>Tensor of atom pairs with shape (n_pairs, 2) or (nframes, n_pairs, 2)</p> <p> TYPE: <code>Tensor</code> </p> <code>ds</code> <p>Distance tensor with shape (n_pairs,) or (nframes, n_pairs)</p> <p> TYPE: <code>Tensor</code> </p> <code>buffer_scales</code> <p>Buffer scales with shape (n_pairs,) or (nframes, n_pairs)</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tuple[Tensor, Optional[Tensor], Tensor, Tensor, Tensor]</code> <p>Standardized tensors with shapes: - positions: (nframes, natoms, 3) - box: (nframes, 3, 3) or None if input was None - pairs: (nframes, n_pairs, 2) - ds: (nframes, n_pairs) - buffer_scales: (nframes, n_pairs)</p> RAISES DESCRIPTION <code>ValueError</code> <p>If any tensor has incorrect dimensions</p> Source code in <code>torch_admp/base_force.py</code> <pre><code>def standardize_input_tensor(\n    self,\n    positions: torch.Tensor,\n    box: Optional[torch.Tensor],\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n) -&gt; Tuple[\n    torch.Tensor, Optional[torch.Tensor], torch.Tensor, torch.Tensor, torch.Tensor\n]:\n    \"\"\"\n    Verify the shape of input tensors.\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        Atomic positions with shape (natoms, 3) or (nframes, natoms, 3)\n    box : Optional[torch.Tensor]\n        Simulation box vectors with shape (3, 3) or (nframes, 3, 3)\n    pairs : torch.Tensor\n        Tensor of atom pairs with shape (n_pairs, 2) or (nframes, n_pairs, 2)\n    ds : torch.Tensor\n        Distance tensor with shape (n_pairs,) or (nframes, n_pairs)\n    buffer_scales : torch.Tensor\n        Buffer scales with shape (n_pairs,) or (nframes, n_pairs)\n\n    Returns\n    -------\n    Tuple[torch.Tensor, Optional[torch.Tensor], torch.Tensor, torch.Tensor, torch.Tensor]\n        Standardized tensors with shapes:\n        - positions: (nframes, natoms, 3)\n        - box: (nframes, 3, 3) or None if input was None\n        - pairs: (nframes, n_pairs, 2)\n        - ds: (nframes, n_pairs)\n        - buffer_scales: (nframes, n_pairs)\n\n    Raises\n    ------\n    ValueError\n        If any tensor has incorrect dimensions\n    \"\"\"\n    nframes = 1\n    # Check positions dimensions\n    if positions.dim() == 3:\n        # Batched input: (nframes, natoms, 3)\n        if positions.size(2) != 3:\n            raise ValueError(\n                f\"positions must have shape (nframes, natoms, 3), got {positions.shape}\"\n            )\n        nframes = positions.size(0)\n    elif positions.dim() == 2:\n        # Single system: (natoms, 3)\n        if positions.size(1) != 3:\n            raise ValueError(\n                f\"positions must have shape (natoms, 3), got {positions.shape}\"\n            )\n        positions = positions.unsqueeze(0)\n    else:\n        raise ValueError(\n            f\"positions must be 2D or 3D tensor, got {positions.dim()}D\"\n        )\n\n    # Check box dimensions if provided\n    if box is not None:\n        if box.dim() == 3:\n            # Batched input: (nframes, 3, 3)\n            if box.shape[1:] != (3, 3):\n                raise ValueError(\n                    f\"box must have shape (nframes, 3, 3), got {box.shape}\"\n                )\n            if box.size(0) != nframes:\n                raise ValueError(\n                    f\"box is expected to have {nframes} frame(s), got {box.size(0)}\"\n                )\n        elif box.dim() == 2:\n            # Single system: (3, 3)\n            if box.shape != (3, 3):\n                raise ValueError(f\"box must have shape (3, 3), got {box.shape}\")\n            if nframes != 1:\n                raise ValueError(\n                    f\"box must include a frame dimension when positions has {nframes} frames\"\n                )\n            box = box.unsqueeze(0)\n        else:\n            raise ValueError(f\"box must be 2D or 3D tensor, got {box.dim()}D\")\n\n    # Check pairs dimensions\n    if pairs.dim() == 3:\n        # Batched input: (nframes, n_pairs, 2)\n        if pairs.size(2) != 2:\n            raise ValueError(\n                f\"pairs must have shape (nframes, n_pairs, 2), got {pairs.shape}\"\n            )\n        if pairs.size(0) != nframes:\n            raise ValueError(\n                f\"pairs is expected to have {nframes} frame(s), got {pairs.size(0)}\"\n            )\n    elif pairs.dim() == 2:\n        # Single system: (n_pairs, 2)\n        if pairs.size(1) != 2:\n            raise ValueError(\n                f\"pairs must have shape (n_pairs, 2), got {pairs.shape}\"\n            )\n        if nframes != 1:\n            raise ValueError(\n                f\"pairs must include a frame dimension when positions has {nframes} frames\"\n            )\n        pairs = pairs.unsqueeze(0)\n    else:\n        raise ValueError(f\"pairs must be 2D or 3D tensor, got {pairs.dim()}D\")\n    n_pairs = pairs.size(-2)\n\n    # Check ds dimensions\n    if ds.dim() == 2:\n        # Batched input: (nframes, n_pairs)\n        if ds.size(0) != nframes:\n            raise ValueError(\n                f\"ds is expected to have {nframes} frame(s), got {ds.size(0)}\"\n            )\n        if ds.size(1) != n_pairs:\n            raise ValueError(\n                f\"ds is expected to have {n_pairs} pairs(s), got {ds.size(1)}\"\n            )\n    elif ds.dim() == 1:\n        # Single system: (n_pairs,)\n        if ds.size(0) != n_pairs:\n            raise ValueError(\n                f\"ds is expected to have {n_pairs} pairs(s), got {ds.size(0)}\"\n            )\n        if nframes != 1:\n            raise ValueError(\n                f\"ds must include a frame dimension when positions has {nframes} frames\"\n            )\n        ds = ds.unsqueeze(0)\n    else:\n        raise ValueError(f\"ds must be 1D or 2D tensor, got {ds.dim()}D\")\n\n    # Check buffer_scales dimensions\n    if buffer_scales.dim() == 2:\n        # Batched input: (nframes, n_pairs)\n        if buffer_scales.size(0) != nframes:\n            raise ValueError(\n                f\"buffer_scales is expected to have {nframes} frame(s), got {buffer_scales.size(0)}\"\n            )\n        if buffer_scales.size(1) != n_pairs:\n            raise ValueError(\n                f\"buffer_scales is expected to have {n_pairs} pairs(s), got {buffer_scales.size(1)}\"\n            )\n    elif buffer_scales.dim() == 1:\n        # Single system: (n_pairs,)\n        if buffer_scales.size(0) != n_pairs:\n            raise ValueError(\n                f\"buffer_scales is expected to have {n_pairs} pairs(s), got {buffer_scales.size(0)}\"\n            )\n        if nframes != 1:\n            raise ValueError(\n                f\"buffer_scales must include a frame dimension when positions has {nframes} frames\"\n            )\n        buffer_scales = buffer_scales.unsqueeze(0)\n    else:\n        raise ValueError(\n            f\"buffer_scales must be 1D or 2D tensor, got {buffer_scales.dim()}D\"\n        )\n\n    return positions, box, pairs, ds, buffer_scales\n</code></pre>"},{"location":"api/electrode/","title":"electrode","text":""},{"location":"api/electrode/#electrode","title":"electrode","text":""},{"location":"api/electrode/#torch_admp.electrode","title":"<code>torch_admp.electrode</code>","text":"<p>Electrode models and constraints for molecular dynamics simulations.</p> <p>This module implements polarizable electrode models and constraint handling for constant potential (CONP) and constant charge (CONQ) electrode simulations. It provides functionality for charge equilibration (QEq) with electrode constraints, finite field calculations, and integration with LAMMPS electrode fix implementations.</p>"},{"location":"api/electrode/#torch_admp.electrode.LAMMPSElectrodeConstraint","title":"<code>LAMMPSElectrodeConstraint(indices: Union[List[int], np.ndarray], mode: str, value: float, eta: float, chi: float = 0.0, hardness: float = 0.0, ffield: bool = False)</code>","text":"<p>Register the electrode constraint for LAMMPS</p> PARAMETER DESCRIPTION <code>indices</code> <p>indices of the atoms in constraint</p> <p> TYPE: <code>Union[List[int], ndarray]</code> </p> <code>mode</code> <p>conp or conq</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>value of the constraint (potential or charge)</p> <p> TYPE: <code>float</code> </p> <code>eta</code> <p>eta as used in LAMMPS (in length^-1)</p> <p> TYPE: <code>float</code> </p> <code>chi</code> <p>electronegativity [V] default: 0.0 (single element)</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>hardness</code> <p>atomic hardness [V/e] default: 0.0</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>ffield</code> <p>if used as ffield group</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Initialize a LAMMPSElectrodeConstraint instance.</p> PARAMETER DESCRIPTION <code>indices</code> <p>indices of the atoms in constraint</p> <p> TYPE: <code>Union[List[int], ndarray]</code> </p> <code>mode</code> <p>conp or conq</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>value of the constraint (potential or charge)</p> <p> TYPE: <code>float</code> </p> <code>eta</code> <p>eta as used in LAMMPS (in length^-1)</p> <p> TYPE: <code>float</code> </p> <code>chi</code> <p>electronegativity [V], by default 0.0 (single element)</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>hardness</code> <p>atomic hardness [V/e], by default 0.0</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>ffield</code> <p>if used as ffield group, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>torch_admp/electrode.py</code> <pre><code>def __init__(\n    self,\n    indices: Union[List[int], np.ndarray],\n    mode: str,\n    value: float,\n    eta: float,\n    chi: float = 0.0,\n    hardness: float = 0.0,\n    ffield: bool = False,\n) -&gt; None:\n    \"\"\"Initialize a LAMMPSElectrodeConstraint instance.\n\n    Parameters\n    ----------\n    indices : Union[List[int], np.ndarray]\n        indices of the atoms in constraint\n    mode : str\n        conp or conq\n    value : float\n        value of the constraint (potential or charge)\n    eta : float\n        eta as used in LAMMPS (in length^-1)\n    chi : float, optional\n        electronegativity [V], by default 0.0 (single element)\n    hardness : float, optional\n        atomic hardness [V/e], by default 0.0\n    ffield : bool, optional\n        if used as ffield group, by default False\n    \"\"\"\n    self.indices = np.array(indices, dtype=int)\n    # assert one dimension array\n    assert self.indices.ndim == 1\n\n    self.mode = mode\n    assert mode in [\"conp\", \"conq\"], f\"mode {mode} not supported\"\n\n    self.value = value\n    self.eta = eta\n    self.hardness = hardness\n    self.chi = chi\n    self.ffield = ffield\n</code></pre>"},{"location":"api/electrode/#torch_admp.electrode.PolarizableElectrode","title":"<code>PolarizableElectrode(rcut: float, ethresh: float = 1e-05, **kwargs)</code>","text":"<p>               Bases: <code>QEqForceModule</code></p> <p>Polarizable Electrode Model</p> PARAMETER DESCRIPTION <code>rcut</code> <p>cutoff radius for short-range interactions</p> <p> TYPE: <code>float</code> </p> <code>ethresh</code> <p>energy threshold for electrostatic interaction, by default 1e-5</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-05</code> </p> <code>**kwargs</code> <p>Additional keyword arguments passed to parent class</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <p>Initialize a PolarizableElectrode instance.</p> PARAMETER DESCRIPTION <code>rcut</code> <p>cutoff radius for short-range interactions</p> <p> TYPE: <code>float</code> </p> <code>ethresh</code> <p>energy threshold for electrostatic interaction, by default 1e-5</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-05</code> </p> <code>**kwargs</code> <p>Additional keyword arguments passed to parent class</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> Source code in <code>torch_admp/electrode.py</code> <pre><code>def __init__(self, rcut: float, ethresh: float = 1e-5, **kwargs) -&gt; None:\n    \"\"\"Initialize a PolarizableElectrode instance.\n\n    Parameters\n    ----------\n    rcut : float\n        cutoff radius for short-range interactions\n    ethresh : float, optional\n        energy threshold for electrostatic interaction, by default 1e-5\n    **kwargs : dict\n        Additional keyword arguments passed to parent class\n    \"\"\"\n    super().__init__(rcut, ethresh, **kwargs)\n</code></pre>"},{"location":"api/electrode/#torch_admp.electrode.PolarizableElectrode.calc_coulomb_potential","title":"<code>calc_coulomb_potential(electrode_mask: torch.Tensor | None, positions: torch.Tensor, box: torch.Tensor, eta: torch.Tensor, charges: torch.Tensor, pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]</code>","text":"<p>Calculate the vector b and add it in chi</p> Source code in <code>torch_admp/electrode.py</code> <pre><code>@torch.jit.export\ndef calc_coulomb_potential(\n    self,\n    electrode_mask: torch.Tensor | None,\n    positions: torch.Tensor,\n    box: torch.Tensor,\n    eta: torch.Tensor,\n    charges: torch.Tensor,\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Calculate the vector b and add it in chi\n    \"\"\"\n    if electrode_mask is None:\n        modified_charges = charges.clone()\n    else:\n        modified_charges = torch.where(electrode_mask == 0, charges, 0.0)\n    modified_charges.requires_grad_(True)\n    energy = self.forward(\n        positions,\n        box,\n        pairs,\n        ds,\n        buffer_scales,\n        {\n            \"charge\": modified_charges,\n            \"eta\": eta,\n            \"hardness\": torch.zeros_like(eta),\n            \"chi\": torch.zeros_like(eta),\n        },\n    )\n    # single frame\n    assert energy.size(0) == 1\n    elec_potential = calc_grads(energy[0], modified_charges)\n    return elec_potential, energy\n</code></pre>"},{"location":"api/electrode/#torch_admp.electrode.PolarizableElectrode.coulomb_calculator","title":"<code>coulomb_calculator(positions: torch.Tensor, box: torch.Tensor, charges: torch.Tensor, eta: torch.Tensor, pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor, efield: Optional[torch.Tensor] = None) -&gt; Tuple[torch.Tensor, torch.Tensor]</code>","text":"<p>Compute the Coulomb force for the system</p> Source code in <code>torch_admp/electrode.py</code> <pre><code>@torch.jit.export\ndef coulomb_calculator(\n    self,\n    positions: torch.Tensor,\n    box: torch.Tensor,\n    charges: torch.Tensor,\n    eta: torch.Tensor,\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n    efield: Optional[torch.Tensor] = None,\n) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Compute the Coulomb force for the system\n    \"\"\"\n    device = positions.device\n    dtype = positions.dtype\n\n    _energy = self.forward(\n        positions,\n        box,\n        pairs,\n        ds,\n        buffer_scales,\n        {\n            \"charge\": charges,\n            \"eta\": eta,\n            \"hardness\": torch.zeros_like(eta),\n            \"chi\": torch.zeros_like(eta),\n        },\n    )\n    # single frame\n    assert _energy.size(0) == 1\n    energy = _energy[0]\n    if not positions.requires_grad:\n        raise ValueError(\n            \"positions must require grad to compute forces; call positions.requires_grad_(True)\"\n        )\n    forces = -calc_grads(energy, positions)\n\n    if efield is not None:\n        _efield = torch.zeros(3, dtype=dtype, device=device)\n        _efield[self.slab_axis] = efield[self.slab_axis]\n        forces = forces + charges.unsqueeze(1) * _efield\n        energy = energy + torch.sum(\n            _efield.reshape(1, 3) * charges.unsqueeze(1) * positions\n        )\n    return energy, forces\n</code></pre>"},{"location":"api/electrode/#torch_admp.electrode.charge_optimization","title":"<code>charge_optimization(calculator: PolarizableElectrode, positions: torch.Tensor, box: torch.Tensor, charges: torch.Tensor, pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor, electrode_mask: torch.Tensor, eta: torch.Tensor, chi: torch.Tensor, hardness: torch.Tensor, constraint_matrix: Optional[torch.Tensor], constraint_vals: Optional[torch.Tensor], ffield_electrode_mask: Optional[torch.Tensor], ffield_potential: Optional[torch.Tensor], method: str = 'lbfgs')</code>","text":"<p>Perform QEq charge optimization</p> Source code in <code>torch_admp/electrode.py</code> <pre><code>def charge_optimization(\n    calculator: PolarizableElectrode,\n    positions: torch.Tensor,\n    box: torch.Tensor,\n    charges: torch.Tensor,\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n    electrode_mask: torch.Tensor,\n    eta: torch.Tensor,\n    chi: torch.Tensor,\n    hardness: torch.Tensor,\n    constraint_matrix: Optional[torch.Tensor],\n    constraint_vals: Optional[torch.Tensor],\n    ffield_electrode_mask: Optional[torch.Tensor],\n    ffield_potential: Optional[torch.Tensor],\n    method: str = \"lbfgs\",\n):\n    \"\"\"\n    Perform QEq charge optimization\n    \"\"\"\n    device = positions.device\n    dtype = positions.dtype\n\n    if electrode_mask.sum() == 0:\n        efield = None\n        return charges[electrode_mask], efield\n    # ffield mode\n    if ffield_electrode_mask is not None and calculator.slab_corr:\n        raise ValueError(\"Slab correction and finite field cannot be used together.\")\n\n    # electrode + electrolyte\n    chi_chemical = chi\n    chi_elec, _energy = calculator.calc_coulomb_potential(\n        electrode_mask,\n        positions,\n        box,\n        eta,\n        charges,\n        pairs,\n        ds,\n        buffer_scales,\n    )\n\n    # electrode\n    chi = chi_chemical + chi_elec\n    chi = chi[electrode_mask]\n    if ffield_electrode_mask is not None:\n        chi_ffield, _efield = finite_field_add_chi(\n            positions,\n            box,\n            ffield_electrode_mask,\n            ffield_potential,\n            calculator.slab_axis,\n        )\n        chi = chi + chi_ffield\n\n        efield = torch.zeros(3, dtype=dtype, device=device)\n        efield[calculator.slab_axis] = _efield\n    else:\n        efield = None\n\n    pair_mask = electrode_mask[pairs[:, 0]] &amp; electrode_mask[pairs[:, 1]]\n    # electrode_indices find the indices of electrode_mask which is True\n    electrode_indices = torch.arange(\n        electrode_mask.size(0), device=device, dtype=torch.long\n    )[electrode_mask]\n    mapping = torch.zeros(electrode_mask.size(0), dtype=torch.long, device=device)\n    mapping[electrode_indices] = torch.arange(\n        electrode_mask.sum().item(), device=device, dtype=torch.long\n    )\n    pair_i = pairs[pair_mask][:, 0]\n    pair_j = pairs[pair_mask][:, 1]\n    new_pairs = torch.stack([mapping[pair_i], mapping[pair_j]], dim=1)\n\n    # common var &amp; for matrix inversion\n    kwargs = {\n        \"module\": calculator,\n        \"positions\": positions[electrode_mask],\n        \"box\": box,\n        \"chi\": chi,\n        \"hardness\": hardness[electrode_mask],\n        \"eta\": eta[electrode_mask],\n        \"pairs\": new_pairs,\n        \"ds\": ds[pair_mask],\n        \"buffer_scales\": buffer_scales[pair_mask],\n        \"constraint_matrix\": constraint_matrix,\n        \"constraint_vals\": constraint_vals,\n    }\n\n    if method == \"matinv\":\n        _energy, _q_opt = matinv_optimize(**kwargs)\n    else:\n        # projected gradient\n        kwargs.update(\n            {\n                \"q0\": charges[electrode_mask].reshape(-1, 1),\n                \"method\": method,\n                \"reinit_q\": True,\n            }\n        )\n\n        _energy, _q_opt = pgrad_optimize(**kwargs)\n\n    return _q_opt, efield\n</code></pre>"},{"location":"api/electrode/#torch_admp.electrode.finite_field_add_chi","title":"<code>finite_field_add_chi(positions: torch.Tensor, box: torch.Tensor, ffield_electrode_mask: torch.Tensor, ffield_potential: torch.Tensor, slab_axis: int = 2)</code>","text":"<p>Compute the correction term for the finite field</p> <p>potential need to be same in the electrode_mask potential drop is potential[0] - potential[1]</p> Source code in <code>torch_admp/electrode.py</code> <pre><code>@torch.jit.script\ndef finite_field_add_chi(\n    positions: torch.Tensor,\n    box: torch.Tensor,\n    ffield_electrode_mask: torch.Tensor,\n    ffield_potential: torch.Tensor,\n    slab_axis: int = 2,\n):\n    \"\"\"\n    Compute the correction term for the finite field\n\n    potential need to be same in the electrode_mask\n    potential drop is potential[0] - potential[1]\n    \"\"\"\n    assert positions.dim() == 2\n    assert box.dim() == 2\n    assert ffield_potential.dim() == 1\n    assert ffield_electrode_mask.dim() == 2\n\n    assert ffield_electrode_mask.shape[0] == 2\n    assert positions.shape[1] == 3\n\n    n_atoms = positions.shape[0]\n    assert ffield_electrode_mask.shape[1] == n_atoms\n    assert ffield_potential.shape[0] == 2\n\n    first_electrode_mask = ffield_electrode_mask[0]\n    second_electrode_mask = ffield_electrode_mask[1]\n\n    potential_drop = ffield_potential[0] - ffield_potential[1]\n\n    ## find max position in slab_axis for left electrode\n    max_pos_first = torch.max(positions[first_electrode_mask, slab_axis])\n    max_pos_second = torch.max(positions[second_electrode_mask, slab_axis])\n    # only valid for orthogonality cell\n    lz = box[slab_axis][slab_axis]\n    normalized_positions = positions[:, slab_axis] / lz\n    ### lammps fix electrode implementation\n    ### cos180(-1) or cos0(1) for E(delta_psi/(r1-r2)) and r\n    if max_pos_first &gt; max_pos_second:\n        zprd_offset = -1 * -1 * normalized_positions\n        efield = -1 * potential_drop / lz\n    else:\n        zprd_offset = -1 * normalized_positions\n        efield = potential_drop / lz\n\n    potential = potential_drop * zprd_offset\n    mask = first_electrode_mask | second_electrode_mask\n    return potential[mask], efield\n</code></pre>"},{"location":"api/electrode/#torch_admp.electrode.infer","title":"<code>infer(calculator: PolarizableElectrode, positions: torch.Tensor, box: torch.Tensor, charges: torch.Tensor, pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor, electrode_mask: torch.Tensor, eta: torch.Tensor, chi: torch.Tensor, hardness: torch.Tensor, constraint_matrix: Optional[torch.Tensor], constraint_vals: Optional[torch.Tensor], ffield_electrode_mask: Optional[torch.Tensor], ffield_potential: Optional[torch.Tensor], method: str = 'lbfgs')</code>","text":"<p>Perform electrode charge optimization and compute energy and forces.</p> PARAMETER DESCRIPTION <code>calculator</code> <p>The polarizable electrode calculator instance</p> <p> TYPE: <code>PolarizableElectrode</code> </p> <code>positions</code> <p>Atomic positions with shape (n_atoms, 3)</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors with shape (3, 3)</p> <p> TYPE: <code>Tensor</code> </p> <code>charges</code> <p>Initial atomic charges with shape (n_atoms,)</p> <p> TYPE: <code>Tensor</code> </p> <code>pairs</code> <p>Neighbor pair list with shape (n_pairs, 2)</p> <p> TYPE: <code>Tensor</code> </p> <code>ds</code> <p>Distances between atom pairs with shape (n_pairs,)</p> <p> TYPE: <code>Tensor</code> </p> <code>buffer_scales</code> <p>Buffer scaling factors with shape (n_pairs,)</p> <p> TYPE: <code>Tensor</code> </p> <code>electrode_mask</code> <p>Boolean mask identifying electrode atoms with shape (n_atoms,)</p> <p> TYPE: <code>Tensor</code> </p> <code>eta</code> <p>Slater-type orbital decay parameters with shape (n_atoms,)</p> <p> TYPE: <code>Tensor</code> </p> <code>chi</code> <p>Electronegativity parameters with shape (n_atoms,)</p> <p> TYPE: <code>Tensor</code> </p> <code>hardness</code> <p>Atomic hardness parameters with shape (n_atoms,)</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_matrix</code> <p>Matrix of constraint equations</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>constraint_vals</code> <p>Values of constraint equations</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>ffield_electrode_mask</code> <p>Mask for finite field electrode groups</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>ffield_potential</code> <p>Applied potential for finite field calculations</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>method</code> <p>Optimization method ('lbfgs' or 'matinv'), by default \"lbfgs\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'lbfgs'</code> </p> RETURNS DESCRIPTION <code>Tuple[Tensor, Tensor, Tensor]</code> <p>A tuple containing: - energy: Total system energy - forces: Forces on all atoms - q_opt: Optimized charges for all atoms</p> Source code in <code>torch_admp/electrode.py</code> <pre><code>def infer(\n    calculator: PolarizableElectrode,\n    positions: torch.Tensor,\n    box: torch.Tensor,\n    charges: torch.Tensor,\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n    electrode_mask: torch.Tensor,\n    eta: torch.Tensor,\n    chi: torch.Tensor,\n    hardness: torch.Tensor,\n    constraint_matrix: Optional[torch.Tensor],\n    constraint_vals: Optional[torch.Tensor],\n    ffield_electrode_mask: Optional[torch.Tensor],\n    ffield_potential: Optional[torch.Tensor],\n    method: str = \"lbfgs\",\n):\n    \"\"\"Perform electrode charge optimization and compute energy and forces.\n\n    Parameters\n    ----------\n    calculator : PolarizableElectrode\n        The polarizable electrode calculator instance\n    positions : torch.Tensor\n        Atomic positions with shape (n_atoms, 3)\n    box : torch.Tensor\n        Simulation box vectors with shape (3, 3)\n    charges : torch.Tensor\n        Initial atomic charges with shape (n_atoms,)\n    pairs : torch.Tensor\n        Neighbor pair list with shape (n_pairs, 2)\n    ds : torch.Tensor\n        Distances between atom pairs with shape (n_pairs,)\n    buffer_scales : torch.Tensor\n        Buffer scaling factors with shape (n_pairs,)\n    electrode_mask : torch.Tensor\n        Boolean mask identifying electrode atoms with shape (n_atoms,)\n    eta : torch.Tensor\n        Slater-type orbital decay parameters with shape (n_atoms,)\n    chi : torch.Tensor\n        Electronegativity parameters with shape (n_atoms,)\n    hardness : torch.Tensor\n        Atomic hardness parameters with shape (n_atoms,)\n    constraint_matrix : Optional[torch.Tensor]\n        Matrix of constraint equations\n    constraint_vals : Optional[torch.Tensor]\n        Values of constraint equations\n    ffield_electrode_mask : Optional[torch.Tensor]\n        Mask for finite field electrode groups\n    ffield_potential : Optional[torch.Tensor]\n        Applied potential for finite field calculations\n    method : str, optional\n        Optimization method ('lbfgs' or 'matinv'), by default \"lbfgs\"\n\n    Returns\n    -------\n    Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n        A tuple containing:\n        - energy: Total system energy\n        - forces: Forces on all atoms\n        - q_opt: Optimized charges for all atoms\n    \"\"\"\n    (\n        _positions,\n        _box,\n        _pairs,\n        _ds,\n        _buffer_scales,\n    ) = calculator.standardize_input_tensor(\n        positions,\n        box,\n        pairs,\n        ds,\n        buffer_scales,\n    )\n\n    # single frame\n    assert _positions.shape[0] == 1\n    assert _box is not None\n\n    _q_opt, efield = charge_optimization(\n        calculator,\n        _positions[0],\n        _box[0],\n        charges,\n        _pairs[0],\n        _ds[0],\n        _buffer_scales[0],\n        electrode_mask,\n        eta,\n        chi,\n        hardness,\n        constraint_matrix,\n        constraint_vals,\n        ffield_electrode_mask,\n        ffield_potential,\n        method,\n    )\n\n    q_opt = charges.clone()\n    q_opt[electrode_mask] = _q_opt\n\n    energy, forces = calculator.coulomb_calculator(\n        positions=positions,\n        box=box,\n        charges=q_opt,\n        eta=eta,\n        pairs=pairs,\n        ds=ds,\n        buffer_scales=buffer_scales,\n        efield=efield,\n    )\n\n    return energy, forces, q_opt\n</code></pre>"},{"location":"api/electrode/#torch_admp.electrode.setup_from_lammps","title":"<code>setup_from_lammps(n_atoms: int, constraint_list: List[LAMMPSElectrodeConstraint], symm: bool = False)</code>","text":"<p>Generate input data based on lammps-like constraint definitions</p> Source code in <code>torch_admp/electrode.py</code> <pre><code>def setup_from_lammps(\n    n_atoms: int,\n    constraint_list: List[LAMMPSElectrodeConstraint],\n    symm: bool = False,\n):\n    \"\"\"\n    Generate input data based on lammps-like constraint definitions\n    \"\"\"\n    device = env.DEVICE\n    dtype = env.GLOBAL_PT_FLOAT_PRECISION\n\n    mask = np.zeros(n_atoms, dtype=bool)\n\n    eta = np.zeros(n_atoms)\n    chi = np.zeros(n_atoms)\n    hardness = np.zeros(n_atoms)\n\n    constraint_matrix = []\n    constraint_vals = []\n    ffield_electrode_mask = []\n    ffield_potential = []\n\n    for constraint in constraint_list:\n        mask[constraint.indices] = True\n        eta[constraint.indices] = 1 / constraint.eta * np.sqrt(2) / 2.0\n        chi[constraint.indices] = constraint.chi\n        hardness[constraint.indices] = constraint.hardness\n        if constraint.mode == \"conq\":\n            if symm:\n                raise AttributeError(\n                    \"symm should be False for conq, user can implement symm by conq\"\n                )\n            if constraint.ffield:\n                raise AttributeError(\"ffield with conq has not been implemented yet\")\n            constraint_matrix.append(np.zeros((1, n_atoms)))\n            constraint_matrix[-1][0, constraint.indices] = 1.0\n            constraint_vals.append(constraint.value)\n        if constraint.mode == \"conp\":\n            chi[constraint.indices] -= constraint.value\n        if constraint.ffield:\n            ffield_electrode_mask.append(np.zeros((1, n_atoms)))\n            ffield_electrode_mask[-1][0, constraint.indices] = 1.0\n            ffield_potential.append(constraint.value)\n\n    if len(ffield_electrode_mask) == 0:\n        ffield_electrode_mask = None\n        ffield_potential = None\n    elif len(ffield_electrode_mask) == 2:\n        ffield_electrode_mask = torch.tensor(\n            np.concatenate(ffield_electrode_mask, axis=0),\n            dtype=torch.bool,\n            device=device,\n        )\n        ffield_potential = to_torch_tensor(np.array(ffield_potential)).to(dtype)\n        # if using ffield, electroneutrality should be enforced\n        # symm = True\n    else:\n        raise AttributeError(\"number of ffield group should be 0 or 2\")\n\n    if symm:\n        constraint_matrix.append(np.ones((1, n_atoms)))\n        constraint_vals.append(0.0)\n\n    if len(constraint_matrix) &gt; 0:\n        constraint_matrix = to_torch_tensor(\n            np.concatenate(constraint_matrix, axis=0)[:, mask]\n        )\n        constraint_vals = to_torch_tensor(np.array(constraint_vals))\n    else:\n        number_electrode = mask.sum()\n        constraint_matrix = torch.zeros((0, number_electrode), device=device)\n        constraint_vals = torch.zeros(0, device=device)\n\n    return (\n        to_torch_tensor(mask),\n        to_torch_tensor(eta).to(dtype),\n        to_torch_tensor(chi).to(dtype),\n        to_torch_tensor(hardness).to(dtype),\n        constraint_matrix.to(dtype),\n        constraint_vals.to(dtype),\n        ffield_electrode_mask,\n        ffield_potential,\n    )\n</code></pre>"},{"location":"api/nblist/","title":"nblist","text":""},{"location":"api/nblist/#nblist","title":"nblist","text":""},{"location":"api/nblist/#torch_admp.nblist","title":"<code>torch_admp.nblist</code>","text":"<p>Neighbor list utilities for torch-admp.</p> <p>This module provides functions and classes for building and managing neighbor lists used in molecular simulations, including implementations for both periodic and non-periodic boundary conditions.</p>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList","title":"<code>TorchNeighborList(cutoff: float)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Torch-compatible neighbor list implementation.</p> <p>Adapted from the curator library for JIT compatibility: https://github.com/Yangxinsix/curator/tree/master curator.data.TorchNeighborList</p> <p>Initialize the TorchNeighborList.</p> PARAMETER DESCRIPTION <code>cutoff</code> <p>Cutoff distance for neighbor list construction</p> <p> TYPE: <code>float</code> </p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def __init__(\n    self,\n    cutoff: float,\n) -&gt; None:\n    \"\"\"\n    Initialize the TorchNeighborList.\n\n    Parameters\n    ----------\n    cutoff : float\n        Cutoff distance for neighbor list construction\n    \"\"\"\n    super().__init__()\n    self.cutoff = cutoff\n    _t = torch.arange(-1, 2, device=DEVICE)\n    self.disp_mat = torch.cartesian_prod(_t, _t, _t)\n\n    self.pairs = torch.jit.annotate(\n        torch.Tensor, torch.empty(1, dtype=torch.long, device=DEVICE)\n    )\n    self.buffer_scales = torch.jit.annotate(\n        torch.Tensor, torch.empty(1, dtype=torch.long, device=DEVICE)\n    )\n    self.ds = torch.jit.annotate(\n        torch.Tensor, torch.empty(1, dtype=GLOBAL_PT_FLOAT_PRECISION, device=DEVICE)\n    )\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList.forward","title":"<code>forward(positions: torch.Tensor, box: Optional[torch.Tensor] = None) -&gt; torch.Tensor</code>","text":"<p>Compute neighbor list for given positions.</p> PARAMETER DESCRIPTION <code>positions</code> <p>Atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors, by default None</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Tensor of atom pairs</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def forward(\n    self, positions: torch.Tensor, box: Optional[torch.Tensor] = None\n) -&gt; torch.Tensor:\n    \"\"\"\n    Compute neighbor list for given positions.\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        Atomic positions\n    box : Optional[torch.Tensor], optional\n        Simulation box vectors, by default None\n\n    Returns\n    -------\n    torch.Tensor\n        Tensor of atom pairs\n    \"\"\"\n    if box is None:\n        pairs = self.forward_obc(positions)\n        pbc_flag = False\n    else:\n        check_cutoff(box, self.cutoff)\n        pairs = self.forward_pbc(positions, box)\n        pbc_flag = True\n\n    self.pairs = pairs\n    self.buffer_scales = self.pairs_buffer_scales(pairs)\n    self.ds = self.pairs_ds(positions, pairs, box, pbc_flag)\n    return pairs\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList.forward_obc","title":"<code>forward_obc(positions: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Compute neighbor list for open boundary conditions.</p> PARAMETER DESCRIPTION <code>positions</code> <p>Atomic positions</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Tensor of atom pairs</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def forward_obc(self, positions: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Compute neighbor list for open boundary conditions.\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        Atomic positions\n\n    Returns\n    -------\n    torch.Tensor\n        Tensor of atom pairs\n    \"\"\"\n    dist_mat = torch.cdist(positions, positions)\n    mask = dist_mat &lt; self.cutoff\n    mask.fill_diagonal_(False)\n    pairs = torch.argwhere(mask)\n    return pairs.to(torch.long)\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList.forward_pbc","title":"<code>forward_pbc(positions: torch.Tensor, box: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Compute neighbor list for periodic boundary conditions.</p> PARAMETER DESCRIPTION <code>positions</code> <p>Atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Tensor of atom pairs</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def forward_pbc(\n    self,\n    positions: torch.Tensor,\n    box: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Compute neighbor list for periodic boundary conditions.\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        Atomic positions\n    box : torch.Tensor\n        Simulation box vectors\n\n    Returns\n    -------\n    torch.Tensor\n        Tensor of atom pairs\n    \"\"\"\n    # calculate padding size. It is useful for all kinds of cells\n    wrapped_pos = self.wrap_positions(positions, box)\n    norm_a = torch.cross(box[1], box[2], dim=-1).norm()\n    norm_b = torch.cross(box[2], box[0], dim=-1).norm()\n    norm_c = torch.cross(box[0], box[1], dim=-1).norm()\n    volume = torch.sum(box[0] * torch.cross(box[1], box[2], dim=-1))\n\n    # get padding size and padding matrix to generate padded atoms. Use minimal image convention\n    padding_a = torch.ceil(self.cutoff * norm_a / volume).long()\n    padding_b = torch.ceil(self.cutoff * norm_b / volume).long()\n    padding_c = torch.ceil(self.cutoff * norm_c / volume).long()\n\n    padding_mat = torch.cartesian_prod(\n        torch.arange(\n            -padding_a.item(), padding_a.item() + 1, device=padding_a.device\n        ),\n        torch.arange(\n            -padding_b.item(), padding_b.item() + 1, device=padding_a.device\n        ),\n        torch.arange(\n            -padding_c.item(), padding_c.item() + 1, device=padding_a.device\n        ),\n    ).to(box.dtype)\n    padding_size = (2 * padding_a + 1) * (2 * padding_b + 1) * (2 * padding_c + 1)\n\n    # padding, calculating box numbers and shapes\n    padded_pos = (wrapped_pos.unsqueeze(1) + padding_mat @ box).view(-1, 3)\n    padded_cpos = torch.floor(padded_pos / self.cutoff).long()\n    corner = torch.min(padded_cpos, dim=0)[0]  # the box at the corner\n    padded_cpos -= corner\n    c_pos_shap = torch.max(padded_cpos, dim=0)[0] + 1  # c_pos starts from 0\n    num_cells = int(torch.prod(c_pos_shap).item())\n    count_vec = torch.ones_like(c_pos_shap)\n    count_vec[0] = c_pos_shap[1] * c_pos_shap[2]\n    count_vec[1] = c_pos_shap[2]\n\n    padded_cind = torch.sum(padded_cpos * count_vec, dim=1)\n    padded_gind = (\n        torch.arange(padded_cind.shape[0], device=count_vec.device) + 1\n    )  # global index of padded atoms, starts from 1\n    padded_rind = torch.arange(\n        positions.shape[0], device=count_vec.device\n    ).repeat_interleave(padding_size)  # local index of padded atoms in the unit box\n\n    # atom box position and index\n    atom_cpos = torch.floor(wrapped_pos / self.cutoff).long() - corner\n    # atom neighbors' box position and index\n    # Ensure disp_mat is on the same device as atom_cpos\n    # Use type: ignore to work around type checking issue with registered buffers\n    disp_mat_device = self.disp_mat.to(atom_cpos.device)  # type: ignore\n    atom_cnpos = atom_cpos.unsqueeze(1) + disp_mat_device  # type: ignore\n    atom_cnind = torch.sum(atom_cnpos * count_vec, dim=-1)\n\n    # construct a C x N matrix to store the box atom list, this is the most expensive part.\n    padded_cind_sorted, padded_cind_args = torch.sort(padded_cind, stable=True)\n    cell_ind, cell_atom_num = torch.unique_consecutive(\n        padded_cind_sorted, return_counts=True\n    )\n    max_cell_anum = int(cell_atom_num.max().item())\n    global_cell_ind = torch.zeros(\n        (num_cells, max_cell_anum, 2),\n        dtype=c_pos_shap.dtype,\n        device=c_pos_shap.device,\n    )\n    cell_aind = torch.nonzero(\n        torch.arange(max_cell_anum, device=count_vec.device).repeat(\n            cell_atom_num.shape[0], 1\n        )\n        &lt; cell_atom_num.unsqueeze(-1)\n    )[:, 1]\n    global_cell_ind[padded_cind_sorted, cell_aind, 0] = padded_gind[\n        padded_cind_args\n    ]\n    global_cell_ind[padded_cind_sorted, cell_aind, 1] = padded_rind[\n        padded_cind_args\n    ]\n\n    # masking\n    atom_nind = global_cell_ind[atom_cnind]\n    pair_i, neigh, j = torch.where(atom_nind[:, :, :, 0])\n    pair_j = atom_nind[pair_i, neigh, j, 1]\n    pair_j_padded = (\n        atom_nind[pair_i, neigh, j, 0] - 1\n    )  # remember global index of padded atoms starts from 1\n    pair_diff = padded_pos[pair_j_padded] - wrapped_pos[pair_i]\n    pair_dist = torch.norm(pair_diff, dim=1)\n    mask = torch.logical_and(\n        pair_dist &lt; self.cutoff, pair_dist &gt; 0.01\n    )  # 0.01 for numerical stability\n    pairs = torch.hstack((pair_i.unsqueeze(-1), pair_j.unsqueeze(-1)))\n    return pairs[mask].to(torch.long)\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList.get_buffer_scales","title":"<code>get_buffer_scales() -&gt; torch.Tensor</code>","text":"<p>Get the buffer scales for atom pairs.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>Buffer scales for each pair</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def get_buffer_scales(self) -&gt; torch.Tensor:\n    \"\"\"\n    Get the buffer scales for atom pairs.\n\n    Returns\n    -------\n    torch.Tensor\n        Buffer scales for each pair\n    \"\"\"\n    return self.buffer_scales\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList.get_ds","title":"<code>get_ds() -&gt; torch.Tensor</code>","text":"<p>Get the distances between atom pairs.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>Distances between atom pairs</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def get_ds(self) -&gt; torch.Tensor:\n    \"\"\"\n    Get the distances between atom pairs.\n\n    Returns\n    -------\n    torch.Tensor\n        Distances between atom pairs\n    \"\"\"\n    return self.ds\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList.get_pairs","title":"<code>get_pairs() -&gt; torch.Tensor</code>","text":"<p>Get the atom pairs.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>Tensor of atom pairs</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def get_pairs(self) -&gt; torch.Tensor:\n    \"\"\"\n    Get the atom pairs.\n\n    Returns\n    -------\n    torch.Tensor\n        Tensor of atom pairs\n    \"\"\"\n    return self.pairs\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList.pairs_buffer_scales","title":"<code>pairs_buffer_scales(pairs: torch.Tensor) -&gt; torch.Tensor</code>  <code>staticmethod</code>","text":"<p>Calculate buffer scales for atom pairs.</p> <p>Returns 1 if pair_i &lt; pair_j, else 0. Used to exclude repeated pairs and buffer pairs.</p> PARAMETER DESCRIPTION <code>pairs</code> <p>Tensor of atom pairs</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Buffer scales for each pair</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>@staticmethod\ndef pairs_buffer_scales(pairs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Calculate buffer scales for atom pairs.\n\n    Returns 1 if pair_i &lt; pair_j, else 0.\n    Used to exclude repeated pairs and buffer pairs.\n\n    Parameters\n    ----------\n    pairs : torch.Tensor\n        Tensor of atom pairs\n\n    Returns\n    -------\n    torch.Tensor\n        Buffer scales for each pair\n    \"\"\"\n    dp = pairs[:, 0] - pairs[:, 1]\n    return torch.where(\n        dp &lt; 0,\n        torch.tensor(1, dtype=torch.long, device=pairs.device),\n        torch.tensor(0, dtype=torch.long, device=pairs.device),\n    )\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList.pairs_ds","title":"<code>pairs_ds(positions: torch.Tensor, pairs: torch.Tensor, box: Optional[torch.Tensor] = None, pbc_flag: bool = True) -&gt; torch.Tensor</code>  <code>staticmethod</code>","text":"<p>Calculate distances between atom pairs.</p> PARAMETER DESCRIPTION <code>positions</code> <p>Atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>pairs</code> <p>Tensor of atom pairs</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors, by default None</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> <code>pbc_flag</code> <p>Whether to apply periodic boundary conditions, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Distances between atom pairs</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>@staticmethod\ndef pairs_ds(\n    positions: torch.Tensor,\n    pairs: torch.Tensor,\n    box: Optional[torch.Tensor] = None,\n    pbc_flag: bool = True,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculate distances between atom pairs.\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        Atomic positions\n    pairs : torch.Tensor\n        Tensor of atom pairs\n    box : Optional[torch.Tensor], optional\n        Simulation box vectors, by default None\n    pbc_flag : bool, optional\n        Whether to apply periodic boundary conditions, by default True\n\n    Returns\n    -------\n    torch.Tensor\n        Distances between atom pairs\n    \"\"\"\n    ri = positions[pairs[:, 0]]\n    rj = positions[pairs[:, 1]]\n    if pbc_flag is False:\n        dr = rj - ri\n    else:\n        assert box is not None, \"Box should be provided for periodic system.\"\n        dr = pbc_shift(ri - rj, box)\n    ds = torch.norm(dr, dim=1)\n    return ds\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList.set_buffer_scales","title":"<code>set_buffer_scales(buffer_scales: torch.Tensor) -&gt; None</code>","text":"<p>Set the buffer scales for atom pairs.</p> PARAMETER DESCRIPTION <code>buffer_scales</code> <p>Buffer scales for each pair</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def set_buffer_scales(self, buffer_scales: torch.Tensor) -&gt; None:\n    \"\"\"\n    Set the buffer scales for atom pairs.\n\n    Parameters\n    ----------\n    buffer_scales : torch.Tensor\n        Buffer scales for each pair\n    \"\"\"\n    self.buffer_scales = buffer_scales\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList.set_ds","title":"<code>set_ds(ds: torch.Tensor) -&gt; None</code>","text":"<p>Set the distances between atom pairs.</p> PARAMETER DESCRIPTION <code>ds</code> <p>Distances between atom pairs</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def set_ds(self, ds: torch.Tensor) -&gt; None:\n    \"\"\"\n    Set the distances between atom pairs.\n\n    Parameters\n    ----------\n    ds : torch.Tensor\n        Distances between atom pairs\n    \"\"\"\n    self.ds = ds\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList.set_pairs","title":"<code>set_pairs(pairs: torch.Tensor) -&gt; None</code>","text":"<p>Set the atom pairs.</p> PARAMETER DESCRIPTION <code>pairs</code> <p>Tensor of atom pairs</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def set_pairs(self, pairs: torch.Tensor) -&gt; None:\n    \"\"\"\n    Set the atom pairs.\n\n    Parameters\n    ----------\n    pairs : torch.Tensor\n        Tensor of atom pairs\n    \"\"\"\n    self.pairs = pairs\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.TorchNeighborList.wrap_positions","title":"<code>wrap_positions(positions: torch.Tensor, box: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Wrap positions into the unit cell.</p> PARAMETER DESCRIPTION <code>positions</code> <p>Atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Wrapped positions</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def wrap_positions(\n    self,\n    positions: torch.Tensor,\n    box: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Wrap positions into the unit cell.\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        Atomic positions\n    box : torch.Tensor\n        Simulation box vectors\n\n    Returns\n    -------\n    torch.Tensor\n        Wrapped positions\n    \"\"\"\n    eps = torch.tensor(1e-7, device=positions.device, dtype=positions.dtype)\n    # wrap atoms outside of the box\n    scaled_pos = (positions @ torch.linalg.inv(box) + eps) % 1.0 - eps\n    return scaled_pos @ box\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.check_cutoff","title":"<code>check_cutoff(box: torch.Tensor, cutoff: float) -&gt; None</code>","text":"<p>Check whether the sphere of cutoff radius is inside the box.</p> PARAMETER DESCRIPTION <code>box</code> <p>Simulation box vectors</p> <p> TYPE: <code>Tensor</code> </p> <code>cutoff</code> <p>Cutoff radius</p> <p> TYPE: <code>float</code> </p> RAISES DESCRIPTION <code>AssertionError</code> <p>If cutoff is larger than half the minimum height of the box</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def check_cutoff(box: torch.Tensor, cutoff: float) -&gt; None:\n    \"\"\"\n    Check whether the sphere of cutoff radius is inside the box.\n\n    Parameters\n    ----------\n    box : torch.Tensor\n        Simulation box vectors\n    cutoff : float\n        Cutoff radius\n\n    Raises\n    ------\n    AssertionError\n        If cutoff is larger than half the minimum height of the box\n    \"\"\"\n    # Get the three cell vectors a1, a2, a3\n    a1, a2, a3 = box[0], box[1], box[2]\n\n    # Compute normals to the three faces\n    normals = torch.stack(\n        [\n            torch.cross(a2, a3, dim=-1),\n            torch.cross(a3, a1, dim=-1),\n            torch.cross(a1, a2, dim=-1),\n        ]\n    )  # shape (3, 3)\n\n    # Normalize normals\n    unit_normals = normals / torch.norm(normals, dim=1, keepdim=True)\n\n    # Heights from origin to the faces (dot of ai with corresponding normal)\n    heights = torch.abs(torch.einsum(\"ij,ij-&gt;i\", box, unit_normals))  # shape (3,)\n\n    # Minimum half-height (distance from origin to nearest face along normal direction)\n    min_half_height = torch.min(heights) / 2\n\n    assert cutoff &lt;= min_half_height, (\n        f\"Cutoff {cutoff} is larger than half the minimum height {min_half_height} of the box. \"\n        \"This may lead to unphysical results.\"\n    )\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.dp_nblist","title":"<code>dp_nblist(positions: torch.Tensor, box: Optional[torch.Tensor], nnei: int, rcut: float)</code>","text":"<p>Build neighbor list data based on DP (Deep Potential) functions.</p> PARAMETER DESCRIPTION <code>positions</code> <p>Atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>nnei</code> <p>Number of neighbors</p> <p> TYPE: <code>int</code> </p> <code>rcut</code> <p>Cutoff radius</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>tuple</code> <p>Tuple containing (pairs, ds, buffer_scales)</p> RAISES DESCRIPTION <code>ImportError</code> <p>If deepmd.pt is not available</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def dp_nblist(\n    positions: torch.Tensor,\n    box: Optional[torch.Tensor],\n    nnei: int,\n    rcut: float,\n):\n    \"\"\"\n    Build neighbor list data based on DP (Deep Potential) functions.\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        Atomic positions\n    box : Optional[torch.Tensor]\n        Simulation box vectors\n    nnei : int\n        Number of neighbors\n    rcut : float\n        Cutoff radius\n\n    Returns\n    -------\n    tuple\n        Tuple containing (pairs, ds, buffer_scales)\n\n    Raises\n    ------\n    ImportError\n        If deepmd.pt is not available\n    \"\"\"\n    if extend_input_and_build_neighbor_list is None:\n        raise ImportError(\n            \"deepmd.pt is required for dp_nblist. Please install deepmd (pt backend) to use this function.\"\n        )\n\n    if rcut &lt;= 0.0:\n        raise ValueError(f\"rcut must be positive, got {rcut}\")\n\n    positions = torch.reshape(positions, [1, -1, 3])\n    (\n        extended_coord,\n        extended_atype,\n        mapping,\n        nlist,\n    ) = extend_input_and_build_neighbor_list(\n        positions,\n        torch.zeros(\n            1, positions.shape[1], dtype=positions.dtype, device=positions.device\n        ),\n        rcut,\n        [nnei],\n        box=box,\n    )\n    extended_pairs = make_extended_pairs(nlist)\n    pairs, _buffer_scales, mask_ij, mask_ii = make_local_pairs(extended_pairs, mapping)\n    buffer_scales = _buffer_scales.to(positions.device)\n    ds_ij = make_ds(extended_pairs, extended_coord, mask_ij)\n    ds_ii = make_ds(extended_pairs, extended_coord, mask_ii)\n    ds = torch.concat([ds_ij, ds_ii])\n    del extended_coord, extended_atype\n    return pairs, ds, buffer_scales\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.make_ds","title":"<code>make_ds(extended_pairs: torch.Tensor, extended_coord: torch.Tensor, pairs_mask: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Calculate the i-j distance from the neighbor list.</p> PARAMETER DESCRIPTION <code>extended_pairs</code> <p>npairs_all x 2,</p> <p> TYPE: <code>Tensor</code> </p> <code>extended_coord</code> <p>nframes x nall x 3, extended coordinates</p> <p> TYPE: <code>Tensor</code> </p> <code>pairs_mask</code> <p>npairs_all, mask for the local pairs (i &lt; j)</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>ds</code> <p>npairs_loc, i-j distance</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def make_ds(\n    extended_pairs: torch.Tensor,\n    extended_coord: torch.Tensor,\n    pairs_mask: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"Calculate the i-j distance from the neighbor list.\n\n    Parameters\n    ----------\n    extended_pairs : torch.Tensor\n        npairs_all x 2,\n    extended_coord : torch.Tensor\n        nframes x nall x 3, extended coordinates\n    pairs_mask : torch.Tensor\n        npairs_all, mask for the local pairs (i &lt; j)\n\n    Returns\n    -------\n    ds: torch.Tensor\n        npairs_loc, i-j distance\n    \"\"\"\n    nframes, _nall, _ = extended_coord.shape\n    assert nframes == 1\n\n    ii = extended_pairs[..., 0]\n    jj = extended_pairs[..., 1]\n    diff = extended_coord[:, jj] - extended_coord[:, ii]\n    ds = torch.norm(diff.reshape(-1, 3)[pairs_mask], dim=-1)\n    return ds\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.make_extended_pairs","title":"<code>make_extended_pairs(nlist: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Return the pairs between local and extended indices.</p> PARAMETER DESCRIPTION <code>nlist</code> <p>nframes x nloc x nsel, neighbor list between local and extended indices</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>extended_pairs</code> <p>[[i1, j1], [i2, j2], ...], in which i is the local index and j is the extended index</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def make_extended_pairs(\n    nlist: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"Return the pairs between local and extended indices.\n\n    Parameters\n    ----------\n    nlist : torch.Tensor\n        nframes x nloc x nsel, neighbor list between local and extended indices\n\n    Returns\n    -------\n    extended_pairs: torch.Tensor\n        [[i1, j1], [i2, j2], ...],\n        in which i is the local index and j is the extended index\n    \"\"\"\n    nframes, nloc, nsel = nlist.shape\n    assert nframes == 1\n    nlist_reshape = torch.reshape(nlist, [nframes, nloc * nsel, 1])\n    # nlist is padded with -1\n    mask = nlist_reshape.ge(0)\n\n    ii = torch.arange(nloc, dtype=torch.int64, device=nlist.device)\n    ii = torch.tile(ii.reshape(-1, 1), [1, nsel])\n    ii = torch.reshape(ii, [nframes, nloc * nsel, 1])\n    sel_ii = torch.masked_select(ii, mask)\n\n    # nf x (nloc x nsel)\n    sel_jj = torch.masked_select(nlist_reshape, mask)\n    extended_pairs = torch.stack([sel_ii, sel_jj], dim=-1)\n    return extended_pairs\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.make_local_pairs","title":"<code>make_local_pairs(extended_pairs: torch.Tensor, mapping: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]</code>","text":"<p>Return the pairs between local indices.</p> PARAMETER DESCRIPTION <code>extended_pairs</code> <p>npairs_all x 2,</p> <p> TYPE: <code>Tensor</code> </p> <code>mapping</code> <p>nframes x nall, index from extended to local</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>local_pairs</code> <p>npairs_loc x 2, [[i1, j1], [i2, j2], ...], in which i and j are the local indices of the atoms (i &lt; j)</p> <p> TYPE: <code>Tensor</code> </p> <code>mask</code> <p>npairs_all, mask for the local pairs (i &lt; j)</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def make_local_pairs(\n    extended_pairs: torch.Tensor,\n    mapping: torch.Tensor,\n) -&gt; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Return the pairs between local indices.\n\n    Parameters\n    ----------\n    extended_pairs : torch.Tensor\n        npairs_all x 2,\n    mapping : torch.Tensor\n        nframes x nall, index from extended to local\n\n    Returns\n    -------\n    local_pairs: torch.Tensor\n        npairs_loc x 2, [[i1, j1], [i2, j2], ...],\n        in which i and j are the local indices of the atoms (i &lt; j)\n    mask: torch.Tensor\n        npairs_all, mask for the local pairs (i &lt; j)\n    \"\"\"\n    nframes, _nall = mapping.shape\n    assert nframes == 1\n    ii = extended_pairs[..., 0]\n    jj = torch.gather(mapping.reshape(-1), 0, extended_pairs[..., 1])\n\n    mask_ij = ii.lt(jj)\n    mask_ii = ii.eq(jj)\n    local_pairs_ij = torch.stack([ii, jj], dim=-1)[mask_ij]\n    local_pairs_ii = torch.stack([ii, jj], dim=-1)[mask_ii]\n\n    buffer_scales_ij = torch.ones(local_pairs_ij.shape[0], device=local_pairs_ij.device)\n    buffer_scales_ii = (\n        torch.ones(local_pairs_ii.shape[0], device=local_pairs_ii.device) / 2.0\n    )\n\n    local_pairs = torch.concat([local_pairs_ij, local_pairs_ii])\n    buffer_scales = torch.concat([buffer_scales_ij, buffer_scales_ii])\n    return local_pairs, buffer_scales, mask_ij, mask_ii\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.sort_pairs","title":"<code>sort_pairs(pairs: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Sort atom pairs lexicographically.</p> <p>Sorts pairs first by the first index, then by the second index.</p> PARAMETER DESCRIPTION <code>pairs</code> <p>Tensor of atom pairs</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Sorted tensor of atom pairs</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def sort_pairs(pairs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Sort atom pairs lexicographically.\n\n    Sorts pairs first by the first index, then by the second index.\n\n    Parameters\n    ----------\n    pairs : torch.Tensor\n        Tensor of atom pairs\n\n    Returns\n    -------\n    torch.Tensor\n        Sorted tensor of atom pairs\n    \"\"\"\n    indices = torch.argsort(pairs[:, 1])\n    pairs = pairs[indices]\n    indices = torch.argsort(pairs[:, 0], stable=True)\n    sorted_pairs = pairs[indices]\n    return sorted_pairs\n</code></pre>"},{"location":"api/nblist/#torch_admp.nblist.vesin_nblist","title":"<code>vesin_nblist(positions: torch.Tensor, box: torch.Tensor, rcut: float)</code>","text":"<p>Build neighbor list using the Vesin library.</p> PARAMETER DESCRIPTION <code>positions</code> <p>Atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>rcut</code> <p>Cutoff radius</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>tuple</code> <p>Tuple containing (pairs, ds, buffer_scales)</p> Source code in <code>torch_admp/nblist.py</code> <pre><code>def vesin_nblist(\n    positions: torch.Tensor,\n    box: torch.Tensor,\n    rcut: float,\n):\n    \"\"\"\n    Build neighbor list using the Vesin library.\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        Atomic positions\n    box : Optional[torch.Tensor]\n        Simulation box vectors\n    rcut : float\n        Cutoff radius\n\n    Returns\n    -------\n    tuple\n        Tuple containing (pairs, ds, buffer_scales)\n    \"\"\"\n    if NeighborList is None:\n        raise ImportError(\n            \"vesin[torch] is required for vesin_nblist. Please install vesin with torch support to use this function.\"\n        )\n\n    if rcut &lt;= 0.0:\n        raise ValueError(f\"rcut must be positive, got {rcut}\")\n\n    device = positions.device\n    calculator = NeighborList(cutoff=rcut, full_list=False)\n\n    # Handle the box parameter properly\n    ii, jj, ds = calculator.compute(\n        points=positions.to(\"cpu\"),\n        box=box.to(\"cpu\"),\n        periodic=to_torch_tensor(np.full(3, True)).to(\"cpu\"),\n        quantities=\"ijd\",\n    )\n    buffer_scales = torch.ones_like(ds).to(device)\n    return torch.stack([ii, jj]).to(device).T, ds.to(device), buffer_scales\n</code></pre>"},{"location":"api/optimizer/","title":"optimizer","text":""},{"location":"api/optimizer/#optimizer","title":"optimizer","text":""},{"location":"api/optimizer/#torch_admp.optimizer","title":"<code>torch_admp.optimizer</code>","text":"<p>Optimization algorithms for torch-admp.</p> <p>This module implements various optimization algorithms used for charge equilibration and other optimization tasks in the torch-admp package, including line search, conjugate gradient methods, and other optimization utilities.</p>"},{"location":"api/optimizer/#torch_admp.optimizer.line_search","title":"<code>line_search(func_value: Callable, func_grads: Callable, x0: torch.Tensor, eps: float = 1e-06, fk: torch.Tensor = None, gk: torch.Tensor = None, pk: torch.Tensor = None, **kwargs) -&gt; torch.Tensor</code>","text":"<p>Perform line search to find optimal step size.</p> PARAMETER DESCRIPTION <code>func_value</code> <p>Function to compute the value of the objective function</p> <p> TYPE: <code>Callable</code> </p> <code>func_grads</code> <p>Function to compute gradients of the objective function</p> <p> TYPE: <code>Callable</code> </p> <code>x0</code> <p>Initial point</p> <p> TYPE: <code>Tensor</code> </p> <code>eps</code> <p>Convergence threshold, by default 1e-6</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-06</code> </p> <code>fk</code> <p>Function value at x0, by default None</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>gk</code> <p>Gradient at x0, by default None</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>pk</code> <p>Search direction, by default None</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Additional keyword arguments passed to func_value and func_grads</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Optimal point found by line search</p> Source code in <code>torch_admp/optimizer.py</code> <pre><code>@torch.jit.unused\ndef line_search(\n    func_value: Callable,\n    func_grads: Callable,\n    x0: torch.Tensor,\n    eps: float = 1e-6,\n    fk: torch.Tensor = None,\n    gk: torch.Tensor = None,\n    pk: torch.Tensor = None,\n    **kwargs,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Perform line search to find optimal step size.\n\n    Parameters\n    ----------\n    func_value : Callable\n        Function to compute the value of the objective function\n    func_grads : Callable\n        Function to compute gradients of the objective function\n    x0 : torch.Tensor\n        Initial point\n    eps : float, optional\n        Convergence threshold, by default 1e-6\n    fk : torch.Tensor, optional\n        Function value at x0, by default None\n    gk : torch.Tensor, optional\n        Gradient at x0, by default None\n    pk : torch.Tensor, optional\n        Search direction, by default None\n    **kwargs\n        Additional keyword arguments passed to func_value and func_grads\n\n    Returns\n    -------\n    torch.Tensor\n        Optimal point found by line search\n    \"\"\"\n    history_x = torch.arange(3, dtype=x0.dtype, device=x0.device)\n    if fk is None:\n        x0 = x0.detach()\n        x0.requires_grad = True\n        if x0.grad is not None:\n            x0.grad.detach_()\n            x0.grad.zero_()\n        fk = func_value(x0, **kwargs)\n        gk = func_grads(fk, x0)\n        pk = -gk / torch.norm(gk)\n    history_f = [fk]\n\n    xk = x0.detach()\n    # xk.requires_grad = True\n    for _ in range(2):\n        if torch.norm(gk) / xk.shape[0] &lt; eps:\n            return xk\n        xk = xk + pk\n        xk.detach_()\n        xk.requires_grad = True\n        if xk.grad is not None:\n            xk.grad.detach_()\n            xk.grad.zero_()\n        fk = func_value(xk, **kwargs)\n        gk = func_grads(fk, xk)\n        fk.detach_()\n        history_f.append(fk)\n\n    coeff_matrix = torch.stack(\n        [history_x**2, history_x, torch.ones_like(history_x)], dim=1\n    )\n    y = torch.stack(history_f)\n    coeff = torch.linalg.solve(coeff_matrix, y)\n    # print(coeff[0])\n    x_opt = x0 - coeff[1] / (2 * coeff[0]) * pk\n    return x_opt\n</code></pre>"},{"location":"api/optimizer/#torch_admp.optimizer.quadratic_optimize","title":"<code>quadratic_optimize(func_value: Callable, func_grads: Callable, xk: torch.Tensor, eps: float = 0.0001, ls_eps: float = 0.0001, max_iter: int = 20, **kwargs)</code>","text":"<p>Perform quadratic optimization with conjugate gradient method.</p> PARAMETER DESCRIPTION <code>func_value</code> <p>Function to compute the value of the objective function</p> <p> TYPE: <code>Callable</code> </p> <code>func_grads</code> <p>Function to compute gradients of the objective function</p> <p> TYPE: <code>Callable</code> </p> <code>xk</code> <p>Initial point</p> <p> TYPE: <code>Tensor</code> </p> <code>eps</code> <p>Convergence threshold, by default 1e-4</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0001</code> </p> <code>ls_eps</code> <p>Line search threshold, by default 1e-4</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0001</code> </p> <code>max_iter</code> <p>Maximum number of iterations, by default 20</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> <code>**kwargs</code> <p>Additional keyword arguments passed to func_value and func_grads</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>tuple</code> <p>Tuple containing (xk, fk, gk, converge_iter) where: - xk: optimal point - fk: function value at optimal point - gk: gradient at optimal point - converge_iter: iteration at which convergence was achieved</p> Source code in <code>torch_admp/optimizer.py</code> <pre><code>@torch.jit.unused\ndef quadratic_optimize(\n    func_value: Callable,\n    func_grads: Callable,\n    xk: torch.Tensor,\n    eps: float = 1e-4,\n    ls_eps: float = 1e-4,\n    max_iter: int = 20,\n    **kwargs,\n):\n    \"\"\"\n    Perform quadratic optimization with conjugate gradient method.\n\n    Parameters\n    ----------\n    func_value : Callable\n        Function to compute the value of the objective function\n    func_grads : Callable\n        Function to compute gradients of the objective function\n    xk : torch.Tensor\n        Initial point\n    eps : float, optional\n        Convergence threshold, by default 1e-4\n    ls_eps : float, optional\n        Line search threshold, by default 1e-4\n    max_iter : int, optional\n        Maximum number of iterations, by default 20\n    **kwargs\n        Additional keyword arguments passed to func_value and func_grads\n\n    Returns\n    -------\n    tuple\n        Tuple containing (xk, fk, gk, converge_iter) where:\n        - xk: optimal point\n        - fk: function value at optimal point\n        - gk: gradient at optimal point\n        - converge_iter: iteration at which convergence was achieved\n    \"\"\"\n    converge_iter: int = -1\n\n    if xk.grad is not None:\n        xk.grad.detach_()\n        xk.grad.zero_()\n\n    fk = func_value(xk, **kwargs)\n    gk = func_grads(fk, xk)\n    pk = -gk / torch.norm(gk)\n    for ii in range(max_iter):\n        fk.detach_()\n        pk.detach_()\n        # Selecting the step length\n        x_new = line_search(func_value, func_grads, xk, ls_eps, fk, gk, pk, **kwargs)\n        x_new.detach_()\n        x_new.requires_grad = True\n        if x_new.grad is not None:\n            x_new.grad.detach_()\n            x_new.grad.zero_()\n        fk_new = func_value(x_new, **kwargs)\n        gk_new = func_grads(fk_new, x_new)\n\n        xk = x_new\n        fk = fk_new\n\n        norm_grad = torch.norm(gk_new) / xk.shape[0]\n        # print(norm_grad)\n        if norm_grad &lt; eps:\n            gk = gk_new\n            converge_iter = ii\n            break\n        else:\n            pk = update_pr(gk, pk, gk_new)\n            gk = gk_new\n\n    return xk, fk, gk, converge_iter\n</code></pre>"},{"location":"api/optimizer/#torch_admp.optimizer.update_dy","title":"<code>update_dy(gk: torch.Tensor, pk: torch.Tensor, gk_new: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Update search direction using Dai-Yuan Algorithm.</p> PARAMETER DESCRIPTION <code>gk</code> <p>Current gradient</p> <p> TYPE: <code>Tensor</code> </p> <code>pk</code> <p>Current search direction</p> <p> TYPE: <code>Tensor</code> </p> <code>gk_new</code> <p>New gradient</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Updated search direction</p> Source code in <code>torch_admp/optimizer.py</code> <pre><code>def update_dy(\n    gk: torch.Tensor,\n    pk: torch.Tensor,\n    gk_new: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Update search direction using Dai-Yuan Algorithm.\n\n    Parameters\n    ----------\n    gk : torch.Tensor\n        Current gradient\n    pk : torch.Tensor\n        Current search direction\n    gk_new : torch.Tensor\n        New gradient\n\n    Returns\n    -------\n    torch.Tensor\n        Updated search direction\n    \"\"\"\n    old_gk = gk\n    gk = gk_new\n    chi = torch.linalg.norm(gk) ** 2 / pk.dot(gk - old_gk)\n    # Updated descent direction\n    pk = -gk + chi * pk\n    return pk\n</code></pre>"},{"location":"api/optimizer/#torch_admp.optimizer.update_fr","title":"<code>update_fr(gk: torch.Tensor, pk: torch.Tensor, gk_new: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Update search direction using Fletcher-Reeves Algorithm.</p> PARAMETER DESCRIPTION <code>gk</code> <p>Current gradient</p> <p> TYPE: <code>Tensor</code> </p> <code>pk</code> <p>Current search direction</p> <p> TYPE: <code>Tensor</code> </p> <code>gk_new</code> <p>New gradient</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Updated search direction</p> Source code in <code>torch_admp/optimizer.py</code> <pre><code>def update_fr(\n    gk: torch.Tensor,\n    pk: torch.Tensor,\n    gk_new: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Update search direction using Fletcher-Reeves Algorithm.\n\n    Parameters\n    ----------\n    gk : torch.Tensor\n        Current gradient\n    pk : torch.Tensor\n        Current search direction\n    gk_new : torch.Tensor\n        New gradient\n\n    Returns\n    -------\n    torch.Tensor\n        Updated search direction\n    \"\"\"\n    old_gk = gk\n    gk = gk_new\n    # Line (16) of the Fletcher-Reeves algorithm\n    chi = torch.linalg.norm(gk) ** 2 / torch.linalg.norm(old_gk) ** 2\n    # Updated descent direction\n    pk = -gk + chi * pk\n    return pk\n</code></pre>"},{"location":"api/optimizer/#torch_admp.optimizer.update_hs","title":"<code>update_hs(gk: torch.Tensor, pk: torch.Tensor, gk_new: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Update search direction using Hestenes-Stiefel Algorithm.</p> PARAMETER DESCRIPTION <code>gk</code> <p>Current gradient</p> <p> TYPE: <code>Tensor</code> </p> <code>pk</code> <p>Current search direction</p> <p> TYPE: <code>Tensor</code> </p> <code>gk_new</code> <p>New gradient</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Updated search direction</p> Source code in <code>torch_admp/optimizer.py</code> <pre><code>def update_hs(\n    gk: torch.Tensor,\n    pk: torch.Tensor,\n    gk_new: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Update search direction using Hestenes-Stiefel Algorithm.\n\n    Parameters\n    ----------\n    gk : torch.Tensor\n        Current gradient\n    pk : torch.Tensor\n        Current search direction\n    gk_new : torch.Tensor\n        New gradient\n\n    Returns\n    -------\n    torch.Tensor\n        Updated search direction\n    \"\"\"\n    old_gk = gk\n    gk = gk_new\n    chi = gk.dot(gk - old_gk) / pk.dot(gk - old_gk)\n    # Updated descent direction\n    pk = -gk + chi * pk\n    return pk\n</code></pre>"},{"location":"api/optimizer/#torch_admp.optimizer.update_hz","title":"<code>update_hz(gk: torch.Tensor, pk: torch.Tensor, gk_new: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Update search direction using Hager-Zhang Algorithm.</p> PARAMETER DESCRIPTION <code>gk</code> <p>Current gradient</p> <p> TYPE: <code>Tensor</code> </p> <code>pk</code> <p>Current search direction</p> <p> TYPE: <code>Tensor</code> </p> <code>gk_new</code> <p>New gradient</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Updated search direction</p> Source code in <code>torch_admp/optimizer.py</code> <pre><code>def update_hz(\n    gk: torch.Tensor,\n    pk: torch.Tensor,\n    gk_new: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Update search direction using Hager-Zhang Algorithm.\n\n    Parameters\n    ----------\n    gk : torch.Tensor\n        Current gradient\n    pk : torch.Tensor\n        Current search direction\n    gk_new : torch.Tensor\n        New gradient\n\n    Returns\n    -------\n    torch.Tensor\n        Updated search direction\n    \"\"\"\n    old_gk = gk\n    gk = gk_new\n    delta_gk = gk - old_gk\n    m = delta_gk - 2 * pk * torch.linalg.norm(delta_gk) ** 2 / pk.dot(delta_gk)\n    n = gk / pk.dot(delta_gk)\n    chi = m.dot(n)\n    # Updated descent direction\n    pk = -gk + chi * pk\n    return pk\n</code></pre>"},{"location":"api/optimizer/#torch_admp.optimizer.update_pr","title":"<code>update_pr(gk: torch.Tensor, pk: torch.Tensor, gk_new: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Update search direction using Polak-Ribiere Algorithm.</p> PARAMETER DESCRIPTION <code>gk</code> <p>Current gradient</p> <p> TYPE: <code>Tensor</code> </p> <code>pk</code> <p>Current search direction</p> <p> TYPE: <code>Tensor</code> </p> <code>gk_new</code> <p>New gradient</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Updated search direction</p> Source code in <code>torch_admp/optimizer.py</code> <pre><code>def update_pr(\n    gk: torch.Tensor,\n    pk: torch.Tensor,\n    gk_new: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Update search direction using Polak-Ribiere Algorithm.\n\n    Parameters\n    ----------\n    gk : torch.Tensor\n        Current gradient\n    pk : torch.Tensor\n        Current search direction\n    gk_new : torch.Tensor\n        New gradient\n\n    Returns\n    -------\n    torch.Tensor\n        Updated search direction\n    \"\"\"\n    old_gk = gk\n    gk = gk_new\n    # Line (16) of the Polak-Ribiere Algorithm\n    chi = (gk - old_gk).dot(gk) / torch.linalg.norm(old_gk) ** 2\n    chi = torch.where(chi &gt; 0, chi, torch.zeros_like(chi))\n    # Updated descent direction\n    pk = -gk + chi * pk\n    return pk\n</code></pre>"},{"location":"api/optimizer/#torch_admp.optimizer.update_sd","title":"<code>update_sd(gk: torch.Tensor, pk: torch.Tensor, gk_new: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Update search direction using Steepest Descent Algorithm.</p> PARAMETER DESCRIPTION <code>gk</code> <p>Current gradient</p> <p> TYPE: <code>Tensor</code> </p> <code>pk</code> <p>Current search direction</p> <p> TYPE: <code>Tensor</code> </p> <code>gk_new</code> <p>New gradient</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Updated search direction</p> Source code in <code>torch_admp/optimizer.py</code> <pre><code>def update_sd(\n    gk: torch.Tensor,\n    pk: torch.Tensor,\n    gk_new: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Update search direction using Steepest Descent Algorithm.\n\n    Parameters\n    ----------\n    gk : torch.Tensor\n        Current gradient\n    pk : torch.Tensor\n        Current search direction\n    gk_new : torch.Tensor\n        New gradient\n\n    Returns\n    -------\n    torch.Tensor\n        Updated search direction\n    \"\"\"\n    gk = gk_new\n    # Selection of the direction of the steepest descent\n    pk = -gk / torch.linalg.norm(gk)\n    return pk\n</code></pre>"},{"location":"api/pme/","title":"pme","text":""},{"location":"api/pme/#pme","title":"pme","text":""},{"location":"api/pme/#torch_admp.pme","title":"<code>torch_admp.pme</code>","text":"<p>Particle Mesh Ewald (PME) implementation for torch-admp.</p> <p>This module implements the Coulomb energy calculation using the Particle Mesh Ewald method, which splits the calculation into real-space and reciprocal-space contributions for improved efficiency in periodic systems. It includes support for slab corrections and various optimization methods.</p>"},{"location":"api/pme/#torch_admp.pme.CoulombForceModule","title":"<code>CoulombForceModule(rcut: float, ethresh: float = 1e-05, kspace: bool = True, rspace: bool = True, slab_corr: bool = False, slab_axis: int = 2, units_dict: Optional[Dict] = None, sel: Optional[list[int]] = None, kappa: Optional[float] = None, spacing: Union[List[float], float, None] = None, kmesh: Union[List[int], int, None] = None)</code>","text":"<p>               Bases: <code>BaseForceModule</code></p> <p>Coulomb energy module with Particle Mesh Ewald (PME).</p> <p>This module implements the Coulomb energy calculation using the Particle Mesh Ewald method, which splits the calculation into real-space and reciprocal-space contributions for improved efficiency in periodic systems.</p> PARAMETER DESCRIPTION <code>rcut</code> <p>Real-space cutoff distance</p> <p> TYPE: <code>float</code> </p> <code>ethresh</code> <p>Energy threshold for PME accuracy, by default 1e-5</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-05</code> </p> <code>kspace</code> <p>Whether to include reciprocal space contribution, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>rspace</code> <p>Whether to include real space contribution, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>slab_corr</code> <p>Whether to apply slab correction, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>slab_axis</code> <p>Axis at which the slab correction is applied, by default 2</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>units_dict</code> <p>Dictionary of unit conversions, by default None</p> <p> TYPE: <code>Optional[Dict]</code> DEFAULT: <code>None</code> </p> <code>sel</code> <p>Selection list for neighbor list, by default None</p> <p> TYPE: <code>Optional[list[int]]</code> DEFAULT: <code>None</code> </p> <code>kappa</code> <p>Inverse screening length [\u00c5^-1], by default None</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>None</code> </p> <code>spacing</code> <p>Grid spacing for reciprocal space, by default None</p> <p> TYPE: <code>Optional[List[float]]</code> DEFAULT: <code>None</code> </p> <p>Initialize the CoulombForceModule with PME.</p> PARAMETER DESCRIPTION <code>rcut</code> <p>Real-space cutoff distance</p> <p> TYPE: <code>float</code> </p> <code>ethresh</code> <p>Energy threshold for PME accuracy, by default 1e-5</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-05</code> </p> <code>kspace</code> <p>Whether to include reciprocal space contribution, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>rspace</code> <p>Whether to include real space contribution, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>slab_corr</code> <p>Whether to apply slab correction, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>slab_axis</code> <p>Axis at which the slab correction is applied, by default 2</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>units_dict</code> <p>Dictionary of unit conversions, by default None</p> <p> TYPE: <code>Optional[Dict]</code> DEFAULT: <code>None</code> </p> <code>sel</code> <p>Selection list for neighbor list, by default None</p> <p> TYPE: <code>Optional[list[int]]</code> DEFAULT: <code>None</code> </p> <code>kappa</code> <p>Inverse screening length [\u00c5^-1], by default None</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>None</code> </p> <code>spacing</code> <p>Grid spacing for reciprocal space, by default None</p> <p> TYPE: <code>Optional[List[float]]</code> DEFAULT: <code>None</code> </p> Source code in <code>torch_admp/pme.py</code> <pre><code>def __init__(\n    self,\n    rcut: float,\n    ethresh: float = 1e-5,\n    kspace: bool = True,\n    rspace: bool = True,\n    slab_corr: bool = False,\n    slab_axis: int = 2,\n    units_dict: Optional[Dict] = None,\n    sel: Optional[list[int]] = None,\n    kappa: Optional[float] = None,\n    spacing: Union[List[float], float, None] = None,\n    kmesh: Union[List[int], int, None] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the CoulombForceModule with PME.\n\n    Parameters\n    ----------\n    rcut : float\n        Real-space cutoff distance\n    ethresh : float, optional\n        Energy threshold for PME accuracy, by default 1e-5\n    kspace : bool, optional\n        Whether to include reciprocal space contribution, by default True\n    rspace : bool, optional\n        Whether to include real space contribution, by default True\n    slab_corr : bool, optional\n        Whether to apply slab correction, by default False\n    slab_axis : int, optional\n        Axis at which the slab correction is applied, by default 2\n    units_dict : Optional[Dict], optional\n        Dictionary of unit conversions, by default None\n    sel : Optional[list[int]], optional\n        Selection list for neighbor list, by default None\n    kappa : Optional[float], optional\n        Inverse screening length [\u00c5^-1], by default None\n    spacing : Optional[List[float]], optional\n        Grid spacing for reciprocal space, by default None\n    \"\"\"\n    BaseForceModule.__init__(self, units_dict)\n\n    if rcut &lt;= 0.0:\n        raise ValueError(f\"rcut must be positive, got {rcut}\")\n\n    if ethresh &lt;= 0.0:\n        raise ValueError(f\"ethresh must be positive, got {ethresh}\")\n\n    if slab_axis not in (0, 1, 2):\n        raise ValueError(f\"slab_axis must be 0/1/2, got {slab_axis}\")\n\n    self.kspace_flag = kspace\n    if kappa is not None:\n        if kappa &lt;= 0.0:\n            raise ValueError(f\"kappa must be positive, got {kappa}\")\n        self.kappa = kappa\n    else:\n        if self.kspace_flag:\n            kappa = math.sqrt(-math.log(2 * ethresh)) / rcut\n            self.kappa = kappa / getattr(self.const_lib, \"length_coeff\")\n        else:\n            self.kappa = 0.0\n    self.ethresh = ethresh\n\n    if kmesh is not None:\n        # use user-defined kmesh\n        if isinstance(kmesh, int):\n            kmesh = [kmesh, kmesh, kmesh]\n        # Validate kmesh values\n        for i, k in enumerate(kmesh):\n            if k &lt;= 0:\n                raise ValueError(\n                    f\"kmesh values must be positive, got kmesh[{i}] = {k}\"\n                )\n        self.kmesh = to_torch_tensor(np.array(kmesh)).to(torch.long)\n    else:\n        self.kmesh = kmesh\n    # record the actually used kmesh\n    self._kmesh = torch.zeros(3, device=DEVICE, dtype=torch.long)\n    # use spacing\n    if spacing is not None:\n        if isinstance(spacing, float):\n            spacing = [spacing, spacing, spacing]\n        # Validate spacing values\n        for i, s in enumerate(spacing):\n            if s &lt;= 0:\n                raise ValueError(\n                    f\"spacing values must be positive, got spacing[{i}] = {s}\"\n                )\n        self.spacing = to_torch_tensor(np.array(spacing)).to(\n            GLOBAL_PT_FLOAT_PRECISION\n        )\n    else:\n        self.spacing = spacing\n\n    self.rspace_flag = rspace\n    self.slab_corr_flag = slab_corr\n    self.slab_axis = slab_axis\n\n    self.real_energy = to_torch_tensor(np.zeros(1)).to(GLOBAL_PT_FLOAT_PRECISION)\n    self.reciprocal_energy = to_torch_tensor(np.zeros(1)).to(\n        GLOBAL_PT_FLOAT_PRECISION\n    )\n    self.self_energy = to_torch_tensor(np.zeros(1)).to(GLOBAL_PT_FLOAT_PRECISION)\n    self.non_neutral_energy = to_torch_tensor(np.zeros(1)).to(\n        GLOBAL_PT_FLOAT_PRECISION\n    )\n    self.slab_corr_energy = to_torch_tensor(np.zeros(1)).to(\n        GLOBAL_PT_FLOAT_PRECISION\n    )\n\n    # Currently only supprots pme_order=6\n    # Because only the 6-th order spline function is hard implemented\n    self.pme_order: int = 6\n    n_mesh = int(self.pme_order**3)\n\n    # global variables for the reciprocal module, all related to pme_order\n    bspline_range = torch.arange(\n        -self.pme_order // 2, self.pme_order // 2, device=DEVICE\n    )\n    shift_y, shift_x, shift_z = torch.meshgrid(\n        bspline_range, bspline_range, bspline_range, indexing=\"ij\"\n    )\n    self.pme_shifts = (\n        torch.stack((shift_x, shift_y, shift_z))\n        .transpose(0, 3)\n        .reshape((1, n_mesh, 3))\n    )\n\n    self.rcut = rcut\n    self.sel = sel\n</code></pre>"},{"location":"api/pme/#torch_admp.pme.CoulombForceModule.get_rcut","title":"<code>get_rcut() -&gt; float</code>","text":"<p>Get the cutoff radius.</p> RETURNS DESCRIPTION <code>float</code> <p>Cutoff radius</p> Source code in <code>torch_admp/pme.py</code> <pre><code>def get_rcut(self) -&gt; float:\n    \"\"\"\n    Get the cutoff radius.\n\n    Returns\n    -------\n    float\n        Cutoff radius\n    \"\"\"\n    return self.rcut\n</code></pre>"},{"location":"api/pme/#torch_admp.pme.CoulombForceModule.get_sel","title":"<code>get_sel() -&gt; Optional[list[int]]</code>","text":"<p>Get <code>sel</code> list of DP model.</p> RETURNS DESCRIPTION <code>Optional[list[int]]</code> <p>The number of selected neighbors for each type of atom.</p> Source code in <code>torch_admp/pme.py</code> <pre><code>def get_sel(self) -&gt; Optional[list[int]]:\n    \"\"\"\n    Get `sel` list of DP model.\n\n    Returns\n    -------\n    Optional[list[int]]\n        The number of selected neighbors for each type of atom.\n    \"\"\"\n    return self.sel\n</code></pre>"},{"location":"api/pme/#torch_admp.pme.setup_ewald_parameters","title":"<code>setup_ewald_parameters(rcut: float, box: Union[torch.Tensor, np.ndarray, None] = None, threshold: float = 1e-05, spacing: Optional[float] = None, method: str = 'openmm') -&gt; Tuple[float, int, int, int]</code>","text":"<p>Given the cutoff distance, and the required precision, determine the parameters used in Ewald sum, including: kappa, kx, ky, and kz.</p> PARAMETER DESCRIPTION <code>rcut</code> <p>Cutoff distance</p> <p> TYPE: <code>float</code> </p> <code>threshold</code> <p>Expected average relative errors in force</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-05</code> </p> <code>box</code> <p>Lattice vectors in (3 x 3) matrix Keep unit consistent with rcut</p> <p> TYPE: <code>Tensor or ndarray</code> DEFAULT: <code>None</code> </p> <code>spacing</code> <p>Fourier spacing to determine K, used in gromacs method Keep unit consistent with rcut</p> <p> TYPE: <code>float</code> DEFAULT: <code>None</code> </p> <code>method</code> <p>Method to determine ewald parameters. Valid values: \"openmm\" or \"gromacs\". If openmm, the algorithm can refer to http://docs.openmm.org/latest/userguide/theory/02_standard_forces.html#coulomb-interaction-with-particle-mesh-ewald If gromacs, the algorithm is adapted from gromacs source code</p> <p> TYPE: <code>str</code> DEFAULT: <code>'openmm'</code> </p> RETURNS DESCRIPTION <code>kappa</code> <p>Ewald parameter, in 1/lenght unit</p> <p> TYPE: <code>float</code> </p> <code>kx, ky, kz: int</code> <p>number of the k-points mesh</p> Source code in <code>torch_admp/pme.py</code> <pre><code>def setup_ewald_parameters(\n    rcut: float,\n    box: Union[torch.Tensor, np.ndarray, None] = None,\n    threshold: float = 1e-5,\n    spacing: Optional[float] = None,\n    method: str = \"openmm\",\n) -&gt; Tuple[float, int, int, int]:\n    \"\"\"\n    Given the cutoff distance, and the required precision, determine the parameters used in\n    Ewald sum, including: kappa, kx, ky, and kz.\n\n    Parameters\n    ----------\n    rcut : float\n        Cutoff distance\n    threshold : float\n        Expected average relative errors in force\n    box : torch.Tensor or np.ndarray\n        Lattice vectors in (3 x 3) matrix\n        Keep unit consistent with rcut\n    spacing : float, optional\n        Fourier spacing to determine K, used in gromacs method\n        Keep unit consistent with rcut\n    method : str\n        Method to determine ewald parameters.\n        Valid values: \"openmm\" or \"gromacs\".\n        If openmm, the algorithm can refer to http://docs.openmm.org/latest/userguide/theory/02_standard_forces.html#coulomb-interaction-with-particle-mesh-ewald\n        If gromacs, the algorithm is adapted from gromacs source code\n\n    Returns\n    -------\n    kappa: float\n        Ewald parameter, in 1/lenght unit\n    kx, ky, kz: int\n        number of the k-points mesh\n    \"\"\"\n    if rcut &lt;= 0.0:\n        raise ValueError(f\"rcut must be positive, got {rcut}\")\n\n    if box is None:\n        return 0.1, 1, 1, 1\n\n    if isinstance(box, torch.Tensor):\n        box = to_numpy_array(box)\n\n    # assert orthogonal box\n    assert (\n        np.inner(box[0], box[1]) == 0.0\n    ), \"Only orthogonal box is supported currently.\"\n    assert (\n        np.inner(box[0], box[2]) == 0.0\n    ), \"Only orthogonal box is supported currently.\"\n    assert (\n        np.inner(box[1], box[2]) == 0.0\n    ), \"Only orthogonal box is supported currently.\"\n\n    if method == \"openmm\":\n        kappa = np.sqrt(-np.log(2 * threshold)) / rcut\n        kx = np.ceil(2 * kappa * box[0, 0] / (3.0 * threshold ** (1.0 / 5.0))).astype(\n            int\n        )\n        ky = np.ceil(2 * kappa * box[1, 1] / (3.0 * threshold ** (1.0 / 5.0))).astype(\n            int\n        )\n        kz = np.ceil(2 * kappa * box[2, 2] / (3.0 * threshold ** (1.0 / 5.0))).astype(\n            int\n        )\n    elif method == \"gromacs\":\n        assert spacing is not None, \"Spacing must be provided for gromacs method.\"\n        # determine kappa\n        kappa = 5.0\n        i = 0\n        while special.erfc(kappa * rcut) &gt; threshold:\n            i += 1\n            kappa *= 2\n\n        n = i + 60\n        low = 0.0\n        high = kappa\n        for _ in range(n):\n            kappa = (low + high) / 2\n            if special.erfc(kappa * rcut) &gt; threshold:\n                low = kappa\n            else:\n                high = kappa\n        # determine K\n        kx = np.ceil(box[0, 0] / spacing).astype(int)\n        ky = np.ceil(box[1, 1] / spacing).astype(int)\n        kz = np.ceil(box[2, 2] / spacing).astype(int)\n    else:\n        raise ValueError(\n            f\"Invalid method: {method}.\" \"Valid methods: 'openmm', 'gromacs'\"\n        )\n\n    return kappa, kx, ky, kz\n</code></pre>"},{"location":"api/qeq/","title":"qeq","text":""},{"location":"api/qeq/#qeq","title":"qeq","text":""},{"location":"api/qeq/#torch_admp.qeq","title":"<code>torch_admp.qeq</code>","text":"<p>Charge equilibration (QEq) implementation for torch-admp.</p> <p>This module implements charge equilibration methods for determining atomic charges in molecular systems. It includes various optimization approaches including matrix inversion and projected gradient methods, with support for different constraints and damping functions.</p>"},{"location":"api/qeq/#torch_admp.qeq.GaussianDampingForceModule","title":"<code>GaussianDampingForceModule(units_dict: Optional[Dict] = None)</code>","text":"<p>               Bases: <code>BaseForceModule</code></p> <p>Gaussian short-range damping force module.</p> <p>This module implements the Gaussian damping function used in charge equilibration to account for short-range electrostatic interactions.</p> PARAMETER DESCRIPTION <code>units_dict</code> <p>Dictionary containing unit conversion factors, by default None</p> <p> TYPE: <code>Optional[Dict]</code> DEFAULT: <code>None</code> </p> <p>Initialize the GaussianDampingForceModule.</p> PARAMETER DESCRIPTION <code>units_dict</code> <p>Dictionary containing unit conversion factors, by default None</p> <p> TYPE: <code>Optional[Dict]</code> DEFAULT: <code>None</code> </p> Source code in <code>torch_admp/qeq.py</code> <pre><code>def __init__(\n    self,\n    units_dict: Optional[Dict] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the GaussianDampingForceModule.\n\n    Parameters\n    ----------\n    units_dict : Optional[Dict], optional\n        Dictionary containing unit conversion factors, by default None\n    \"\"\"\n    BaseForceModule.__init__(self, units_dict)\n</code></pre>"},{"location":"api/qeq/#torch_admp.qeq.QEqForceModule","title":"<code>QEqForceModule(rcut: float, ethresh: float = 1e-05, kspace: bool = True, rspace: bool = True, slab_corr: bool = False, slab_axis: int = 2, max_iter: int = 20, ls_eps: float = 0.0001, eps: float = 0.0001, units_dict: Optional[Dict] = None, damping: bool = True, sel: Optional[list[int]] = None, kappa: Optional[float] = None, spacing: Union[List[float], float, None] = None, kmesh: Union[List[int], int, None] = None)</code>","text":"<p>               Bases: <code>BaseForceModule</code></p> <p>Charge equilibrium (QEq) model</p> PARAMETER DESCRIPTION <code>rcut</code> <p>cutoff radius for short-range interactions</p> <p> TYPE: <code>float</code> </p> <code>ethresh</code> <p>energy threshold for electrostatic interaction, by default 1e-5</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-05</code> </p> <code>kspace</code> <p>whether the reciprocal part is included</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>rspace</code> <p>whether the real space part is included</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>slab_corr</code> <p>whether the slab correction is applied</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>slab_axis</code> <p>axis at which the slab correction is applied</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>max_iter</code> <p>maximum number of iterations for optimization, by default 20 only used for projected gradient method</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> <code>ls_eps</code> <p>threshold for line search, by default 1e-4 only used for projected gradient method</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0001</code> </p> <code>eps</code> <p>threshold for convergence, by default 1e-4 only used for projected gradient method</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0001</code> </p> <code>units_dict</code> <p>dictionary of units, by default None</p> <p> TYPE: <code>Optional[Dict]</code> DEFAULT: <code>None</code> </p> <p>Initialize the QEqForceModule.</p> PARAMETER DESCRIPTION <code>rcut</code> <p>cutoff radius for short-range interactions</p> <p> TYPE: <code>float</code> </p> <code>ethresh</code> <p>energy threshold for electrostatic interaction, by default 1e-5</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-05</code> </p> <code>kspace</code> <p>whether the reciprocal part is included</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>rspace</code> <p>whether the real space part is included</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>slab_corr</code> <p>whether the slab correction is applied</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>slab_axis</code> <p>axis at which the slab correction is applied</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>max_iter</code> <p>maximum number of iterations for optimization, by default 20 only used for projected gradient method</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> <code>ls_eps</code> <p>threshold for line search, by default 1e-4 only used for projected gradient method</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0001</code> </p> <code>eps</code> <p>threshold for convergence, by default 1e-4 only used for projected gradient method</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0001</code> </p> <code>units_dict</code> <p>dictionary of units, by default None</p> <p> TYPE: <code>Dict</code> DEFAULT: <code>None</code> </p> <code>damping</code> <p>Whether to include Gaussian damping, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>sel</code> <p>Selection list for neighbor list, by default None</p> <p> TYPE: <code>Optional[list[int]]</code> DEFAULT: <code>None</code> </p> <code>kappa</code> <p>Inverse screening length [\u00c5^-1], by default None</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>None</code> </p> <code>spacing</code> <p>Grid spacing for reciprocal space, by default None</p> <p> TYPE: <code>Optional[List[float]]</code> DEFAULT: <code>None</code> </p> Source code in <code>torch_admp/qeq.py</code> <pre><code>def __init__(\n    self,\n    rcut: float,\n    ethresh: float = 1e-5,\n    kspace: bool = True,\n    rspace: bool = True,\n    slab_corr: bool = False,\n    slab_axis: int = 2,\n    max_iter: int = 20,\n    ls_eps: float = 1e-4,\n    eps: float = 1e-4,\n    units_dict: Optional[Dict] = None,\n    damping: bool = True,\n    sel: Optional[list[int]] = None,\n    kappa: Optional[float] = None,\n    spacing: Union[List[float], float, None] = None,\n    kmesh: Union[List[int], int, None] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the QEqForceModule.\n\n    Parameters\n    ----------\n    rcut : float\n        cutoff radius for short-range interactions\n    ethresh : float, optional\n        energy threshold for electrostatic interaction, by default 1e-5\n    kspace : bool\n        whether the reciprocal part is included\n    rspace : bool\n        whether the real space part is included\n    slab_corr : bool\n        whether the slab correction is applied\n    slab_axis : int\n        axis at which the slab correction is applied\n    max_iter : int, optional\n        maximum number of iterations for optimization, by default 20\n        only used for projected gradient method\n    ls_eps : float, optional\n        threshold for line search, by default 1e-4\n        only used for projected gradient method\n    eps : float, optional\n        threshold for convergence, by default 1e-4\n        only used for projected gradient method\n    units_dict : Dict, optional\n        dictionary of units, by default None\n    damping : bool, optional\n        Whether to include Gaussian damping, by default True\n    sel : Optional[list[int]], optional\n        Selection list for neighbor list, by default None\n    kappa : Optional[float], optional\n        Inverse screening length [\u00c5^-1], by default None\n    spacing : Optional[List[float]], optional\n        Grid spacing for reciprocal space, by default None\n    \"\"\"\n    BaseForceModule.__init__(self, units_dict)\n\n    models: Dict[str, BaseForceModule] = {\n        \"site\": SiteForceModule(units_dict=units_dict),\n        \"coulomb\": CoulombForceModule(\n            rcut=rcut,\n            ethresh=ethresh,\n            kspace=kspace,\n            rspace=rspace,\n            slab_corr=slab_corr,\n            slab_axis=slab_axis,\n            units_dict=units_dict,\n            kappa=kappa,\n            spacing=spacing,\n            kmesh=kmesh,\n        ),\n    }\n    if damping:\n        models[\"damping\"] = GaussianDampingForceModule(units_dict=units_dict)\n\n    self.submodels = torch.nn.ModuleDict(models)\n\n    self.rcut = rcut\n    self.max_iter = max_iter\n    self.ls_eps = ls_eps\n    self.eps = eps\n    self.converge_iter: int = -1\n    self.sel = sel\n\n    self.slab_axis = slab_axis\n    self.slab_corr = slab_corr\n</code></pre>"},{"location":"api/qeq/#torch_admp.qeq.QEqForceModule.calc_hessian","title":"<code>calc_hessian(positions: torch.Tensor, box: Optional[torch.Tensor], chi: torch.Tensor, hardness: torch.Tensor, eta: torch.Tensor, pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor)</code>","text":"<p>Calculate the Hessian matrix of the energy with respect to charges.</p> PARAMETER DESCRIPTION <code>positions</code> <p>Atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>chi</code> <p>Electronegativity in energy/charge unit</p> <p> TYPE: <code>Tensor</code> </p> <code>hardness</code> <p>Atomic hardness in energy/charge^2 unit</p> <p> TYPE: <code>Tensor</code> </p> <code>eta</code> <p>Gaussian width in length unit</p> <p> TYPE: <code>Tensor</code> </p> <code>pairs</code> <p>Tensor of atom pairs</p> <p> TYPE: <code>Tensor</code> </p> <code>ds</code> <p>Distance tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>buffer_scales</code> <p>Buffer scales for each pair</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Hessian matrix with shape (n_atoms, n_atoms)</p> Source code in <code>torch_admp/qeq.py</code> <pre><code>@torch.jit.ignore\ndef calc_hessian(\n    self,\n    positions: torch.Tensor,\n    box: Optional[torch.Tensor],\n    chi: torch.Tensor,\n    hardness: torch.Tensor,\n    eta: torch.Tensor,\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n):\n    \"\"\"\n    Calculate the Hessian matrix of the energy with respect to charges.\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        Atomic positions\n    box : Optional[torch.Tensor]\n        Simulation box vectors\n    chi : torch.Tensor\n        Electronegativity in energy/charge unit\n    hardness : torch.Tensor\n        Atomic hardness in energy/charge^2 unit\n    eta : torch.Tensor\n        Gaussian width in length unit\n    pairs : torch.Tensor\n        Tensor of atom pairs\n    ds : torch.Tensor\n        Distance tensor\n    buffer_scales : torch.Tensor\n        Buffer scales for each pair\n\n    Returns\n    -------\n    torch.Tensor\n        Hessian matrix with shape (n_atoms, n_atoms)\n    \"\"\"\n    n_atoms = positions.shape[0]\n    q_tmp = torch.zeros(\n        n_atoms, device=positions.device, dtype=positions.dtype, requires_grad=True\n    )\n    # calculate hessian\n    # hessian = torch.func.hessian(self.func_energy)(\n    #     q_tmp, positions, box, chi, hardness, eta, pairs, ds, buffer_scales\n    # )\n    y = self.func_energy(\n        q_tmp, positions, box, chi, hardness, eta, pairs, ds, buffer_scales\n    )\n    grad = torch.autograd.grad(y, q_tmp, retain_graph=True, create_graph=True)\n    hessian = []\n    for anygrad in grad[0]:\n        hessian.append(torch.autograd.grad(anygrad, q_tmp, retain_graph=True)[0])\n    hessian = torch.stack(hessian)\n    return hessian.reshape([n_atoms, n_atoms])\n</code></pre>"},{"location":"api/qeq/#torch_admp.qeq.QEqForceModule.func_energy","title":"<code>func_energy(charges: torch.Tensor, positions: torch.Tensor, box: Optional[torch.Tensor], chi: torch.Tensor, hardness: torch.Tensor, eta: torch.Tensor, pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Energy method for QEq model</p> PARAMETER DESCRIPTION <code>charges</code> <p>atomic charges</p> <p> TYPE: <code>Tensor</code> </p> <code>positions</code> <p>atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>simulation box</p> <p> TYPE: <code>Tensor</code> </p> <code>chi</code> <p>eletronegativity in energy / charge unit</p> <p> TYPE: <code>Tensor</code> </p> <code>hardness</code> <p>atomic hardness in energy / charge^2 unit</p> <p> TYPE: <code>Tensor</code> </p> <code>eta</code> <p>Gaussian width in length unit</p> <p> TYPE: <code>Tensor</code> </p> <code>pairs</code> <p>n_pairs * 2 tensor of pairs</p> <p> TYPE: <code>Tensor</code> </p> <code>ds</code> <p>i-j distance tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>buffer_scales</code> <p>buffer scales for each pair, 1 if i &lt; j else 0</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>energy</code> <p>energy tensor</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/qeq.py</code> <pre><code>@torch.jit.export\ndef func_energy(\n    self,\n    charges: torch.Tensor,\n    positions: torch.Tensor,\n    box: Optional[torch.Tensor],\n    chi: torch.Tensor,\n    hardness: torch.Tensor,\n    eta: torch.Tensor,\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"Energy method for QEq model\n\n    Parameters\n    ----------\n    charges : torch.Tensor\n        atomic charges\n    positions : torch.Tensor\n        atomic positions\n    box : torch.Tensor\n        simulation box\n    chi : torch.Tensor\n        eletronegativity in energy / charge unit\n    hardness : torch.Tensor\n        atomic hardness in energy / charge^2 unit\n    eta : torch.Tensor\n        Gaussian width in length unit\n    pairs : torch.Tensor\n        n_pairs * 2 tensor of pairs\n    ds : torch.Tensor\n        i-j distance tensor\n    buffer_scales : torch.Tensor\n        buffer scales for each pair, 1 if i &lt; j else 0\n\n    Returns\n    -------\n    energy: torch.Tensor\n        energy tensor\n    \"\"\"\n    params = {\n        \"charge\": charges,  # (optional) initial guess for atomic charges,\n        \"chi\": chi,  # eletronegativity in energy / charge unit\n        \"hardness\": hardness,  # atomic hardness in energy / charge^2 unit\n        \"eta\": eta,  # Gaussian width in length unit\n    }\n    energy = torch.zeros(1, device=positions.device)\n    for model in self.submodels.values():\n        energy = energy + model(positions, box, pairs, ds, buffer_scales, params)\n    return energy\n</code></pre>"},{"location":"api/qeq/#torch_admp.qeq.QEqForceModule.get_rcut","title":"<code>get_rcut() -&gt; float</code>","text":"<p>Get the cutoff radius.</p> RETURNS DESCRIPTION <code>float</code> <p>Cutoff radius</p> Source code in <code>torch_admp/qeq.py</code> <pre><code>def get_rcut(self) -&gt; float:\n    \"\"\"\n    Get the cutoff radius.\n\n    Returns\n    -------\n    float\n        Cutoff radius\n    \"\"\"\n    return self.rcut\n</code></pre>"},{"location":"api/qeq/#torch_admp.qeq.QEqForceModule.get_sel","title":"<code>get_sel() -&gt; Optional[list[int]]</code>","text":"<p>Get <code>sel</code> list of DP model.</p> RETURNS DESCRIPTION <code>Optional[list[int]]</code> <p>The number of selected neighbors for each type of atom.</p> Source code in <code>torch_admp/qeq.py</code> <pre><code>def get_sel(self) -&gt; Optional[list[int]]:\n    \"\"\"\n    Get `sel` list of DP model.\n\n    Returns\n    -------\n    Optional[list[int]]\n        The number of selected neighbors for each type of atom.\n    \"\"\"\n    return self.sel\n</code></pre>"},{"location":"api/qeq/#torch_admp.qeq.QEqForceModule.optimality","title":"<code>optimality(charges: torch.Tensor, positions: torch.Tensor, box: Optional[torch.Tensor], chi: torch.Tensor, hardness: torch.Tensor, eta: torch.Tensor, pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor, constraint_matrix: torch.Tensor, coeff_matrix: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Optimality function (normalized projected gradient)</p> PARAMETER DESCRIPTION <code>charges</code> <p>atomic charges</p> <p> TYPE: <code>Tensor</code> </p> <code>positions</code> <p>atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>simulation box</p> <p> TYPE: <code>Tensor</code> </p> <code>chi</code> <p>eletronegativity in energy / charge unit</p> <p> TYPE: <code>Tensor</code> </p> <code>hardness</code> <p>atomic hardness in energy / charge^2 unit</p> <p> TYPE: <code>Tensor</code> </p> <code>eta</code> <p>Gaussian width in length unit</p> <p> TYPE: <code>Tensor</code> </p> <code>pairs</code> <p>n_pairs * 2 tensor of pairs</p> <p> TYPE: <code>Tensor</code> </p> <code>ds</code> <p>i-j distance tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>buffer_scales</code> <p>buffer scales for each pair, 1 if i &lt; j else 0</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_matrix</code> <p>n_const * natoms, constraint matrix</p> <p> TYPE: <code>Tensor</code> </p> <code>coeff_matrix</code> <p>n_atoms * n_const, coefficient matrix</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>pgrad_norm</code> <p>normalized projected gradient, ~zero at for optimal charges</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/qeq.py</code> <pre><code>@torch.jit.export\ndef optimality(\n    self,\n    charges: torch.Tensor,\n    positions: torch.Tensor,\n    box: Optional[torch.Tensor],\n    chi: torch.Tensor,\n    hardness: torch.Tensor,\n    eta: torch.Tensor,\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n    constraint_matrix: torch.Tensor,\n    coeff_matrix: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"Optimality function (normalized projected gradient)\n\n    Parameters\n    ----------\n    charges : torch.Tensor\n        atomic charges\n    positions : torch.Tensor\n        atomic positions\n    box : torch.Tensor\n        simulation box\n    chi : torch.Tensor\n        eletronegativity in energy / charge unit\n    hardness : torch.Tensor\n        atomic hardness in energy / charge^2 unit\n    eta : torch.Tensor\n        Gaussian width in length unit\n    pairs : torch.Tensor\n        n_pairs * 2 tensor of pairs\n    ds : torch.Tensor\n        i-j distance tensor\n    buffer_scales : torch.Tensor\n        buffer scales for each pair, 1 if i &lt; j else 0\n    constraint_matrix : torch.Tensor\n        n_const * natoms, constraint matrix\n    coeff_matrix : torch.Tensor\n        n_atoms * n_const, coefficient matrix\n\n    Returns\n    -------\n    pgrad_norm: torch.Tensor\n        normalized projected gradient, ~zero at for optimal charges\n    \"\"\"\n    energy = self.func_energy(\n        charges, positions, box, chi, hardness, eta, pairs, ds, buffer_scales\n    )\n    pgrads = calc_pgrads(energy, charges, constraint_matrix, coeff_matrix)\n    return torch.norm(pgrads) / charges.shape[0]\n</code></pre>"},{"location":"api/qeq/#torch_admp.qeq.QEqForceModule.solve_matrix_inversion","title":"<code>solve_matrix_inversion(positions: torch.Tensor, box: Optional[torch.Tensor], chi: torch.Tensor, hardness: torch.Tensor, eta: torch.Tensor, pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor, constraint_matrix: Optional[torch.Tensor], constraint_vals: Optional[torch.Tensor], check_hessian: bool = False)</code>","text":"<p>Solve QEq with matrix inversion method</p> PARAMETER DESCRIPTION <code>positions</code> <p>atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>simulation box</p> <p> TYPE: <code>Tensor</code> </p> <code>chi</code> <p>eletronegativity in energy / charge unit</p> <p> TYPE: <code>Tensor</code> </p> <code>hardness</code> <p>atomic hardness in energy / charge^2 unit</p> <p> TYPE: <code>Tensor</code> </p> <code>eta</code> <p>Gaussian width in length unit</p> <p> TYPE: <code>Tensor</code> </p> <code>pairs</code> <p>n_pairs * 2 tensor of pairs</p> <p> TYPE: <code>Tensor</code> </p> <code>ds</code> <p>i-j distance tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>buffer_scales</code> <p>buffer scales for each pair, 1 if i &lt; j else 0</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_matrix</code> <p>n_const * natoms, constraint matrix</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_vals</code> <p>n_const, constraint values</p> <p> TYPE: <code>Tensor</code> </p> <code>check_hessian</code> <p>(debugger) check whether hessian matrix is positive definite, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>energy</code> <p>energy tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>q_opt</code> <p>optimized atomic charges</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/qeq.py</code> <pre><code>@torch.jit.ignore\ndef solve_matrix_inversion(\n    self,\n    positions: torch.Tensor,\n    box: Optional[torch.Tensor],\n    chi: torch.Tensor,\n    hardness: torch.Tensor,\n    eta: torch.Tensor,\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n    constraint_matrix: Optional[torch.Tensor],\n    constraint_vals: Optional[torch.Tensor],\n    check_hessian: bool = False,\n):\n    \"\"\"Solve QEq with matrix inversion method\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        atomic positions\n    box : torch.Tensor\n        simulation box\n    chi : torch.Tensor\n        eletronegativity in energy / charge unit\n    hardness : torch.Tensor\n        atomic hardness in energy / charge^2 unit\n    eta : torch.Tensor\n        Gaussian width in length unit\n    pairs : torch.Tensor\n        n_pairs * 2 tensor of pairs\n    ds : torch.Tensor\n        i-j distance tensor\n    buffer_scales : torch.Tensor\n        buffer scales for each pair, 1 if i &lt; j else 0\n    constraint_matrix : torch.Tensor\n        n_const * natoms, constraint matrix\n    constraint_vals : torch.Tensor\n        n_const, constraint values\n    check_hessian : bool, optional\n        (debugger) check whether hessian matrix is positive definite, by default False\n\n    Returns\n    -------\n    energy: torch.Tensor\n        energy tensor\n    q_opt: torch.Tensor\n        optimized atomic charges\n    \"\"\"\n    # calculate hessian\n    # n_atoms * n_atoms\n    hessian = self.calc_hessian(\n        positions, box, chi, hardness, eta, pairs, ds, buffer_scales\n    )\n\n    # coeff matrix as [[hessian, constraint_matrix.T], [constraint_matrix, 0]]\n    # (n_atoms + n_const) * (n_atoms + n_const)\n    n_atoms = positions.shape[0]\n    if constraint_matrix is None:\n        coeff_matrix = hessian\n        vector = -chi\n    else:\n        n_const = constraint_matrix.shape[0]\n        coeff_matrix = torch.cat(\n            [\n                torch.cat([hessian, constraint_matrix.T], dim=1),\n                torch.cat(\n                    [\n                        constraint_matrix,\n                        torch.zeros(n_const, n_const, device=positions.device),\n                    ],\n                    dim=1,\n                ),\n            ],\n            dim=0,\n        )\n        vector = torch.concat([-chi, constraint_vals])\n\n    if check_hessian:\n        print(torch.all(torch.diag(hessian) &gt; 0.0))\n\n    _q_opt = torch.linalg.solve(coeff_matrix, vector.reshape(-1, 1)).reshape(-1)\n\n    q_opt = _q_opt[:n_atoms].detach()\n    q_opt.requires_grad = True\n    energy = self.func_energy(\n        q_opt, positions, box, chi, hardness, eta, pairs, ds, buffer_scales\n    )\n    # forces = -calc_grads(energy, positions)\n    fermi = torch.mean(chi + torch.matmul(hessian, _q_opt[:n_atoms]))\n    return energy, _q_opt[:n_atoms], torch.diag(hessian), fermi\n</code></pre>"},{"location":"api/qeq/#torch_admp.qeq.QEqForceModule.solve_pgrad","title":"<code>solve_pgrad(q0: Optional[torch.Tensor], positions: torch.Tensor, box: Optional[torch.Tensor], chi: torch.Tensor, hardness: torch.Tensor, eta: torch.Tensor, pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor, constraint_matrix: torch.Tensor, constraint_vals: torch.Tensor, coeff_matrix: Optional[torch.Tensor] = None, reinit_q: bool = False, method: str = 'lbfgs')</code>","text":"<p>Solve QEq with projected gradient method</p> PARAMETER DESCRIPTION <code>q0</code> <p>initial guess for atomic charges, all zeros for None</p> <p> TYPE: <code>Tensor</code> </p> <code>positions</code> <p>atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>simulation box</p> <p> TYPE: <code>Tensor</code> </p> <code>chi</code> <p>eletronegativity in energy / charge unit</p> <p> TYPE: <code>Tensor</code> </p> <code>hardness</code> <p>atomic hardness in energy / charge^2 unit</p> <p> TYPE: <code>Tensor</code> </p> <code>eta</code> <p>Gaussian width in length unit</p> <p> TYPE: <code>Tensor</code> </p> <code>pairs</code> <p>n_pairs * 2 tensor of pairs</p> <p> TYPE: <code>Tensor</code> </p> <code>ds</code> <p>i-j distance tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>buffer_scales</code> <p>buffer scales for each pair, 1 if i &lt; j else 0</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_matrix</code> <p>n_const * natoms, constraint matrix</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_vals</code> <p>n_const, constraint values</p> <p> TYPE: <code>Tensor</code> </p> <code>coeff_matrix</code> <p>n_atoms * n_const, coefficient matrix</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>reinit_q</code> <p>if reinitialize the atomic charges based on constraints, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>method</code> <p>optimization method, by default \"quadratic\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'lbfgs'</code> </p> RETURNS DESCRIPTION <code>energy</code> <p>energy tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>q_opt</code> <p>optimized atomic charges</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/qeq.py</code> <pre><code>@torch.jit.ignore\ndef solve_pgrad(\n    self,\n    q0: Optional[torch.Tensor],\n    positions: torch.Tensor,\n    box: Optional[torch.Tensor],\n    chi: torch.Tensor,\n    hardness: torch.Tensor,\n    eta: torch.Tensor,\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n    constraint_matrix: torch.Tensor,\n    constraint_vals: torch.Tensor,\n    coeff_matrix: Optional[torch.Tensor] = None,\n    reinit_q: bool = False,\n    method: str = \"lbfgs\",\n):\n    \"\"\"Solve QEq with projected gradient method\n\n    Parameters\n    ----------\n    q0 : torch.Tensor\n        initial guess for atomic charges, all zeros for None\n    positions : torch.Tensor\n        atomic positions\n    box : torch.Tensor\n        simulation box\n    chi : torch.Tensor\n        eletronegativity in energy / charge unit\n    hardness : torch.Tensor\n        atomic hardness in energy / charge^2 unit\n    eta : torch.Tensor\n        Gaussian width in length unit\n    pairs : torch.Tensor\n        n_pairs * 2 tensor of pairs\n    ds : torch.Tensor\n        i-j distance tensor\n    buffer_scales : torch.Tensor\n        buffer scales for each pair, 1 if i &lt; j else 0\n    constraint_matrix : torch.Tensor\n        n_const * natoms, constraint matrix\n    constraint_vals : torch.Tensor\n        n_const, constraint values\n    coeff_matrix : torch.Tensor\n        n_atoms * n_const, coefficient matrix\n    reinit_q : bool, optional\n        if reinitialize the atomic charges based on constraints, by default False\n    method : str, optional\n        optimization method, by default \"quadratic\"\n\n    Returns\n    -------\n    energy: torch.Tensor\n        energy tensor\n    q_opt: torch.Tensor\n        optimized atomic charges\n    \"\"\"\n    n_atoms = positions.shape[0]\n    # n_const = constraint_matrix.shape[0]\n\n    if q0 is None:\n        q0 = torch.rand(n_atoms, device=positions.device, dtype=positions.dtype)\n        reinit_q = True\n    assert q0.shape[0] == n_atoms\n    # make sure the initial guess satisfy constraints\n    if reinit_q:\n        q0 = vector_projection(q0, constraint_matrix, constraint_vals)\n\n    if coeff_matrix is None:\n        coeff_matrix = vector_projection_coeff_matrix(constraint_matrix)\n\n    # choose iterative algorithm\n    try:\n        solver_fn = getattr(self, f\"_optimize_{method}\")()\n    except KeyError as exc:\n        raise ValueError(f\"Method {method} is not supported.\") from exc\n\n    with torch.device(positions.device):\n        _q_opt = custom_root(\n            self.optimality,\n            argnums=1,\n            solve=torchopt.linear_solve.solve_normal_cg(maxiter=5, atol=0),\n        )(solver_fn)(\n            q0,\n            positions,\n            box,\n            chi,\n            hardness,\n            eta,\n            pairs,\n            ds,\n            buffer_scales,\n            constraint_matrix,\n            coeff_matrix,\n        )\n\n    q_opt = _q_opt.detach()\n    q_opt.requires_grad = True\n    energy = self.func_energy(\n        q_opt, positions, box, chi, hardness, eta, pairs, ds, buffer_scales\n    )\n    # forces = -calc_grads(energy, positions)\n    return energy, q_opt\n</code></pre>"},{"location":"api/qeq/#torch_admp.qeq.SiteForceModule","title":"<code>SiteForceModule(units_dict: Optional[Dict] = None)</code>","text":"<p>               Bases: <code>BaseForceModule</code></p> <p>Chemical site energy force module.</p> <p>This module implements the chemical site energy term in charge equilibration, accounting for electronegativity and hardness of atomic sites.</p> PARAMETER DESCRIPTION <code>units_dict</code> <p>Dictionary containing unit conversion factors, by default None</p> <p> TYPE: <code>Optional[Dict]</code> DEFAULT: <code>None</code> </p> <p>Initialize the SiteForceModule.</p> PARAMETER DESCRIPTION <code>units_dict</code> <p>Dictionary containing unit conversion factors, by default None</p> <p> TYPE: <code>Optional[Dict]</code> DEFAULT: <code>None</code> </p> Source code in <code>torch_admp/qeq.py</code> <pre><code>def __init__(\n    self,\n    units_dict: Optional[Dict] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the SiteForceModule.\n\n    Parameters\n    ----------\n    units_dict : Optional[Dict], optional\n        Dictionary containing unit conversion factors, by default None\n    \"\"\"\n    BaseForceModule.__init__(self, units_dict)\n</code></pre>"},{"location":"api/qeq/#torch_admp.qeq.calc_hessian","title":"<code>calc_hessian(func_energy: Callable, positions: torch.Tensor, box: Optional[torch.Tensor], chi: torch.Tensor, hardness: torch.Tensor, eta: torch.Tensor, pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor)</code>","text":"<p>Calculate Hessian matrix of the energy with respect to charges.</p> PARAMETER DESCRIPTION <code>func_energy</code> <p>Energy function</p> <p> TYPE: <code>Callable</code> </p> <code>positions</code> <p>Atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>chi</code> <p>Electronegativity in energy/charge unit</p> <p> TYPE: <code>Tensor</code> </p> <code>hardness</code> <p>Atomic hardness in energy/charge^2 unit</p> <p> TYPE: <code>Tensor</code> </p> <code>eta</code> <p>Gaussian width in length unit</p> <p> TYPE: <code>Tensor</code> </p> <code>pairs</code> <p>Tensor of atom pairs</p> <p> TYPE: <code>Tensor</code> </p> <code>ds</code> <p>Distance tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>buffer_scales</code> <p>Buffer scales for each pair</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Hessian matrix with shape (n_atoms, n_atoms)</p> Source code in <code>torch_admp/qeq.py</code> <pre><code>def calc_hessian(\n    func_energy: Callable,\n    positions: torch.Tensor,\n    box: Optional[torch.Tensor],\n    chi: torch.Tensor,\n    hardness: torch.Tensor,\n    eta: torch.Tensor,\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n):\n    \"\"\"\n    Calculate Hessian matrix of the energy with respect to charges.\n\n    Parameters\n    ----------\n    func_energy : Callable\n        Energy function\n    positions : torch.Tensor\n        Atomic positions\n    box : Optional[torch.Tensor]\n        Simulation box vectors\n    chi : torch.Tensor\n        Electronegativity in energy/charge unit\n    hardness : torch.Tensor\n        Atomic hardness in energy/charge^2 unit\n    eta : torch.Tensor\n        Gaussian width in length unit\n    pairs : torch.Tensor\n        Tensor of atom pairs\n    ds : torch.Tensor\n        Distance tensor\n    buffer_scales : torch.Tensor\n        Buffer scales for each pair\n\n    Returns\n    -------\n    torch.Tensor\n        Hessian matrix with shape (n_atoms, n_atoms)\n    \"\"\"\n    n_atoms = positions.shape[0]\n    q_tmp = torch.zeros(\n        n_atoms, device=positions.device, dtype=positions.dtype, requires_grad=True\n    )\n    y = func_energy(q_tmp, positions, box, chi, hardness, eta, pairs, ds, buffer_scales)\n    grad = torch.autograd.grad(y, q_tmp, retain_graph=True, create_graph=True)\n    hessian = []\n    for anygrad in grad[0]:\n        hessian.append(torch.autograd.grad(anygrad, q_tmp, retain_graph=True)[0])\n    hessian = torch.stack(hessian)\n    return hessian.reshape([n_atoms, n_atoms])\n</code></pre>"},{"location":"api/qeq/#torch_admp.qeq.matinv_optimize","title":"<code>matinv_optimize(module: QEqForceModule, positions: torch.Tensor, box: Optional[torch.Tensor], chi: torch.Tensor, hardness: torch.Tensor, eta: torch.Tensor, pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor, constraint_matrix: torch.Tensor, constraint_vals: torch.Tensor, **kwargs)</code>","text":"<p>Function to optimize atomic charges with matrix inversion method.</p> PARAMETER DESCRIPTION <code>module</code> <p>QEq module</p> <p> TYPE: <code>QEqForceModule</code> </p> <code>positions</code> <p>Atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>chi</code> <p>Electronegativity in energy/charge unit</p> <p> TYPE: <code>Tensor</code> </p> <code>hardness</code> <p>Atomic hardness in energy/charge^2 unit</p> <p> TYPE: <code>Tensor</code> </p> <code>eta</code> <p>Gaussian width in length unit</p> <p> TYPE: <code>Tensor</code> </p> <code>pairs</code> <p>Tensor of atom pairs</p> <p> TYPE: <code>Tensor</code> </p> <code>ds</code> <p>Distance tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>buffer_scales</code> <p>Buffer scales for each pair</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_matrix</code> <p>n_const * natoms, constraint matrix</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_vals</code> <p>n_const, constraint values</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>energy</code> <p>Energy tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>q_opt</code> <p>Optimized atomic charges</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/qeq.py</code> <pre><code>def matinv_optimize(\n    module: QEqForceModule,\n    positions: torch.Tensor,\n    box: Optional[torch.Tensor],\n    chi: torch.Tensor,\n    hardness: torch.Tensor,\n    eta: torch.Tensor,\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n    constraint_matrix: torch.Tensor,\n    constraint_vals: torch.Tensor,\n    **kwargs,\n):\n    \"\"\"\n    Function to optimize atomic charges with matrix inversion method.\n\n    Parameters\n    ----------\n    module : QEqForceModule\n        QEq module\n    positions : torch.Tensor\n        Atomic positions\n    box : Optional[torch.Tensor]\n        Simulation box vectors\n    chi : torch.Tensor\n        Electronegativity in energy/charge unit\n    hardness : torch.Tensor\n        Atomic hardness in energy/charge^2 unit\n    eta : torch.Tensor\n        Gaussian width in length unit\n    pairs : torch.Tensor\n        Tensor of atom pairs\n    ds : torch.Tensor\n        Distance tensor\n    buffer_scales : torch.Tensor\n        Buffer scales for each pair\n    constraint_matrix : torch.Tensor\n        n_const * natoms, constraint matrix\n    constraint_vals : torch.Tensor\n        n_const, constraint values\n\n    Returns\n    -------\n    energy: torch.Tensor\n        Energy tensor\n    q_opt: torch.Tensor\n        Optimized atomic charges\n    \"\"\"\n    device = positions.device\n    dtype = positions.dtype\n    # calculate hessian\n    # n_atoms * n_atoms\n    hessian = calc_hessian(\n        module.func_energy, positions, box, chi, hardness, eta, pairs, ds, buffer_scales\n    )\n\n    # coeff matrix as [[hessian, constraint_matrix.T], [constraint_matrix, 0]]\n    # (n_atoms + n_const) * (n_atoms + n_const)\n    n_atoms = positions.shape[0]\n    if constraint_matrix is None:\n        coeff_matrix = hessian\n        vector = -chi\n    else:\n        n_const = constraint_matrix.shape[0]\n        coeff_matrix = torch.cat(\n            [\n                torch.cat([hessian, constraint_matrix.T], dim=1),\n                torch.cat(\n                    [\n                        constraint_matrix,\n                        torch.zeros((n_const, n_const), device=device, dtype=dtype),\n                    ],\n                    dim=1,\n                ),\n            ],\n            dim=0,\n        )\n        vector = torch.concat([-chi, constraint_vals])\n\n    _q_opt = torch.linalg.solve(coeff_matrix, vector.reshape(-1, 1)).reshape(-1)\n\n    q_opt = _q_opt[:n_atoms].detach()\n    q_opt.requires_grad = True\n    energy = module.func_energy(\n        q_opt, positions, box, chi, hardness, eta, pairs, ds, buffer_scales\n    )\n    return energy, q_opt\n</code></pre>"},{"location":"api/qeq/#torch_admp.qeq.pgrad_optimize","title":"<code>pgrad_optimize(module: QEqForceModule, q0: Optional[torch.Tensor], positions: torch.Tensor, box: Optional[torch.Tensor], chi: torch.Tensor, hardness: torch.Tensor, eta: torch.Tensor, pairs: torch.Tensor, ds: torch.Tensor, buffer_scales: torch.Tensor, constraint_matrix: torch.Tensor, constraint_vals: torch.Tensor, coeff_matrix: Optional[torch.Tensor] = None, reinit_q: bool = False, method: str = 'lbfgs', **kwargs)</code>","text":"<p>Function to optimize atomic charges with projected gradient method.</p> PARAMETER DESCRIPTION <code>module</code> <p>QEq module</p> <p> TYPE: <code>QEqForceModule</code> </p> <code>q0</code> <p>Initial guess for atomic charges, all zeros for None</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>positions</code> <p>Atomic positions</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>Simulation box vectors</p> <p> TYPE: <code>Optional[Tensor]</code> </p> <code>chi</code> <p>Electronegativity in energy/charge unit</p> <p> TYPE: <code>Tensor</code> </p> <code>hardness</code> <p>Atomic hardness in energy/charge^2 unit</p> <p> TYPE: <code>Tensor</code> </p> <code>eta</code> <p>Gaussian width in length unit</p> <p> TYPE: <code>Tensor</code> </p> <code>pairs</code> <p>n_pairs * 2 tensor of pairs</p> <p> TYPE: <code>Tensor</code> </p> <code>ds</code> <p>i-j distance tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>buffer_scales</code> <p>Buffer scales for each pair, 1 if i &lt; j else 0</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_matrix</code> <p>n_const * natoms, constraint matrix</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_vals</code> <p>n_const, constraint values</p> <p> TYPE: <code>Tensor</code> </p> <code>coeff_matrix</code> <p>n_atoms * n_const, coefficient matrix</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> <code>reinit_q</code> <p>If reinitialize atomic charges based on constraints, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>method</code> <p>Optimization method, by default \"lbfgs\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'lbfgs'</code> </p> RETURNS DESCRIPTION <code>energy</code> <p>Energy tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>q_opt</code> <p>Optimized atomic charges</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/qeq.py</code> <pre><code>def pgrad_optimize(\n    module: QEqForceModule,\n    q0: Optional[torch.Tensor],\n    positions: torch.Tensor,\n    box: Optional[torch.Tensor],\n    chi: torch.Tensor,\n    hardness: torch.Tensor,\n    eta: torch.Tensor,\n    pairs: torch.Tensor,\n    ds: torch.Tensor,\n    buffer_scales: torch.Tensor,\n    constraint_matrix: torch.Tensor,\n    constraint_vals: torch.Tensor,\n    coeff_matrix: Optional[torch.Tensor] = None,\n    reinit_q: bool = False,\n    method: str = \"lbfgs\",\n    **kwargs,\n):\n    \"\"\"\n    Function to optimize atomic charges with projected gradient method.\n\n    Parameters\n    ----------\n    module : QEqForceModule\n        QEq module\n    q0 : Optional[torch.Tensor]\n        Initial guess for atomic charges, all zeros for None\n    positions : torch.Tensor\n        Atomic positions\n    box : Optional[torch.Tensor]\n        Simulation box vectors\n    chi : torch.Tensor\n        Electronegativity in energy/charge unit\n    hardness : torch.Tensor\n        Atomic hardness in energy/charge^2 unit\n    eta : torch.Tensor\n        Gaussian width in length unit\n    pairs : torch.Tensor\n        n_pairs * 2 tensor of pairs\n    ds : torch.Tensor\n        i-j distance tensor\n    buffer_scales : torch.Tensor\n        Buffer scales for each pair, 1 if i &lt; j else 0\n    constraint_matrix : torch.Tensor\n        n_const * natoms, constraint matrix\n    constraint_vals : torch.Tensor\n        n_const, constraint values\n    coeff_matrix : Optional[torch.Tensor]\n        n_atoms * n_const, coefficient matrix\n    reinit_q : bool, optional\n        If reinitialize atomic charges based on constraints, by default False\n    method : str, optional\n        Optimization method, by default \"lbfgs\"\n\n    Returns\n    -------\n    energy: torch.Tensor\n        Energy tensor\n    q_opt: torch.Tensor\n        Optimized atomic charges\n    \"\"\"\n    \"\"\"Function to optimize atomic charges with projected gradient method\n\n    Parameters\n    ----------\n    module : QEqForceModule\n        QEq module\n    q0 : torch.Tensor\n        initial guess for atomic charges, all zeros for None\n    positions : torch.Tensor\n        atomic positions\n    box : torch.Tensor\n        simulation box\n    chi : torch.Tensor\n        eletronegativity in energy / charge unit\n    hardness : torch.Tensor\n        atomic hardness in energy / charge^2 unit\n    eta : torch.Tensor\n        Gaussian width in length unit\n    pairs : torch.Tensor\n        n_pairs * 2 tensor of pairs\n    ds : torch.Tensor\n        i-j distance tensor\n    buffer_scales : torch.Tensor\n        buffer scales for each pair, 1 if i &lt; j else 0\n    constraint_matrix : torch.Tensor\n        n_const * natoms, constraint matrix\n    constraint_vals : torch.Tensor\n        n_const, constraint values\n    coeff_matrix : torch.Tensor\n        n_atoms * n_const, coefficient matrix\n    reinit_q : bool, optional\n        if reinitialize the atomic charges based on constraints, by default False\n    method : str, optional\n        optimization method, by default \"lbfgs\"\n\n    Returns\n    -------\n    energy: torch.Tensor\n        energy tensor\n    q_opt: torch.Tensor\n        optimized atomic charges\n    \"\"\"\n    n_atoms = positions.shape[0]\n    # n_const = constraint_matrix.shape[0]\n\n    if q0 is None:\n        q0 = torch.rand(n_atoms, device=positions.device, dtype=positions.dtype)\n        reinit_q = True\n    assert q0.shape[0] == n_atoms\n    # make sure the initial guess satisfy constraints\n    if reinit_q:\n        q0 = vector_projection(q0, constraint_matrix, constraint_vals)\n\n    if coeff_matrix is None:\n        coeff_matrix = vector_projection_coeff_matrix(constraint_matrix)\n\n    # choose iterative algorithm\n    try:\n        solver_fn = globals()[f\"_pgrad_optimize_{method}\"](\n            module.func_energy, module.max_iter, module.eps\n        )\n    except KeyError as exc:\n        raise ValueError(f\"Method {method} is not supported.\") from exc\n\n    with torch.device(positions.device):\n        out = custom_root(\n            module.optimality,\n            argnums=1,\n            has_aux=True,\n            solve=torchopt.linear_solve.solve_normal_cg(maxiter=5, atol=0),\n        )(solver_fn)(\n            q0,\n            positions,\n            box,\n            chi,\n            hardness,\n            eta,\n            pairs,\n            ds,\n            buffer_scales,\n            constraint_matrix,\n            coeff_matrix,\n        )\n    if out[1] == -1:\n        Warning(\"Optimization did not converge.\")\n    module.converge_iter = out[1]\n    q_opt = out[0].detach()\n    q_opt.requires_grad = True\n    energy = module.func_energy(\n        q_opt, positions, box, chi, hardness, eta, pairs, ds, buffer_scales\n    )\n    # forces = -calc_grads(energy, positions)\n    return energy, q_opt\n</code></pre>"},{"location":"api/recip/","title":"recip","text":""},{"location":"api/recip/#recip","title":"recip","text":""},{"location":"api/recip/#torch_admp.recip","title":"<code>torch_admp.recip</code>","text":"<p>Reciprocal space operations for torch-admp.</p> <p>This module provides functions for reciprocal space calculations used in Particle Mesh Ewald (PME) and other reciprocal space methods, including B-spline interpolation, charge spreading, and k-point setup.</p>"},{"location":"api/recip/#torch_admp.recip.Q_m_peratom","title":"<code>Q_m_peratom(charges: torch.Tensor, sph_harms: torch.Tensor, pme_order: int)</code>","text":"<p>Computes . See eq. (49) of https://doi.org/10.1021/ct5007983</p> <p>Inputs:     Q:         N_a * (l+1)2 matrix containing global frame multipole moments up to lmax,     sph_harms:         N_a, 216, (l+1)2     lmax:         int: maximal L</p> <p>Output:     Q_m_pera:         N_a * 216 matrix, values of theta evaluated on a 6 * 6 block about the atoms</p> Source code in <code>torch_admp/recip.py</code> <pre><code>def Q_m_peratom(\n    charges: torch.Tensor,\n    sph_harms: torch.Tensor,\n    pme_order: int,\n):\n    \"\"\"\n    Computes &lt;R_t|Q&gt;. See eq. (49) of https://doi.org/10.1021/ct5007983\n\n    Inputs:\n        Q:\n            N_a * (l+1)**2 matrix containing global frame multipole moments up to lmax,\n        sph_harms:\n            N_a, 216, (l+1)**2\n        lmax:\n            int: maximal L\n\n    Output:\n        Q_m_pera:\n            N_a * 216 matrix, values of theta evaluated on a 6 * 6 block about the atoms\n    \"\"\"\n    n_mesh = int(pme_order**3)\n    N_a = sph_harms.shape[0]\n    Q_dbf = torch.atleast_2d(charges)[:, 0:1]\n    Q_m_pera = torch.sum(Q_dbf[:, None, :] * sph_harms, dim=2)\n    assert Q_m_pera.shape == (N_a, n_mesh)\n    return Q_m_pera\n</code></pre>"},{"location":"api/recip/#torch_admp.recip.Q_mesh_on_m","title":"<code>Q_mesh_on_m(Q_mesh_pera: torch.Tensor, m_u0: torch.Tensor, t_kmesh: torch.Tensor, shifts: torch.Tensor)</code>","text":"<p>Reduce the local Q_m_peratom into the global mesh</p> <p>Input:     Q_mesh_pera, m_u0, N</p> <p>Output:     Q_mesh:         Nx * Ny * Nz matrix</p> Source code in <code>torch_admp/recip.py</code> <pre><code>def Q_mesh_on_m(\n    Q_mesh_pera: torch.Tensor,\n    m_u0: torch.Tensor,\n    t_kmesh: torch.Tensor,\n    shifts: torch.Tensor,\n):\n    \"\"\"\n    Reduce the local Q_m_peratom into the global mesh\n\n    Input:\n        Q_mesh_pera, m_u0, N\n\n    Output:\n        Q_mesh:\n            Nx * Ny * Nz matrix\n    \"\"\"\n    indices_arr = torch.fmod(\n        m_u0[:, None, :] + shifts + t_kmesh[None, None, :] * 10, t_kmesh[None, None, :]\n    )\n    Q_mesh = torch.zeros(\n        int(t_kmesh[0].item()) * int(t_kmesh[1].item()) * int(t_kmesh[2].item()),\n        device=t_kmesh.device,\n        dtype=Q_mesh_pera.dtype,\n    )\n    indices_0 = indices_arr[:, :, 0].flatten()\n    indices_1 = indices_arr[:, :, 1].flatten()\n    indices_2 = indices_arr[:, :, 2].flatten()\n    flat_indices = (\n        indices_0 * int(t_kmesh[1].item()) * int(t_kmesh[2].item())\n        + indices_1 * int(t_kmesh[2].item())\n        + indices_2\n    )\n    Q_mesh.index_add_(0, flat_indices, Q_mesh_pera.view(-1))\n    Q_mesh = Q_mesh.reshape(\n        int(t_kmesh[0].item()),\n        int(t_kmesh[1].item()),\n        int(t_kmesh[2].item()),\n    )\n\n    return Q_mesh\n</code></pre>"},{"location":"api/recip/#torch_admp.recip.bspline","title":"<code>bspline(u: torch.Tensor)</code>","text":"<p>Computes the cardinal B-spline function</p> Source code in <code>torch_admp/recip.py</code> <pre><code>def bspline(u: torch.Tensor):\n    \"\"\"\n    Computes the cardinal B-spline function\n    \"\"\"\n    return torch.where(\n        (u &gt;= 0.0) &amp; (u &lt; 1.0),\n        u**5 / 120,\n        torch.where(\n            u &lt; 2.0,\n            u**5 / 120 - (u - 1) ** 5 / 20,\n            torch.where(\n                u &lt; 3.0,\n                u**5 / 120 + (u - 2) ** 5 / 8 - (u - 1) ** 5 / 20,\n                torch.where(\n                    u &lt; 4.0,\n                    u**5 / 120\n                    - (u - 3) ** 5 / 6\n                    + (u - 2) ** 5 / 8\n                    - (u - 1) ** 5 / 20,\n                    torch.where(\n                        u &lt; 5.0,\n                        u**5 / 24\n                        - u**4\n                        + 19 * u**3 / 2\n                        - 89 * u**2 / 2\n                        + 409 * u / 4\n                        - 1829 / 20,\n                        torch.where(\n                            u &lt; 6.0,\n                            -(u**5) / 120\n                            + u**4 / 4\n                            - 3 * u**3\n                            + 18 * u**2\n                            - 54 * u\n                            + 324 / 5,\n                            torch.zeros_like(u),\n                        ),\n                    ),\n                ),\n            ),\n        ),\n    )\n</code></pre>"},{"location":"api/recip/#torch_admp.recip.get_recip_grid_vectors","title":"<code>get_recip_grid_vectors(box_inv: torch.Tensor, t_kmesh: torch.Tensor)</code>","text":"<p>Compute reciprocal lattice vectors of grids</p> PARAMETER DESCRIPTION <code>box_inv</code> <p>(3 * 3)-matrix for inv cell vectors inv_box = torch.linalg.inv(box)</p> <p> TYPE: <code>Tensor</code> </p> <code>t_kmesh</code> <p>(3,)-shaped tensor [kx, ky, kz]</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>recip_grid_vectors</code> <p>(3 * 3)-matrix for reciprocal lattice vectors of grids</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/recip.py</code> <pre><code>def get_recip_grid_vectors(\n    box_inv: torch.Tensor,\n    t_kmesh: torch.Tensor,\n):\n    \"\"\"\n    Compute reciprocal lattice vectors of grids\n\n    Parameters\n    ----------\n    box_inv : torch.Tensor\n        (3 * 3)-matrix for inv cell vectors\n        inv_box = torch.linalg.inv(box)\n    t_kmesh : torch.Tensor\n        (3,)-shaped tensor [kx, ky, kz]\n\n    Returns\n    -------\n    recip_grid_vectors: torch.Tensor\n        (3 * 3)-matrix for reciprocal lattice vectors of grids\n    \"\"\"\n    recip_grid_vectors = (t_kmesh.reshape(1, 3) * box_inv).transpose(0, 1)\n    return recip_grid_vectors\n</code></pre>"},{"location":"api/recip/#torch_admp.recip.setup_kpts","title":"<code>setup_kpts(box_inv, kpts_int)</code>","text":"<p>This function sets up the k-points used for reciprocal space calculations</p> <p>Input:     box_inv:         3 * 3, three axis arranged in rows     kpts_int:         n_k * 3 matrix</p> <p>Output:     kpts:         4 * K, K=K1K2K3, contains kx, ky, kz, k^2 for each kpoint</p> Source code in <code>torch_admp/recip.py</code> <pre><code>def setup_kpts(box_inv, kpts_int):\n    \"\"\"\n    This function sets up the k-points used for reciprocal space calculations\n\n    Input:\n        box_inv:\n            3 * 3, three axis arranged in rows\n        kpts_int:\n            n_k * 3 matrix\n\n    Output:\n        kpts:\n            4 * K, K=K1*K2*K3, contains kx, ky, kz, k^2 for each kpoint\n    \"\"\"\n    # in this array, a*, b*, c* (without 2*pi) are arranged in column\n    # K * 3, coordinate in reciprocal space\n    kpts = 2 * torch.pi * torch.matmul(kpts_int.double(), box_inv)\n    ksq = torch.sum(kpts**2, dim=1)\n    # 4 * K\n    kpts = torch.hstack((kpts, ksq[:, None])).transpose(0, 1)\n    return kpts\n</code></pre>"},{"location":"api/recip/#torch_admp.recip.setup_kpts_integer","title":"<code>setup_kpts_integer(t_kmesh: torch.Tensor)</code>","text":"<p>Set up integer k-points for reciprocal space calculations.</p> PARAMETER DESCRIPTION <code>t_kmesh</code> <p>Mesh dimensions [Kx, Ky, Kz]</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>n_k * 3 matrix of integer k-points, where n_k = Kx * Ky * Kz</p> Source code in <code>torch_admp/recip.py</code> <pre><code>def setup_kpts_integer(\n    t_kmesh: torch.Tensor,\n):\n    \"\"\"\n    Set up integer k-points for reciprocal space calculations.\n\n    Parameters\n    ----------\n    t_kmesh : torch.Tensor\n        Mesh dimensions [Kx, Ky, Kz]\n\n    Returns\n    -------\n    torch.Tensor\n        n_k * 3 matrix of integer k-points, where n_k = Kx * Ky * Kz\n    \"\"\"\n    kx, ky, kz = [\n        torch.roll(\n            torch.arange(\n                -(int(t_kmesh[i].item()) - 1) // 2,\n                (int(t_kmesh[i].item()) + 1) // 2,\n                device=t_kmesh.device,\n            ),\n            shifts=[-(int(t_kmesh[i].item()) - 1) // 2],\n        )\n        for i in range(3)\n    ]\n    kpts_int = torch.hstack(\n        [ki.flatten()[:, None] for ki in torch.meshgrid(kx, ky, kz, indexing=\"ij\")]\n    )\n    return kpts_int\n</code></pre>"},{"location":"api/recip/#torch_admp.recip.sph_harmonics_GO","title":"<code>sph_harmonics_GO(u0: torch.Tensor, shifts: torch.Tensor, pme_order: int)</code>","text":"<p>Find out the value of spherical harmonics GRADIENT OPERATORS, assume the order is: 00, 10, 11c, 11s, 20, 21c, 21s, 22c, 22s, ... Currently supports lmax &lt;= 2</p> PARAMETER DESCRIPTION <code>u0</code> <p>(N_a * 3)-matrix containing all positions</p> <p> TYPE: <code>Tensor</code> </p> <code>recip_grid_vectors</code> <p>(3 * 3)-matrix for reciprocal lattice vectors of grids</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>harmonics</code> <p>a Na * (63) * (l+1)^2 matrix, STGO operated on theta, evaluated at 666 integer points about reference points m_u0</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/recip.py</code> <pre><code>def sph_harmonics_GO(\n    u0: torch.Tensor,\n    shifts: torch.Tensor,\n    pme_order: int,\n):\n    \"\"\"\n    Find out the value of spherical harmonics GRADIENT OPERATORS, assume the order is:\n    00, 10, 11c, 11s, 20, 21c, 21s, 22c, 22s, ...\n    Currently supports lmax &lt;= 2\n\n    Parameters\n    ----------\n    u0 : torch.Tensor\n        (N_a * 3)-matrix containing all positions\n    recip_grid_vectors : torch.Tensor\n        (3 * 3)-matrix for reciprocal lattice vectors of grids\n\n    Returns\n    -------\n    harmonics: torch.Tensor\n        a Na * (6**3) * (l+1)^2 matrix, STGO operated on theta,\n        evaluated at 6*6*6 integer points about reference points m_u0\n    \"\"\"\n    n_mesh = int(pme_order**3)\n    N_a = u0.shape[0]\n\n    # mesh points around each site\n    u = u0[:, None, :] + shifts\n    u_reshape = torch.reshape(u, (N_a * n_mesh, 3))\n    # bspline may have little different value\n    M_u = bspline(u_reshape)\n    theta = torch.prod(M_u, dim=-1)\n    return theta.reshape(N_a, n_mesh, 1)\n</code></pre>"},{"location":"api/recip/#torch_admp.recip.spread_charges","title":"<code>spread_charges(positions: torch.Tensor, box_inv: torch.Tensor, charges: torch.Tensor, t_kmesh: torch.Tensor, shifts: torch.Tensor, pme_order: int)</code>","text":"<p>This is the high level wrapper function, in charge of spreading the charges/multipoles on grid</p> PARAMETER DESCRIPTION <code>positions</code> <p>Na * 3: positions of atoms</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>3 * 3: cell vectors</p> <p> TYPE: <code>Tensor</code> </p> <code>charges</code> <p>Na * (lmax+1)**2: the multipole of each atomic site in global frame</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Nx * Ny * Nz: the meshed multipoles</p> <code>Output</code> <p>Q_mesh:     K1 * K2 * K3: the meshed multipoles</p> Source code in <code>torch_admp/recip.py</code> <pre><code>def spread_charges(\n    positions: torch.Tensor,\n    box_inv: torch.Tensor,\n    charges: torch.Tensor,\n    t_kmesh: torch.Tensor,\n    shifts: torch.Tensor,\n    pme_order: int,\n):\n    \"\"\"\n    This is the high level wrapper function, in charge of spreading the charges/multipoles on grid\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        Na * 3: positions of atoms\n    box : torch.Tensor\n        3 * 3: cell vectors\n    charges : torch.Tensor\n        Na * (lmax+1)**2: the multipole of each atomic site in global frame\n\n    Returns\n    -------\n    torch.Tensor\n        Nx * Ny * Nz: the meshed multipoles\n    Output:\n        Q_mesh:\n            K1 * K2 * K3: the meshed multipoles\n\n    \"\"\"\n    recip_grid_vectors = get_recip_grid_vectors(box_inv, t_kmesh)\n    # For each atom, find the reference mesh point, and u position of the site\n    m_u0, u0 = u_reference(positions, recip_grid_vectors, pme_order)\n    # find out the STGO values of each grid point\n    sph_harms = sph_harmonics_GO(u0, shifts, pme_order)\n    # find out the local meshed values for each site\n    Q_mesh_pera = Q_m_peratom(charges, sph_harms, pme_order)\n    return Q_mesh_on_m(Q_mesh_pera, m_u0, t_kmesh, shifts)\n</code></pre>"},{"location":"api/recip/#torch_admp.recip.u_reference","title":"<code>u_reference(positions: torch.Tensor, recip_grid_vectors: torch.Tensor, pme_order: int)</code>","text":"<p>Each atom is meshed to dispersion_ORDER**3 points on the m-meshgrid. This function computes the xyz-index of the reference point, which is the point on the meshgrid just above atomic coordinates, and the corresponding values of xyz fractional displacements from real coordinate to the reference point.</p> PARAMETER DESCRIPTION <code>positions</code> <p>Na * 3: positions of atoms</p> <p> TYPE: <code>Tensor</code> </p> <code>recip_grid_vectors</code> <p>(3 * 3)-matrix for reciprocal lattice vectors of grids</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>m_u0</code> <p>N_a * 3 matrix, positions of the reference points of R_a on the m-meshgrid</p> <p> TYPE: <code>Tensor</code> </p> <code>u0</code> <p>N_a * 3 matrix, (R_a - R_m)*a_star values</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/recip.py</code> <pre><code>def u_reference(\n    positions: torch.Tensor,\n    recip_grid_vectors: torch.Tensor,\n    pme_order: int,\n):\n    \"\"\"\n    Each atom is meshed to dispersion_ORDER**3 points on the m-meshgrid.\n    This function computes the xyz-index of the reference point, which is the point on the meshgrid just above atomic coordinates,\n    and the corresponding values of xyz fractional displacements from real coordinate to the reference point.\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        Na * 3: positions of atoms\n    recip_grid_vectors : torch.Tensor\n        (3 * 3)-matrix for reciprocal lattice vectors of grids\n\n    Returns\n    -------\n    m_u0: torch.Tensor\n        N_a * 3 matrix, positions of the reference points of R_a on the m-meshgrid\n    u0: torch.Tensor\n        N_a * 3 matrix, (R_a - R_m)*a_star values\n    \"\"\"\n    R_in_m_basis = torch.einsum(\"ij,kj-&gt;ki\", recip_grid_vectors, positions)\n    m_u0 = torch.ceil(R_in_m_basis).to(torch.int)\n    u0 = (m_u0 - R_in_m_basis) + pme_order / 2\n    return m_u0, u0\n</code></pre>"},{"location":"api/spatial/","title":"spatial","text":""},{"location":"api/spatial/#spatial","title":"spatial","text":""},{"location":"api/spatial/#torch_admp.spatial","title":"<code>torch_admp.spatial</code>","text":"<p>Spatial operations for torch-admp.</p> <p>This module provides spatial operations and utilities for molecular simulations, including periodic boundary condition handling, distance calculations, and coordinate transformations.</p>"},{"location":"api/spatial/#torch_admp.spatial.build_quasi_internal","title":"<code>build_quasi_internal(r1: torch.Tensor, r2: torch.Tensor, dr: torch.Tensor, norm_dr: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Build the quasi-internal frame between a pair of sites.</p> <p>In this frame, the z-axis is pointing from r2 to r1.</p> PARAMETER DESCRIPTION <code>r1</code> <p>N * 3, positions of the first vector</p> <p> TYPE: <code>Tensor</code> </p> <code>r2</code> <p>N * 3, positions of the second vector</p> <p> TYPE: <code>Tensor</code> </p> <code>dr</code> <p>N * 3, vector pointing from r1 to r2</p> <p> TYPE: <code>Tensor</code> </p> <code>norm_dr</code> <p>(N,), distances between r1 and r2</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>N * 3 * 3: local frames, three axes arranged in rows</p> Source code in <code>torch_admp/spatial.py</code> <pre><code>@torch.jit.script\ndef build_quasi_internal(\n    r1: torch.Tensor, r2: torch.Tensor, dr: torch.Tensor, norm_dr: torch.Tensor\n) -&gt; torch.Tensor:\n    \"\"\"\n    Build the quasi-internal frame between a pair of sites.\n\n    In this frame, the z-axis is pointing from r2 to r1.\n\n    Parameters\n    ----------\n    r1 : torch.Tensor\n        N * 3, positions of the first vector\n    r2 : torch.Tensor\n        N * 3, positions of the second vector\n    dr : torch.Tensor\n        N * 3, vector pointing from r1 to r2\n    norm_dr : torch.Tensor\n        (N,), distances between r1 and r2\n\n    Returns\n    -------\n    torch.Tensor\n        N * 3 * 3: local frames, three axes arranged in rows\n    \"\"\"\n    dtype = r1.dtype\n    device = r1.device\n    # n x 3\n    vectorZ = dr / norm_dr.reshape(-1, 1)\n    vectorX = torch.where(\n        torch.logical_or(r1[1] != r2[1], r1[2] != r2[2]),\n        vectorZ + torch.tensor([1.0, 0.0, 0.0], dtype=dtype, device=device),\n        vectorZ + torch.tensor([0.0, 1.0, 0.0], dtype=dtype, device=device),\n    )\n\n    dot_xz = torch.matmul(vectorZ, vectorX)\n    vectorX = vectorX - vectorZ * dot_xz\n    vectorX = vectorX / torch.norm(vectorX)\n    vectorY = torch.linalg.cross(vectorZ, vectorX)\n    return torch.stack([vectorX, vectorY, vectorZ])\n</code></pre>"},{"location":"api/spatial/#torch_admp.spatial.ds_pairs","title":"<code>ds_pairs(positions: torch.Tensor, pairs: torch.Tensor, box: Optional[torch.Tensor] = None, pbc_flag: bool = True) -&gt; torch.Tensor</code>","text":"<p>Calculate distances between atom pairs.</p> PARAMETER DESCRIPTION <code>positions</code> <p>N * 3, positions of particles</p> <p> TYPE: <code>Tensor</code> </p> <code>pairs</code> <p>M * 2, atom pair indices</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>3 * 3, box vectors arranged in rows, by default None</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> <code>pbc_flag</code> <p>Whether to apply periodic boundary conditions, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>M, distances between atom pairs</p> Source code in <code>torch_admp/spatial.py</code> <pre><code>@torch.jit.script\ndef ds_pairs(\n    positions: torch.Tensor,\n    pairs: torch.Tensor,\n    box: Optional[torch.Tensor] = None,\n    pbc_flag: bool = True,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculate distances between atom pairs.\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        N * 3, positions of particles\n    pairs : torch.Tensor\n        M * 2, atom pair indices\n    box : Optional[torch.Tensor], optional\n        3 * 3, box vectors arranged in rows, by default None\n    pbc_flag : bool, optional\n        Whether to apply periodic boundary conditions, by default True\n\n    Returns\n    -------\n    torch.Tensor\n        M, distances between atom pairs\n    \"\"\"\n    indices = torch.tile(pairs[:, 0].reshape(-1, 1), [1, 3])\n    pos1 = torch.gather(positions, 0, indices)\n    indices = torch.tile(pairs[:, 1].reshape(-1, 1), [1, 3])\n    pos2 = torch.gather(positions, 0, indices)\n    dr = pos1 - pos2\n    if pbc_flag:\n        assert box is not None, \"Box should be provided for periodic system.\"\n        dr = pbc_shift(dr, box)\n    ds = torch.linalg.norm(dr + 1e-64, dim=1)  # add eta to avoid division by zero\n    return ds\n</code></pre>"},{"location":"api/spatial/#torch_admp.spatial.pbc_shift","title":"<code>pbc_shift(positions: torch.Tensor, box: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>wrap positions into the box</p> PARAMETER DESCRIPTION <code>positions</code> <p>N * 3, positions of the particles</p> <p> TYPE: <code>Tensor</code> </p> <code>box</code> <p>3 * 3, box vectors arranged in rows</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>wrapped_positions</code> <p>N * 3, wrapped positions</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/spatial.py</code> <pre><code>@torch.jit.script\ndef pbc_shift(positions: torch.Tensor, box: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    wrap positions into the box\n\n    Parameters\n    ----------\n    positions : torch.Tensor\n        N * 3, positions of the particles\n    box : torch.Tensor\n        3 * 3, box vectors arranged in rows\n\n    Returns\n    -------\n    wrapped_positions: torch.Tensor\n        N * 3, wrapped positions\n    \"\"\"\n    # box_inv = torch.linalg.inv(box + torch.eye(3, device=positions.device) * 1e-36)\n    box_inv = torch.linalg.inv(box)\n    unshifted_positions = torch.matmul(positions, box_inv)\n    wrapped_positions = unshifted_positions - torch.floor(unshifted_positions + 0.5)\n    return torch.matmul(wrapped_positions, box)\n</code></pre>"},{"location":"api/torch_admp/","title":"torch_admp","text":""},{"location":"api/torch_admp/#torch_admp_1","title":"torch_admp","text":""},{"location":"api/torch_admp/#torch_admp","title":"<code>torch_admp</code>","text":"<p>torch-admp: ADMP in PyTorch backend.</p>"},{"location":"api/utils/","title":"utils","text":""},{"location":"api/utils/#utils","title":"utils","text":""},{"location":"api/utils/#torch_admp.utils","title":"<code>torch_admp.utils</code>","text":"<p>Utility functions for torch-admp.</p> <p>This module provides various utility functions used throughout the torch-admp package, including mathematical operations, unit conversions, and helper functions for optimization and calculations.</p>"},{"location":"api/utils/#torch_admp.utils.TorchConstants","title":"<code>TorchConstants(units_dict: Optional[Dict] = None)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Physical constants and unit conversions for torch-admp.</p> <p>This class provides consistent physical constants and unit conversions compatible with ASE (Atomic Simulation Environment). It handles conversion between different unit systems for energy, length, and other physical quantities used in molecular simulations.</p> Notes <p>Electron volts (eV), \u00c5ngstr\u00f6m (Ang), atomic mass unit and Kelvin are defined as 1.0.</p> <p>Consistent with ASE: https://wiki.fysik.dtu.dk/ase/ase/units.html Example: units_dict = {     \"energy\": \"kJ/mol\",     \"length\": \"nm\", } Electron volts (eV), \u00c5ngstr\u00f6m (Ang), the atomic mass unit and Kelvin are defined as 1.0.</p> Source code in <code>torch_admp/utils.py</code> <pre><code>def __init__(self, units_dict: Optional[Dict] = None):\n    \"\"\"\n    Consistent with ASE: https://wiki.fysik.dtu.dk/ase/ase/units.html\n    Example:\n    units_dict = {\n        \"energy\": \"kJ/mol\",\n        \"length\": \"nm\",\n    }\n    Electron volts (eV), \u00c5ngstr\u00f6m (Ang), the atomic mass unit and Kelvin are defined as 1.0.\n    \"\"\"\n    torch.nn.Module.__init__(self)\n    self.pi = np.pi\n    self.sqrt_pi = np.sqrt(np.pi)\n    if units_dict is None:\n        units_dict = {}\n    user_energy = units_dict.get(\"energy\", \"eV\")\n    user_length = units_dict.get(\"length\", \"Ang\")\n\n    # from user-defined units to ASE units (eV, Ang)\n    try:\n        length_coeff = getattr(units, user_length)\n    except AttributeError as exc:\n        raise ValueError(f\"Unknown length unit: {user_length}\") from exc\n    try:\n        if user_energy == \"kJ/mol\":\n            energy_coeff = units.kJ / units.mol\n        else:\n            energy_coeff = getattr(units, user_energy)\n    except AttributeError as exc:\n        raise ValueError(f\"Unknown energy unit: {user_energy}\") from exc\n\n    self.length_coeff = length_coeff\n    self.energy_coeff = energy_coeff\n    # self.register_buffer(\n    #     \"j2ev\",\n    #     torch.tensor(\n    #         constants.physical_constants[\"joule-electron volt relationship\"][0],\n    #         device=DEVICE,\n    #     ),\n    # )\n    # # convert energy unit from kJ/mol to eV/particle (DMFF &lt;-&gt; DP)\n    # self.register_buffer(\n    #     \"energy_coeff\", self.j2ev * constants.kilo / constants.Avogadro\n    # )\n\n    # vacuum electric permittivity in eV^-1 * angstrom^-1\n    self.epsilon = (\n        constants.epsilon_0 / constants.elementary_charge * constants.angstrom\n    )\n    # qqrd2e = 1 / (4 * np.pi * EPSILON)\n    # eV\n    self.dielectric = 1.0 / (4.0 * np.pi * self.epsilon)\n</code></pre>"},{"location":"api/utils/#torch_admp.utils.calc_grads","title":"<code>calc_grads(t_out: torch.Tensor, t_in: torch.Tensor)</code>","text":"<p>Calculate gradients</p> PARAMETER DESCRIPTION <code>t_out</code> <p>Outputs of the differentiated function</p> <p> TYPE: <code>Tensor</code> </p> <code>t_in</code> <p>Inputs w.r.t. which the gradient will be returned</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>grad</code> <p>Gradients</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/utils.py</code> <pre><code>@torch.jit.script\ndef calc_grads(t_out: torch.Tensor, t_in: torch.Tensor):\n    \"\"\"\n    Calculate gradients\n\n    Parameters\n    ----------\n    t_out : torch.Tensor\n        Outputs of the differentiated function\n    t_in : torch.Tensor\n        Inputs w.r.t. which the gradient will be returned\n\n    Returns\n    -------\n    grad : torch.Tensor\n        Gradients\n    \"\"\"\n    assert t_in.requires_grad, \"Input tensor requires grad\"\n\n    faked_grad = torch.ones_like(t_out)\n    lst = torch.jit.annotate(List[Optional[torch.Tensor]], [faked_grad])\n    grad = torch.autograd.grad(\n        [t_out],\n        [t_in],\n        grad_outputs=lst,\n        retain_graph=True,\n    )[0]\n    assert grad is not None\n    return grad\n</code></pre>"},{"location":"api/utils/#torch_admp.utils.calc_pgrads","title":"<code>calc_pgrads(t_out: torch.Tensor, t_in: torch.Tensor, constraint_matrix: torch.Tensor, coeff_matrix: torch.Tensor)</code>","text":"<p>Calculate projected gradients for constrained optimization</p> PARAMETER DESCRIPTION <code>t_out</code> <p>Output tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>t_in</code> <p>Input tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_matrix</code> <p>n_const * natoms, constraint matrix</p> <p> TYPE: <code>Tensor</code> </p> <code>coeff_matrix</code> <p>natoms * n_const, Coefficient matrix for vector projection</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Projected gradients</p> Source code in <code>torch_admp/utils.py</code> <pre><code>@torch.jit.script\ndef calc_pgrads(\n    t_out: torch.Tensor,\n    t_in: torch.Tensor,\n    constraint_matrix: torch.Tensor,\n    coeff_matrix: torch.Tensor,\n):\n    \"\"\"\n    Calculate projected gradients for constrained optimization\n\n    Parameters\n    ----------\n    t_out : torch.Tensor\n        Output tensor\n    t_in : torch.Tensor\n        Input tensor\n    constraint_matrix : torch.Tensor\n        n_const * natoms, constraint matrix\n    coeff_matrix : torch.Tensor\n        natoms * n_const, Coefficient matrix for vector projection\n\n    Returns\n    -------\n    torch.Tensor\n        Projected gradients\n    \"\"\"\n    raw_grads = calc_grads(t_out, t_in)\n    # n_atoms * 1\n    raw_grads = raw_grads.reshape(-1, 1)\n    # n_const * 1\n    residual = -torch.matmul(constraint_matrix, raw_grads)\n    # n_atoms * 1\n    pgrads = raw_grads + torch.matmul(coeff_matrix, residual)\n    return pgrads.reshape(-1)\n</code></pre>"},{"location":"api/utils/#torch_admp.utils.pair_buffer_scales","title":"<code>pair_buffer_scales(pairs: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Calculate buffer scales for atom pairs.</p> PARAMETER DESCRIPTION <code>pairs</code> <p>Tensor of atom pairs</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Buffer scales for each pair (1 if i &lt; j, else 0)</p> Source code in <code>torch_admp/utils.py</code> <pre><code>def pair_buffer_scales(pairs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Calculate buffer scales for atom pairs.\n\n    Parameters\n    ----------\n    pairs : torch.Tensor\n        Tensor of atom pairs\n\n    Returns\n    -------\n    torch.Tensor\n        Buffer scales for each pair (1 if i &lt; j, else 0)\n    \"\"\"\n    dp = pairs[:, 0] - pairs[:, 1]\n    return torch.where(\n        dp &lt; 0,\n        torch.tensor(1, dtype=torch.long, device=pairs.device),\n        torch.tensor(0, dtype=torch.long, device=pairs.device),\n    )\n</code></pre>"},{"location":"api/utils/#torch_admp.utils.regularize_pairs","title":"<code>regularize_pairs(pairs: torch.Tensor, buffer_scales: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Regularize atom pairs based on buffer scales.</p> PARAMETER DESCRIPTION <code>pairs</code> <p>Tensor of atom pairs</p> <p> TYPE: <code>Tensor</code> </p> <code>buffer_scales</code> <p>Buffer scales for each pair</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>Regularized atom pairs</p> Source code in <code>torch_admp/utils.py</code> <pre><code>def regularize_pairs(pairs: torch.Tensor, buffer_scales: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Regularize atom pairs based on buffer scales.\n\n    Parameters\n    ----------\n    pairs : torch.Tensor\n        Tensor of atom pairs\n    buffer_scales : torch.Tensor\n        Buffer scales for each pair\n\n    Returns\n    -------\n    torch.Tensor\n        Regularized atom pairs\n    \"\"\"\n    a = pairs[:, 0] - buffer_scales\n    b = pairs[:, 1] - buffer_scales * 2\n    return torch.stack((a, b), dim=1)\n</code></pre>"},{"location":"api/utils/#torch_admp.utils.safe_inverse","title":"<code>safe_inverse(x: torch.Tensor, threshold: float = 1e-08) -&gt; torch.Tensor</code>","text":"<p>Safe inverse for numerical stability</p> PARAMETER DESCRIPTION <code>x</code> <p>Input tensor</p> <p> TYPE: <code>Tensor</code> </p> <code>threshold</code> <p>Threshold for numerical stability</p> <p> TYPE: <code>float (default: 1e-8)</code> DEFAULT: <code>1e-08</code> </p> RETURNS DESCRIPTION <code>inv_x</code> <p>Inverse of x if x.abs() &gt; threshold, otherwise 0</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/utils.py</code> <pre><code>def safe_inverse(x: torch.Tensor, threshold: float = 1e-8) -&gt; torch.Tensor:\n    \"\"\"Safe inverse for numerical stability\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor\n    threshold : float (default: 1e-8)\n        Threshold for numerical stability\n\n    Returns\n    -------\n    inv_x : torch.Tensor\n        Inverse of x if x.abs() &gt; threshold, otherwise 0\n    \"\"\"\n    return torch.where(x.abs() &gt; threshold, 1 / x, torch.zeros_like(x))\n</code></pre>"},{"location":"api/utils/#torch_admp.utils.vector_projection","title":"<code>vector_projection(vector_in: torch.Tensor, constraint_matrix: torch.Tensor, constraint_vector: Optional[torch.Tensor] = None) -&gt; torch.Tensor</code>","text":"<p>Vector projection subject to linear constraints     P(x) = x + A^T(A A^T)^{-1}(b - Ax)</p> PARAMETER DESCRIPTION <code>vector_in</code> <p>Input vector (n_atoms * 1).</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_matrix</code> <p>Constraint matrix (n_const * natoms).</p> <p> TYPE: <code>Tensor</code> </p> <code>constraint_vector</code> <p>Constraint vector (n_const * 1). All zeros when set as None (default).</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>vector_out</code> <p>n_atoms, projected vector</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/utils.py</code> <pre><code>@torch.jit.script\ndef vector_projection(\n    vector_in: torch.Tensor,\n    constraint_matrix: torch.Tensor,\n    constraint_vector: Optional[torch.Tensor] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Vector projection subject to linear constraints\n        P(x) = x + A^T(A A^T)^{-1}(b - Ax)\n\n    Parameters\n    ----------\n    vector_in : torch.Tensor\n        Input vector (n_atoms * 1).\n    constraint_matrix : torch.Tensor\n        Constraint matrix (n_const * natoms).\n    constraint_vector : torch.Tensor, optional\n        Constraint vector (n_const * 1).\n        All zeros when set as None (default).\n\n    Returns\n    -------\n    vector_out : torch.Tensor\n        n_atoms, projected vector\n    \"\"\"\n    if constraint_vector is None:\n        constraint_vector = torch.zeros(\n            [constraint_matrix.shape[0]], device=vector_in.device\n        )\n\n    # n_atoms * n_atoms\n    coeff_matrix = vector_projection_coeff_matrix(constraint_matrix)\n    # n_atoms * 1\n    residual = constraint_vector.reshape(-1, 1) - torch.matmul(\n        constraint_matrix, vector_in\n    )\n    vector_out = vector_in.reshape(-1, 1) + torch.matmul(coeff_matrix, residual)\n    return vector_out.reshape(-1)\n</code></pre>"},{"location":"api/utils/#torch_admp.utils.vector_projection_coeff_matrix","title":"<code>vector_projection_coeff_matrix(constraint_matrix: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Calculate coefficient matrix for vector projection based on constraint matrix</p> PARAMETER DESCRIPTION <code>constraint_matrix</code> <p>Constraint matrix (n_const * natoms).</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>coeff_mat</code> <p>Coefficient matrix (n_atoms * n_const).</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>torch_admp/utils.py</code> <pre><code>@torch.jit.script\ndef vector_projection_coeff_matrix(constraint_matrix: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Calculate coefficient matrix for vector projection based on constraint matrix\n\n    Parameters\n    ----------\n    constraint_matrix : torch.Tensor\n        Constraint matrix (n_const * natoms).\n\n    Returns\n    -------\n    coeff_mat: torch.Tensor\n        Coefficient matrix (n_atoms * n_const).\n    \"\"\"\n    constraint_matrix_t = torch.transpose(constraint_matrix, 0, 1)\n    # n_atoms * n_const\n    coeff_mat = torch.matmul(\n        constraint_matrix_t,\n        torch.inverse(torch.matmul(constraint_matrix, constraint_matrix_t)),\n    )\n    return coeff_mat\n</code></pre>"},{"location":"examples/pme/","title":"PME Example","text":""},{"location":"examples/pme/#pme-example","title":"PME Example","text":"<p>This example demonstrates the comprehensive use of the Particle Mesh Ewald (PME) implementation in torch-admp to calculate electrostatic interactions and forces.</p>"},{"location":"examples/pme/#overview","title":"Overview","text":"<p>The PME method efficiently calculates long-range electrostatic interactions by splitting the calculation into real-space and reciprocal-space components. This comprehensive example shows how to:</p> <ol> <li>Set up a basic system with random positions and charges</li> <li>Use advanced PME parameters (slab correction, kappa, spacing, kmesh)</li> <li>Access individual energy components (real, reciprocal, self, non-neutral)</li> <li>Use JIT compilation for performance optimization</li> <li>Process multiple configurations in a batch</li> <li>Handle errors and validate inputs</li> <li>Use getter methods to retrieve module parameters</li> <li>Compare 3D PBC and 2D slab correction cases</li> <li>Use the setup_ewald_parameters utility function</li> </ol>"},{"location":"examples/pme/#running-the-example","title":"Running the Example","text":"<p>To run the comprehensive PME example:</p> <pre><code>cd examples/pme\npython run.py\n</code></pre>"},{"location":"examples/pme/#key-features-demonstrated","title":"Key Features Demonstrated","text":""},{"location":"examples/pme/#1-basic-pme-usage","title":"1. Basic PME Usage","text":"<p>The example starts with a basic PME calculation for a periodic system:</p> <pre><code># System parameters\nrcut = 6.0  # Cutoff distance in Angstroms\nn_atoms = 100  # Number of atoms\nethresh = 1e-5  # Ewald precision threshold\nl_box = 20.0  # Box length in Angstroms\n\n# Generate random system\npositions = np.random.rand(n_atoms, 3) * l_box\nbox = np.diag([l_box, l_box, l_box])\ncharges = np.random.uniform(-1.0, 1.0, (n_atoms))\ncharges -= charges.mean()  # Make system charge-neutral\n\n# Create neighbor list and PME module\nnblist = TorchNeighborList(cutoff=rcut)\npairs = nblist(positions, box)\nds = nblist.get_ds()\nbuffer_scales = nblist.get_buffer_scales()\n\n# Calculate PME energy and forces\nmodule = CoulombForceModule(rcut=rcut, ethresh=ethresh)\nenergy = module(positions, box, pairs, ds, buffer_scales, {\"charge\": charges})\nforces = -calc_grads(energy, positions)\n</code></pre>"},{"location":"examples/pme/#2-advanced-parameters","title":"2. Advanced Parameters","text":"<p>The example demonstrates various advanced PME parameters:</p>"},{"location":"examples/pme/#custom-kappa-inverse-screening-length","title":"Custom kappa (inverse screening length)","text":"<pre><code>custom_kappa = 0.3  # \u00c5^-1\nmodule_kappa = CoulombForceModule(rcut=rcut, ethresh=ethresh, kappa=custom_kappa)\n</code></pre>"},{"location":"examples/pme/#custom-grid-spacing","title":"Custom grid spacing","text":"<pre><code>custom_spacing = 1.0  # \u00c5\nmodule_spacing = CoulombForceModule(rcut=rcut, ethresh=ethresh, spacing=custom_spacing)\n</code></pre>"},{"location":"examples/pme/#custom-kmesh","title":"Custom kmesh","text":"<pre><code>custom_kmesh = [24, 24, 24]\nmodule_kmesh = CoulombForceModule(rcut=rcut, ethresh=ethresh, kmesh=custom_kmesh)\n</code></pre>"},{"location":"examples/pme/#slab-correction","title":"Slab correction","text":"<pre><code>module_slab = CoulombForceModule(\n    rcut=rcut,\n    ethresh=ethresh,\n    slab_corr=True,\n    slab_axis=2,  # Apply correction along z-axis\n)\n</code></pre>"},{"location":"examples/pme/#3-energy-component-access","title":"3. Energy Component Access","text":"<p>The example shows how to access individual energy components:</p> <pre><code># After calculating energy\nreal_energy = module.real_energy\nreciprocal_energy = module.reciprocal_energy\nself_energy = module.self_energy\nnon_neutral_energy = module.non_neutral_energy\nslab_corr_energy = module.slab_corr_energy  # If slab_corr=True\n\nprint(f\"Real-space energy:     {real_energy.item():.6f} eV\")\nprint(f\"Reciprocal energy:     {reciprocal_energy.item():.6f} eV\")\nprint(f\"Self energy:            {self_energy.item():.6f} eV\")\nprint(f\"Non-neutral correction: {non_neutral_energy.item():.6f} eV\")\nprint(f\"Total energy:           {energy.item():.6f} eV\")\n</code></pre>"},{"location":"examples/pme/#4-jit-compilation","title":"4. JIT Compilation","text":"<p>The example demonstrates JIT compilation for performance optimization:</p> <pre><code># Create regular module\nmodule = CoulombForceModule(rcut=rcut, ethresh=ethresh)\n\n# Create JIT-compiled module\njit_module = torch.jit.script(module)\n\n# Save JIT module for later use\ntorch.jit.save(jit_module, \"pme_module_jit.pt\")\n\n# Load JIT module later\nloaded_jit_module = torch.jit.load(\"pme_module_jit.pt\")\n</code></pre>"},{"location":"examples/pme/#5-batch-processing","title":"5. Batch Processing","text":"<p>The example shows how to process multiple configurations in a batch:</p> <pre><code># Create batch of systems\nbatch_positions = torch.tensor(\n    batch_positions, requires_grad=True\n)  # (n_frames, n_atoms, 3)\nbatch_box = (\n    torch.tensor(np.diag([l_box, l_box, l_box])).unsqueeze(0).repeat(n_frames, 1, 1)\n)  # (n_frames, 3, 3)\nbatch_charges = torch.tensor(batch_charges)  # (n_frames, n_atoms)\n\n# Calculate batch energies\nbatch_energies = module(\n    batch_positions,\n    batch_box,\n    batch_pairs,\n    batch_ds,\n    batch_buffer_scales,\n    {\"charge\": batch_charges},\n)\n</code></pre>"},{"location":"examples/pme/#6-error-handling","title":"6. Error Handling","text":"<p>The example demonstrates proper error handling:</p> <pre><code># Test invalid slab_axis\ntry:\n    module = CoulombForceModule(rcut=6.0, ethresh=1e-5, slab_corr=True, slab_axis=3)\nexcept (ValueError, AssertionError) as e:\n    print(f\"Correctly caught error: {type(e).__name__}: {e}\")\n\n# Test invalid ethresh\ntry:\n    module = CoulombForceModule(rcut=6.0, ethresh=-1e-5)\nexcept (ValueError, AssertionError) as e:\n    print(f\"Correctly caught error: {type(e).__name__}: {e}\")\n</code></pre>"},{"location":"examples/pme/#7-getter-methods","title":"7. Getter Methods","text":"<p>The example shows how to use getter methods:</p> <pre><code># Create module with custom parameters\nrcut = 6.0\nsel = [10, 20, 30]  # Example selection list\nmodule = CoulombForceModule(rcut=rcut, ethresh=1e-5, sel=sel)\n\n# Use getter methods\nretrieved_rcut = module.get_rcut()\nretrieved_sel = module.get_sel()\n\nprint(f\"Retrieved rcut: {retrieved_rcut} \u00c5\")\nprint(f\"Retrieved sel: {retrieved_sel}\")\n</code></pre>"},{"location":"examples/pme/#8-3d-pbc-vs-2d-slab-correction","title":"8. 3D PBC vs 2D Slab Correction","text":"<p>The example compares 3D PBC and 2D slab correction cases:</p> <pre><code># 3D PBC calculation\nmodule_3d = CoulombForceModule(rcut=rcut, ethresh=ethresh, slab_corr=False)\nenergy_3d = module_3d(positions, box_3d, pairs, ds, buffer_scales, {\"charge\": charges})\n\n# 2D slab correction calculation (z-axis)\nmodule_2d = CoulombForceModule(rcut=rcut, ethresh=ethresh, slab_corr=True, slab_axis=2)\nenergy_2d = module_2d(positions, box_2d, pairs, ds, buffer_scales, {\"charge\": charges})\n\nprint(f\"3D PBC energy:           {energy_3d.item():.6f} eV\")\nprint(f\"2D slab correction energy: {energy_2d.item():.6f} eV\")\nprint(f\"Slab correction term:     {module_2d.slab_corr_energy.item():.6f} eV\")\n</code></pre>"},{"location":"examples/pme/#9-ewald-parameters-setup","title":"9. Ewald Parameters Setup","text":"<p>The example demonstrates the <code>setup_ewald_parameters</code> utility function:</p> <pre><code>from torch_admp.pme import setup_ewald_parameters\n\n# OpenMM method\nkappa_omm, kx_omm, ky_omm, kz_omm = setup_ewald_parameters(\n    rcut=rcut, box=box, threshold=ethresh, method=\"openmm\"\n)\n\n# Gromacs method\nkappa_gmx, kx_gmx, ky_gmx, kz_gmx = setup_ewald_parameters(\n    rcut=rcut, box=box, threshold=ethresh, spacing=1.0, method=\"gromacs\"\n)\n</code></pre>"},{"location":"examples/pme/#key-components","title":"Key Components","text":"<ul> <li>TorchNeighborList: Efficient neighbor list construction for periodic systems</li> <li>CoulombForceModule: PME implementation for electrostatic calculations</li> <li>calc_grads: Utility function for computing gradients using automatic differentiation</li> <li>setup_ewald_parameters: Utility function to compute optimal PME parameters</li> </ul>"},{"location":"examples/pme/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>The implementation is optimized for GPU acceleration</li> <li>Uses double precision (float64) for numerical accuracy</li> <li>JIT compilation can provide significant speedups for repeated calculations</li> <li>Batch processing is more efficient than processing configurations individually</li> <li>Neighbor list is updated automatically when positions change significantly</li> </ul>"},{"location":"examples/pme/#parameters","title":"Parameters","text":"<ul> <li><code>rcut</code>: Real-space cutoff distance (typically 6-12 \u00c5)</li> <li><code>ethresh</code>: Ewald convergence threshold (typically 1e-4 to 1e-6)</li> <li><code>kappa</code>: Inverse screening length (computed automatically if not specified)</li> <li><code>spacing</code>: Grid spacing for reciprocal space (affects kmesh if specified)</li> <li><code>kmesh</code>: Number of grid points in each dimension (computed automatically if not specified)</li> <li><code>slab_corr</code>: Whether to apply slab correction (default: False)</li> <li><code>slab_axis</code>: Axis for slab correction (0=x, 1=y, 2=z, default: 2)</li> <li><code>kspace</code>: Whether to include reciprocal space contribution (default: True)</li> <li><code>rspace</code>: Whether to include real space contribution (default: True)</li> <li><code>sel</code>: Selection list for neighbor list (default: None)</li> </ul>"},{"location":"examples/pme/#output","title":"Output","text":"<p>The example provides detailed output for each demonstration, including:</p> <ul> <li>Energy values and breakdowns into components</li> <li>Performance comparisons between regular and JIT execution</li> <li>Error handling demonstrations</li> <li>Parameter retrieval examples</li> <li>Comparisons between different PME configurations</li> </ul>"},{"location":"examples/qeq/","title":"QEq Example","text":""},{"location":"examples/qeq/#qeq-examples","title":"QEq Examples","text":"<p>This directory contains comprehensive examples demonstrating the full capabilities of QEq (Charge Equilibration) module in torch-admp. The examples cover everything from basic usage to advanced features like JIT compilation, constraint handling, and Hessian analysis.</p>"},{"location":"examples/qeq/#overview","title":"Overview","text":"<p>Charge Equilibration (QEq) is a method for determining atomic charges in molecular systems by minimizing electrostatic energy subject to constraints. The torch-admp implementation provides multiple optimization methods, constraint handling, and advanced features for efficient charge calculation.</p>"},{"location":"examples/qeq/#available-examples","title":"Available Examples","text":""},{"location":"examples/qeq/#1-basic-qeq-usage-basic_qeqpy","title":"1. Basic QEq Usage (<code>basic_qeq.py</code>)","text":"<p>Demonstrates fundamental QEq usage including:</p> <ul> <li>Loading molecular data from PDB and XML files</li> <li>Setting up QEq calculation with basic parameters</li> <li>Solving for equilibrium charges using projected gradient method</li> <li>Calculating energy and forces</li> </ul> <p>Key Features:</p> <ul> <li>Basic QEq setup and execution</li> <li>Charge conservation constraints</li> <li>Energy and force calculation</li> </ul> <p>Usage:</p> <pre><code>python basic_qeq.py\n</code></pre>"},{"location":"examples/qeq/#2-matrix-inversion-method-matrix_inversionpy","title":"2. Matrix Inversion Method (<code>matrix_inversion.py</code>)","text":"<p>Shows how to use the matrix inversion method for QEq calculations:</p> <ul> <li>Direct solution of linear system without iterative optimization</li> <li>Comparison with projected gradient method</li> <li>Hessian matrix analysis</li> </ul> <p>Key Features:</p> <ul> <li>Matrix inversion vs projected gradient comparison</li> <li>Diagonal Hessian elements</li> <li>Fermi level calculation</li> </ul> <p>Usage:</p> <pre><code>python matrix_inversion.py\n</code></pre>"},{"location":"examples/qeq/#3-optimization-methods-optimization_methodspy","title":"3. Optimization Methods (<code>optimization_methods.py</code>)","text":"<p>Demonstrates different optimization methods available for QEq:</p> <ul> <li>LBFGS optimization</li> <li>Quadratic optimization</li> <li>Performance comparison between methods</li> <li>Testing with different initial guesses</li> </ul> <p>Key Features:</p> <ul> <li>Multiple optimization algorithms</li> <li>Convergence behavior analysis</li> <li>Initial guess sensitivity</li> </ul> <p>Usage:</p> <pre><code>python optimization_methods.py\n</code></pre>"},{"location":"examples/qeq/#4-advanced-parameters-advanced_parameterspy","title":"4. Advanced Parameters (<code>advanced_parameters.py</code>)","text":"<p>Shows how to use various advanced QEq parameters:</p> <ul> <li><code>max_iter</code>: Maximum number of iterations</li> <li><code>eps</code>: Convergence threshold</li> <li><code>damping</code>: Gaussian damping toggle</li> <li><code>kspace</code>/<code>rspace</code>: Reciprocal/real space control</li> </ul> <p>Key Features:</p> <ul> <li>Parameter tuning demonstrations</li> <li>Performance impact analysis</li> <li>Submodel configuration</li> </ul> <p>Usage:</p> <pre><code>python advanced_parameters.py\n</code></pre>"},{"location":"examples/qeq/#5-convergence-criteria-convergence_criteriapy","title":"5. Convergence Criteria (<code>convergence_criteria.py</code>)","text":"<p>Demonstrates convergence customization and monitoring:</p> <ul> <li>Different convergence thresholds</li> <li>Convergence history tracking</li> <li>Method-specific convergence behavior</li> <li>Line search parameter tuning</li> </ul> <p>Key Features:</p> <ul> <li>Convergence threshold testing</li> <li>Iteration monitoring</li> <li>Performance optimization</li> </ul> <p>Usage:</p> <pre><code>python convergence_criteria.py\n</code></pre>"},{"location":"examples/qeq/#6-batch-processing-batch_processingpy","title":"6. Batch Processing (<code>batch_processing.py</code>)","text":"<p>Shows how to efficiently process multiple configurations:</p> <ul> <li>Batch processing workflows</li> <li>Trajectory processing</li> <li>Force calculation for multiple frames</li> <li>Performance optimization strategies</li> </ul> <p>Key Features:</p> <ul> <li>Multiple configuration handling</li> <li>Trajectory analysis</li> <li>Efficient batch workflows</li> </ul> <p>Usage:</p> <pre><code>python batch_processing.py\n</code></pre>"},{"location":"examples/qeq/#7-jit-compilation-jit_compilationpy","title":"7. JIT Compilation (<code>jit_compilation.py</code>)","text":"<p>Demonstrates JIT compilation for performance optimization:</p> <ul> <li>JIT vs regular performance comparison</li> <li>Method-specific JIT optimization</li> <li>Warm-up effects</li> <li>Batch processing with JIT</li> </ul> <p>Key Features:</p> <ul> <li>Performance benchmarking</li> <li>JIT compilation benefits</li> <li>Optimization strategies</li> </ul> <p>Usage:</p> <pre><code>python jit_compilation.py\n</code></pre>"},{"location":"examples/qeq/#8-hessian-calculation-hessian_calculationpy","title":"8. Hessian Calculation (<code>hessian_calculation.py</code>)","text":"<p>Shows how to calculate and analyze the Hessian matrix:</p> <ul> <li>Hessian matrix calculation</li> <li>Eigenvalue analysis</li> <li>Structure analysis</li> <li>Parameter effects on Hessian</li> </ul> <p>Key Features:</p> <ul> <li>Hessian matrix properties</li> <li>Positive definiteness checking</li> <li>Distance dependence analysis</li> <li>Parameter sensitivity</li> </ul> <p>Usage:</p> <pre><code>python hessian_calculation.py\n</code></pre> <p>&lt;!--</p>"},{"location":"examples/qeq/#9-constraint-handling-constraint_handlingpy","title":"9. Constraint Handling (<code>constraint_handling.py</code>)","text":"<p>Demonstrates various constraint types and handling:</p> <ul> <li>Charge conservation constraints</li> <li>Fixed charge constraints</li> <li>Group charge constraints</li> <li>Vector projection coefficient matrices</li> </ul> <p>Key Features:</p> <ul> <li>Multiple constraint types</li> <li>Constraint matrix properties</li> <li>Vector projection mathematics</li> <li>Constraint verification</li> </ul> <p>Usage:</p> <pre><code>python constraint_handling.py\n``` --&gt;\n\n## Running All Examples\n\nTo run all examples in sequence, use the provided script:\n\n```bash\npython run_all.py\n</code></pre> <p>This will execute each example in order and display the results, providing a comprehensive demonstration of all QEq features.</p>"},{"location":"examples/qeq/#basic-usage","title":"Basic Usage","text":"<p>Here's a minimal example of QEq usage:</p> <pre><code>import torch\nfrom torch_admp.qeq import QEqForceModule\nfrom torch_admp.nblist import TorchNeighborList\n\n# Create QEq module\nmodule = QEqForceModule(rcut=8.0, ethresh=1e-5)\n\n# Calculate neighbor list\nnblist = TorchNeighborList(cutoff=8.0)\npairs = nblist(positions, box)\nds = nblist.get_ds()\nbuffer_scales = nblist.get_buffer_scales()\n\n# Set up constraints (total charge = 0)\nconstraint_matrix = torch.ones([1, n_atoms], dtype=torch.float64)\nconstraint_vals = torch.zeros(1, dtype=torch.float64)\n\n# Solve for charges using projected gradient method\nenergy, charges = module.solve_pgrad(\n    charges,\n    positions,\n    box,\n    chi,\n    hardness,\n    eta,\n    pairs,\n    ds,\n    buffer_scales,\n    constraint_matrix,\n    constraint_vals,\n)\n</code></pre>"},{"location":"examples/qeq/#advanced-features","title":"Advanced Features","text":""},{"location":"examples/qeq/#matrix-inversion-method","title":"Matrix Inversion Method","text":"<p>For direct solution without iterative optimization:</p> <pre><code># Solve using matrix inversion\nenergy, charges, diag_hessian, fermi = module.solve_matrix_inversion(\n    positions,\n    box,\n    chi,\n    hardness,\n    eta,\n    pairs,\n    ds,\n    buffer_scales,\n    constraint_matrix,\n    constraint_vals,\n)\n</code></pre>"},{"location":"examples/qeq/#jit-compilation","title":"JIT Compilation","text":"<p>For performance optimization with repeated calculations:</p> <pre><code># Create JIT-compiled module\njit_module = torch.jit.script(QEqForceModule(rcut=8.0, ethresh=1e-5))\n\n# Use with pgrad_optimize function\nfrom torch_admp.qeq import pgrad_optimize\n\nenergy, charges = pgrad_optimize(\n    jit_module,\n    charges,\n    positions,\n    box,\n    chi,\n    hardness,\n    eta,\n    pairs,\n    ds,\n    buffer_scales,\n    constraint_matrix,\n    constraint_vals,\n)\n</code></pre>"},{"location":"examples/qeq/#custom-constraints","title":"Custom Constraints","text":"<p>Implement custom constraints using constraint matrix:</p> <pre><code># Define constraint matrix A and values b\nA = torch.tensor([...])  # Constraint coefficients\nb = torch.tensor([...])  # Constraint values\n\n# Calculate coefficient matrix\nfrom torch_admp.utils import vector_projection_coeff_matrix\n\ncoeff_matrix = vector_projection_coeff_matrix(A)\n\n# Solve with constraints\nenergy, charges = module.solve_pgrad(..., A, b, coeff_matrix=coeff_matrix)\n</code></pre>"},{"location":"examples/qeq/#hessian-analysis","title":"Hessian Analysis","text":"<p>For analyzing the energy landscape curvature:</p> <pre><code># Calculate Hessian matrix\nhessian = module.calc_hessian(\n    positions, box, chi, hardness, eta, pairs, ds, buffer_scales\n)\n\n# Analyze eigenvalues\neigenvalues = torch.linalg.eigvalsh(hessian)\nprint(f\"Condition number: {eigenvalues.max() / eigenvalues.min()}\")\n</code></pre>"},{"location":"examples/qeq/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use JIT Compilation: For repeated calculations, use JIT compilation for significant speedup</li> <li>Choose Appropriate Method: LBFGS is generally faster, quadratic may be more robust</li> <li>Tune Convergence: Adjust <code>eps</code> and <code>max_iter</code> for your specific system</li> <li>Batch Processing: Process multiple configurations together when possible</li> <li>Constraint Optimization: Use the most specific constraints needed</li> </ol>"},{"location":"examples/qeq/#common-use-cases","title":"Common Use Cases","text":""},{"location":"examples/qeq/#molecular-dynamics","title":"Molecular Dynamics","text":"<p>Use <code>batch_processing.py</code> as a template for processing MD trajectories:</p> <pre><code># Process each frame\nfor frame in trajectory:\n    charges = solve_qeq(frame.positions, frame.box)\n    # Use charges for force calculation\n</code></pre>"},{"location":"examples/qeq/#parameter-optimization","title":"Parameter Optimization","text":"<p>Use <code>advanced_parameters.py</code> and <code>convergence_criteria.py</code> to optimize parameters:</p> <pre><code># Test different convergence thresholds\nfor eps in [1e-4, 1e-5, 1e-6]:\n    module = QEqForceModule(eps=eps, ...)\n    # Test performance\n</code></pre>"},{"location":"examples/qeq/#large-systems","title":"Large Systems","text":"<p>For large systems, consider:</p> <ul> <li>Using matrix inversion method if memory allows</li> <li>JIT compilation for repeated calculations</li> <li>Appropriate cutoff values</li> </ul>"},{"location":"examples/qeq/#api-reference","title":"API Reference","text":""},{"location":"examples/qeq/#qeqforcemodule","title":"QEqForceModule","text":"<p>Main class for QEq calculations.</p> <p>Parameters:</p> <ul> <li><code>rcut</code> (float): Cutoff radius for short-range interactions</li> <li><code>ethresh</code> (float, optional): Energy threshold for electrostatic interactions</li> <li><code>max_iter</code> (int, optional): Maximum iterations for optimization</li> <li><code>eps</code> (float, optional): Convergence threshold</li> <li><code>damping</code> (bool, optional): Whether to include Gaussian damping</li> </ul> <p>Methods:</p> <ul> <li><code>solve_pgrad()</code>: Solve using projected gradient method</li> <li><code>solve_matrix_inversion()</code>: Solve using matrix inversion</li> <li><code>calc_hessian()</code>: Calculate Hessian matrix</li> <li><code>func_energy()</code>: Calculate energy for given charges</li> </ul>"},{"location":"examples/qeq/#utility-functions","title":"Utility Functions","text":"<ul> <li><code>vector_projection()</code>: Project vector onto constraint subspace</li> <li><code>vector_projection_coeff_matrix()</code>: Calculate coefficient matrix for projection</li> <li><code>pgrad_optimize()</code>: Function for projected gradient optimization</li> <li><code>calc_pgrads()</code>: Calculate projected gradients</li> </ul>"},{"location":"examples/qeq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"examples/qeq/#common-issues","title":"Common Issues","text":"<ol> <li>Non-convergence:</li> <li>Increase <code>max_iter</code></li> <li>Relax <code>eps</code> threshold</li> <li> <p>Try different optimization method</p> </li> <li> <p>Memory issues:</p> </li> <li>Reduce cutoff radius</li> <li>Use projected gradient instead of matrix inversion</li> <li> <p>Process in smaller batches</p> </li> <li> <p>Incorrect charges:</p> </li> <li>Check constraint setup</li> <li>Verify parameter units</li> <li>Validate input data</li> </ol>"},{"location":"examples/qeq/#performance-issues","title":"Performance Issues","text":"<ol> <li>Slow convergence:</li> <li>Use better initial guesses</li> <li>Try LBFGS method</li> <li> <p>Enable JIT compilation</p> </li> <li> <p>Large memory usage:</p> </li> <li>Reduce system size</li> <li>Use appropriate cutoffs</li> <li>Disable unnecessary submodels</li> </ol>"},{"location":"examples/qeq/#references","title":"References","text":"<p>For more detailed information about QEq theory and implementation:</p> <ol> <li> <p>Rapp\u00e9, A. K., &amp; Goddard, W. A. (1991). Charge equilibration for molecular dynamics simulations. The Journal of Physical Chemistry, 95(8), 3358-3363.</p> </li> <li> <p>Chen, J., &amp; Mart\u00ednez, T. J. (2007). Charge equilibration: A variational approach. The Journal of Chemical Physics, 126(14), 144107.</p> </li> <li> <p>torch-admp documentation: https://github.com/ChiahsinChu/torch-admp</p> </li> </ol>"}]}